<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Openai Research</title>
  <id>tag:ai-news-direct.local,2025:openai_research</id>
  <icon>https://openai.com/favicon.ico</icon>
  <logo>https://openai.com/favicon.ico</logo>
  <updated>2025-12-07T21:17:55.051742+00:00</updated>
  <author>
    <name>AI News Direct</name>
  </author>
  <link href="https://raw.githubusercontent.com/mibuhand/AI-News-Direct/main/feeds/openai_research.xml" rel="self"/>
  <entry>
    <title>How confessions can keep language models honest</title>
    <id>2ce28f3cfd7679be0ab59c0e10dcce2a</id>
    <link href="https://openai.com/index/how-confessions-can-keep-language-models-honest/"/>
    <updated>2025-12-03T10:00:00+00:00</updated>
    <category term="Research"/>
    <summary>OpenAI researchers are testing “confessions,” a method that trains models to admit when they make mistakes or act undesirably, helping improve AI honesty, transparency, and trust in model outputs.</summary>
  </entry>
  <entry>
    <title>Early experiments in accelerating science with GPT-5</title>
    <id>3a40213ef23ea9cb083d60f173b66831</id>
    <link href="https://openai.com/index/accelerating-science-gpt-5/"/>
    <updated>2025-11-20T00:00:00+00:00</updated>
    <category term="Research"/>
    <summary>OpenAI introduces the first research cases showing how GPT-5 accelerates scientific progress across math, physics, biology, and computer science. Explore how AI and researchers collaborate to generate proofs, uncover new insights, and reshape the pace of discovery.</summary>
  </entry>
  <entry>
    <title>GPT-5.1-Codex-Max System Card</title>
    <id>87486d1e9b976754ee6cf23212d14dc7</id>
    <link href="https://openai.com/index/gpt-5-1-codex-max-system-card/"/>
    <updated>2025-11-19T00:00:00+00:00</updated>
    <category term="Publication"/>
    <summary>This system card outlines the comprehensive safety measures implemented for GPT‑5.1-CodexMax. It details both model-level mitigations, such as specialized safety training for harmful tasks and prompt injections, and product-level mitigations like agent sandboxing and configurable network access.</summary>
  </entry>
  <entry>
    <title>Building more with GPT-5.1-Codex-Max</title>
    <id>49046311c4be2fcb23f716f2a199926d</id>
    <link href="https://openai.com/index/gpt-5-1-codex-max/"/>
    <updated>2025-11-19T00:00:00+00:00</updated>
    <category term="Product"/>
    <summary>Introducing GPT-5.1-Codex-Max, a faster, more intelligent agentic coding model for Codex. The model is designed for long-running, project-scale work with enhanced reasoning and token efficiency.</summary>
  </entry>
  <entry>
    <title>Understanding neural networks through sparse circuits</title>
    <id>76786030386ff19d3670fbfb28012430</id>
    <link href="https://openai.com/index/understanding-neural-networks-through-sparse-circuits/"/>
    <updated>2025-11-13T10:00:00+00:00</updated>
    <category term="Research"/>
    <summary>OpenAI is exploring mechanistic interpretability to understand how neural networks reason. Our new sparse model approach could make AI systems more transparent and support safer, more reliable behavior.</summary>
  </entry>
  <entry>
    <title>GPT-5.1: A smarter, more conversational ChatGPT</title>
    <id>c3387415a5e1df503bd503201d90ecaa</id>
    <link href="https://openai.com/index/gpt-5-1/"/>
    <updated>2025-11-12T00:00:00+00:00</updated>
    <category term="Product"/>
    <summary>We’re upgrading the GPT-5 series with warmer, more capable models and new ways to customize ChatGPT’s tone and style. GPT-5.1 starts rolling out today to paid users.</summary>
  </entry>
  <entry>
    <title>GPT-5.1 Instant and GPT-5.1 Thinking System Card Addendum</title>
    <id>a37acfed24a908a166f997aceb9fcb06</id>
    <link href="https://openai.com/index/gpt-5-system-card-addendum-gpt-5-1/"/>
    <updated>2025-11-12T00:00:00+00:00</updated>
    <category term="Publication"/>
    <summary>This GPT-5 system card addendum provides updated safety metrics for GPT-5.1 Instant and Thinking, including new evaluations for mental health and emotional reliance.</summary>
  </entry>
  <entry>
    <title>Introducing IndQA</title>
    <id>f76988be9f427fe14d5d5feaf1f5ef98</id>
    <link href="https://openai.com/index/introducing-indqa/"/>
    <updated>2025-11-03T22:30:00+00:00</updated>
    <category term="Research"/>
    <summary>OpenAI introduces IndQA, a new benchmark for evaluating AI systems in Indian languages. Built with domain experts, IndQA tests cultural understanding and reasoning across 12 languages and 10 knowledge areas.</summary>
  </entry>
  <entry>
    <title>Introducing Aardvark: OpenAI’s agentic security researcher</title>
    <id>005c42f69c4969517b32b0b141cec5ab</id>
    <link href="https://openai.com/index/introducing-aardvark/"/>
    <updated>2025-10-30T11:00:00+00:00</updated>
    <category term="Research"/>
    <summary>OpenAI introduces Aardvark, an AI-powered security researcher that autonomously finds, validates, and helps fix software vulnerabilities at scale. The system is in private beta—sign up to join early testing.</summary>
  </entry>
</feed>
