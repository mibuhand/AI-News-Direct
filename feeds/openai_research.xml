<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Openai Research</title>
  <id>tag:ai-news-direct.local,2025:openai_research</id>
  <icon>https://openai.com/favicon.ico</icon>
  <logo>https://openai.com/favicon.ico</logo>
  <updated>2025-11-01T09:21:17.936923+00:00</updated>
  <author>
    <name>AI News Direct</name>
  </author>
  <link href="https://raw.githubusercontent.com/mibuhand/AI-News-Direct/main/feeds/openai_research.xml" rel="self"/>
  <entry>
    <title>Technical Report: Performance and baseline evaluations of gpt-oss-safeguard-120b</title>
    <id>954f63c357c5dc716c95f20c1fc7d84f</id>
    <link href="https://openai.com/index/gpt-oss-safeguard-technical-report/"/>
    <updated>2025-10-29T00:00:00+00:00</updated>
    <category term="Safety"/>
    <summary>and gpt-oss-safeguard-20bgpt-oss-safeguard-120b and gpt-oss-safeguard-20b are two open-weight reasoning models post-trained from the gpt-oss models and trained to reason from a provided policy in order to label content under that policy. In this report, we describe gpt-oss-safeguard’s capabilities and provide our baseline safety evaluations on the gpt-oss-safeguard models, using the underlying gpt-oss models as a baseline. For more information about the development and architecture of the underlying gpt-oss models, see the original gpt-oss model model card⁠.</summary>
  </entry>
  <entry>
    <title>Introducing gpt-oss-safeguard</title>
    <id>3601f3ad341eb27939506c0f5e361225</id>
    <link href="https://openai.com/index/introducing-gpt-oss-safeguard/"/>
    <updated>2025-10-29T00:00:00+00:00</updated>
    <category term="Product"/>
    <summary>OpenAI introduces gpt-oss-safeguard—open-weight reasoning models for safety classification that let developers apply and iterate on custom policies.</summary>
  </entry>
  <entry>
    <title>Addendum to GPT-5 System Card: Sensitive conversations</title>
    <id>2fad364d831037ee94c4b914d2314855</id>
    <link href="https://openai.com/index/gpt-5-system-card-sensitive-conversations/"/>
    <updated>2025-10-27T10:00:00+00:00</updated>
    <category term="Safety"/>
    <summary>This system card details GPT-5’s improvements in handling sensitive conversations, including new benchmarks for emotional reliance, mental health, and jailbreak resistance.</summary>
  </entry>
  <entry>
    <title>Defining and evaluating political bias in LLMs</title>
    <id>d1962a3e021e8e22e6986ad0c3c73d35</id>
    <link href="https://openai.com/index/defining-and-evaluating-political-bias-in-llms/"/>
    <updated>2025-10-09T13:00:00+00:00</updated>
    <category term="Research"/>
    <summary>Learn how OpenAI evaluates political bias in ChatGPT through new real-world testing methods that improve objectivity and reduce bias.</summary>
  </entry>
  <entry>
    <title>Codex is now generally available</title>
    <id>ce22613b413df56e8aef16bec72be34e</id>
    <link href="https://openai.com/index/codex-now-generally-available/"/>
    <updated>2025-10-06T10:50:00+00:00</updated>
    <category term="Product"/>
    <summary>OpenAI Codex is now generally available with powerful new features for developers: a Slack integration, Codex SDK, and admin tools like usage dashboards and workspace management—making Codex easier to use and manage at scale.</summary>
  </entry>
  <entry>
    <title>Sora 2 System Card</title>
    <id>2a0868a53977d4037f6e3c736298134c</id>
    <link href="https://openai.com/index/sora-2-system-card/"/>
    <updated>2025-09-30T00:00:00+00:00</updated>
    <category term="Publication"/>
    <summary>Sora 2 is our new state of the art video and audio generation model. Building on the foundation of Sora, this new model introduces capabilities that have been difficult for prior video models to achieve– such as more accurate physics, sharper realism, synchronized audio, enhanced steerability, and an expanded stylistic range.</summary>
  </entry>
  <entry>
    <title>Sora 2 is here</title>
    <id>46e9bb4fd850bff9a07c7ca3f6ae5e2d</id>
    <link href="https://openai.com/index/sora-2/"/>
    <updated>2025-09-30T00:00:00+00:00</updated>
    <category term="Research"/>
    <summary>Our latest video generation model is more physically accurate, realistic, and controllable than prior systems. It also features synchronized dialogue and sound effects. Create with it in the new Sora app.</summary>
  </entry>
  <entry>
    <title>Measuring the performance of our models on real-world tasks</title>
    <id>26670c67b9bec0773a4f12068a53a83e</id>
    <link href="https://openai.com/index/gdpval/"/>
    <updated>2025-09-25T09:00:00+00:00</updated>
    <category term="Publication"/>
    <summary>OpenAI introduces GDPval, a new evaluation that measures model performance on real-world economically valuable tasks across 44 occupations.</summary>
  </entry>
  <entry>
    <title>Detecting and reducing scheming in AI models</title>
    <id>aca4dbe0bbebe47c36d11f5a4710396a</id>
    <link href="https://openai.com/index/detecting-and-reducing-scheming-in-ai-models/"/>
    <updated>2025-09-17T00:00:00+00:00</updated>
    <category term="Publication"/>
    <summary>Apollo Research and OpenAI developed evaluations for hidden misalignment (“scheming”) and found behaviors consistent with scheming in controlled tests across frontier models. The team shared concrete examples and stress tests of an early method to reduce scheming.</summary>
  </entry>
</feed>
