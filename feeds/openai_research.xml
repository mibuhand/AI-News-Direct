<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Openai Research</title>
  <id>tag:ai-news-direct.local,2025:openai_research</id>
  <icon>https://openai.com/favicon.ico</icon>
  <logo>https://openai.com/favicon.ico</logo>
  <updated>2025-11-11T09:27:13.291044+00:00</updated>
  <author>
    <name>AI News Direct</name>
  </author>
  <link href="https://raw.githubusercontent.com/mibuhand/AI-News-Direct/main/feeds/openai_research.xml" rel="self"/>
  <entry>
    <title>Introducing IndQA</title>
    <id>f76988be9f427fe14d5d5feaf1f5ef98</id>
    <link href="https://openai.com/index/introducing-indqa/"/>
    <updated>2025-11-03T22:30:00+00:00</updated>
    <category term="Research"/>
    <summary>OpenAI introduces IndQA, a new benchmark for evaluating AI systems in Indian languages. Built with domain experts, IndQA tests cultural understanding and reasoning across 12 languages and 10 knowledge areas.</summary>
  </entry>
  <entry>
    <title>Introducing Aardvark: OpenAI’s agentic security researcher</title>
    <id>005c42f69c4969517b32b0b141cec5ab</id>
    <link href="https://openai.com/index/introducing-aardvark/"/>
    <updated>2025-10-30T11:00:00+00:00</updated>
    <category term="Research"/>
    <summary>OpenAI introduces Aardvark, an AI-powered security researcher that autonomously finds, validates, and helps fix software vulnerabilities at scale. The system is in private beta—sign up to join early testing.</summary>
  </entry>
  <entry>
    <title>Technical Report: Performance and baseline evaluations of gpt-oss-safeguard-120b</title>
    <id>954f63c357c5dc716c95f20c1fc7d84f</id>
    <link href="https://openai.com/index/gpt-oss-safeguard-technical-report/"/>
    <updated>2025-10-29T00:00:00+00:00</updated>
    <category term="Safety"/>
    <summary>and gpt-oss-safeguard-20bgpt-oss-safeguard-120b and gpt-oss-safeguard-20b are two open-weight reasoning models post-trained from the gpt-oss models and trained to reason from a provided policy in order to label content under that policy. In this report, we describe gpt-oss-safeguard’s capabilities and provide our baseline safety evaluations on the gpt-oss-safeguard models, using the underlying gpt-oss models as a baseline. For more information about the development and architecture of the underlying gpt-oss models, see the original gpt-oss model model card⁠.</summary>
  </entry>
  <entry>
    <title>Introducing gpt-oss-safeguard</title>
    <id>3601f3ad341eb27939506c0f5e361225</id>
    <link href="https://openai.com/index/introducing-gpt-oss-safeguard/"/>
    <updated>2025-10-29T00:00:00+00:00</updated>
    <category term="Product"/>
    <summary>OpenAI introduces gpt-oss-safeguard—open-weight reasoning models for safety classification that let developers apply and iterate on custom policies.</summary>
  </entry>
  <entry>
    <title>Addendum to GPT-5 System Card: Sensitive conversations</title>
    <id>2fad364d831037ee94c4b914d2314855</id>
    <link href="https://openai.com/index/gpt-5-system-card-sensitive-conversations/"/>
    <updated>2025-10-27T10:00:00+00:00</updated>
    <category term="Safety"/>
    <summary>This system card details GPT-5’s improvements in handling sensitive conversations, including new benchmarks for emotional reliance, mental health, and jailbreak resistance.</summary>
  </entry>
  <entry>
    <title>Defining and evaluating political bias in LLMs</title>
    <id>d1962a3e021e8e22e6986ad0c3c73d35</id>
    <link href="https://openai.com/index/defining-and-evaluating-political-bias-in-llms/"/>
    <updated>2025-10-09T13:00:00+00:00</updated>
    <category term="Research"/>
    <summary>Learn how OpenAI evaluates political bias in ChatGPT through new real-world testing methods that improve objectivity and reduce bias.</summary>
  </entry>
  <entry>
    <title>Codex is now generally available</title>
    <id>ce22613b413df56e8aef16bec72be34e</id>
    <link href="https://openai.com/index/codex-now-generally-available/"/>
    <updated>2025-10-06T10:50:00+00:00</updated>
    <category term="Product"/>
    <summary>OpenAI Codex is now generally available with powerful new features for developers: a Slack integration, Codex SDK, and admin tools like usage dashboards and workspace management—making Codex easier to use and manage at scale.</summary>
  </entry>
  <entry>
    <title>Sora 2 System Card</title>
    <id>2a0868a53977d4037f6e3c736298134c</id>
    <link href="https://openai.com/index/sora-2-system-card/"/>
    <updated>2025-09-30T00:00:00+00:00</updated>
    <category term="Publication"/>
    <summary>Sora 2 is our new state of the art video and audio generation model. Building on the foundation of Sora, this new model introduces capabilities that have been difficult for prior video models to achieve– such as more accurate physics, sharper realism, synchronized audio, enhanced steerability, and an expanded stylistic range.</summary>
  </entry>
  <entry>
    <title>Sora 2 is here</title>
    <id>46e9bb4fd850bff9a07c7ca3f6ae5e2d</id>
    <link href="https://openai.com/index/sora-2/"/>
    <updated>2025-09-30T00:00:00+00:00</updated>
    <category term="Research"/>
    <summary>Our latest video generation model is more physically accurate, realistic, and controllable than prior systems. It also features synchronized dialogue and sound effects. Create with it in the new Sora app.</summary>
  </entry>
</feed>
