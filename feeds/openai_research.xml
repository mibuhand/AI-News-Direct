<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Openai Research</title>
  <id>tag:ai-news-direct.local,2025:openai_research</id>
  <icon>https://openai.com/favicon.ico</icon>
  <logo>https://openai.com/favicon.ico</logo>
  <updated>2025-09-02T21:16:16.104072+00:00</updated>
  <author>
    <name>AI News Direct</name>
  </author>
  <link href="https://openai.com/research/index/feeds/openai_research.xml" rel="self"/>
  <entry>
    <title>Introducing gpt-realtime and Realtime API updates</title>
    <id>3f0ab7de2e55ab99133e58a0f29f1f45</id>
    <link href="https://openai.com/index/introducing-gpt-realtime/"/>
    <updated>2025-08-28T10:00:00+00:00</updated>
    <category term="Product"/>
    <summary>We’re releasing a more advanced speech-to-speech model and new API capabilities including MCP server support, image input, and SIP phone calling support.</summary>
  </entry>
  <entry>
    <title>Collective alignment: public input on our Model Spec</title>
    <id>225a3fcfb3b1946607f9b85ee634c057</id>
    <link href="https://openai.com/index/collective-alignment-aug-2025-updates/"/>
    <updated>2025-08-27T13:00:00+00:00</updated>
    <category term="Publication"/>
    <summary>OpenAI surveyed over 1,000 people worldwide on how AI should behave and compared their views to our Model Spec. Learn how collective alignment is shaping AI defaults to better reflect diverse human values and perspectives.</summary>
  </entry>
  <entry>
    <title>Accelerating life sciences research</title>
    <id>404e303b8b1839a41e95b2bd60757c63</id>
    <link href="https://openai.com/index/accelerating-life-sciences-research-with-retro-biosciences/"/>
    <updated>2025-08-22T08:30:00+00:00</updated>
    <category term="Publication"/>
    <summary>Discover how a specialized AI model, GPT-4b micro, helped OpenAI and Retro Bio engineer more effective proteins for stem cell therapy and longevity research.</summary>
  </entry>
  <entry>
    <title>From hard refusals to safe-completions: toward output-centric safety training</title>
    <id>99a9f530b7f2a56994e9558be653852f</id>
    <link href="https://openai.com/index/gpt-5-safe-completions/"/>
    <updated>2025-08-07T00:00:00+00:00</updated>
    <category term="Safety"/>
    <summary>Discover how OpenAI's new safe-completions approach in GPT-5 improves both safety and helpfulness in AI responses—moving beyond hard refusals to nuanced, output-centric safety training for handling dual-use prompts.</summary>
  </entry>
  <entry>
    <title>GPT-5 System Card</title>
    <id>72949d96db2dc231b2b0557c5bbccb0a</id>
    <link href="https://openai.com/index/gpt-5-system-card/"/>
    <updated>2025-08-07T00:00:00+00:00</updated>
    <category term="Publication"/>
    <summary>This GPT-5 system card explains how a unified model routing system powers fast and smart responses using gpt-5-main, gpt-5-thinking, and lightweight versions like gpt-5-thinking-nano, optimized for different tasks and developer use.</summary>
  </entry>
  <entry>
    <title>Introducing GPT-5</title>
    <id>998c84220a4d5ea101223a2375550679</id>
    <link href="https://openai.com/index/introducing-gpt-5/"/>
    <updated>2025-08-07T00:00:00+00:00</updated>
    <category term="Release"/>
    <summary>We are introducing GPT‑5, our best AI system yet. GPT‑5 is a significant leap in intelligence over all our previous models, featuring state-of-the-art performance across coding, math, writing, health, visual perception, and more.</summary>
  </entry>
  <entry>
    <title>Estimating worst case frontier risks of open weight LLMs</title>
    <id>b9bcb4b71556787bcf276b10204b300b</id>
    <link href="https://openai.com/index/estimating-worst-case-frontier-risks-of-open-weight-llms/"/>
    <updated>2025-08-05T00:00:00+00:00</updated>
    <category term="Safety"/>
    <summary>In this paper, we study the worst-case frontier risks of releasing gpt-oss. We introduce malicious fine-tuning (MFT), where we attempt to elicit maximum capabilities by fine-tuning gpt-oss to be as capable as possible in two domains: biology and cybersecurity.</summary>
  </entry>
  <entry>
    <title>gpt-oss-120b &amp; gpt-oss-20b Model Card</title>
    <id>62626f2b2a5452b587709d31e9c2d252</id>
    <link href="https://openai.com/index/gpt-oss-model-card/"/>
    <updated>2025-08-05T00:00:00+00:00</updated>
    <category term="Publication"/>
    <summary>We introduce gpt-oss-120b and gpt-oss-20b, two open-weight reasoning models available under the Apache 2.0 license and our gpt-oss usage policy.</summary>
  </entry>
  <entry>
    <title>Introducing gpt-oss</title>
    <id>94ac6af5adb14e0682d02d2b7d329f69</id>
    <link href="https://openai.com/index/introducing-gpt-oss/"/>
    <updated>2025-08-05T00:00:00+00:00</updated>
    <category term="Release"/>
    <summary>We’re releasing gpt-oss-120b and gpt-oss-20b—two state-of-the-art open-weight language models that deliver strong real-world performance at low cost. Available under the flexible Apache 2.0 license, these models outperform similarly sized open models on reasoning tasks, demonstrate strong tool use capabilities, and are optimized for efficient deployment on consumer hardware.</summary>
  </entry>
</feed>
