<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Anthropic News</title>
  <id>tag:ai-news-direct.local,2025:anthropic_aggregated</id>
  <link href="https://www.anthropic.com/feed/anthropic_aggregated.xml" rel="self"/>
  <icon>https://www.anthropic.com/favicon.ico</icon>
  <logo>https://www.anthropic.com/favicon.ico</logo>
  <updated>2025-07-27T03:40:18.030448+00:00</updated>
  <author>
    <name>AI News Direct</name>
  </author>
  <entry>
    <title>Anthropic to sign the EU Code of Practice</title>
    <id>9c6814aa5ad8771a4b782ad661a59959</id>
    <link href="https://www.anthropic.com/news/eu-code-practice"/>
    <updated>2025-07-21T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Paul Smith to join Anthropic as Chief Commercial Officer</title>
    <id>0eb8bd61db291ac1c698d8f79737d98b</id>
    <link href="https://www.anthropic.com/news/paul-smith-to-join-anthropic"/>
    <updated>2025-07-15T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Anthropic and the Department of Defense to advance responsible AI in defense operations</title>
    <id>46629fce1176873c699e6a4df1553787</id>
    <link href="https://www.anthropic.com/news/anthropic-and-the-department-of-defense-to-advance-responsible-ai-in-defense-operations"/>
    <updated>2025-07-14T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Project Vend: Can Claude run a small shop? (And why does that matter?)</title>
    <id>9688f0a21ac3ae079ba2cfe0bdd55749</id>
    <link href="https://www.anthropic.com/research/project-vend-1"/>
    <updated>2025-06-27T06:05:00+00:00</updated>
    <category term="Policy"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>Desktop Extensions: One-click MCP server installation for Claude Desktop</title>
    <id>51caa23a7033fd0bffba0a614c3bbe19</id>
    <link href="https://www.anthropic.com/engineering/desktop-extensions"/>
    <updated>2025-06-26T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (engineering)</summary>
  </entry>
  <entry>
    <title>Agentic Misalignment: How LLMs could be insider threats</title>
    <id>141153d9c830e689fb408e655ade95f0</id>
    <link href="https://www.anthropic.com/research/agentic-misalignment"/>
    <updated>2025-06-20T22:30:00+00:00</updated>
    <category term="Alignment"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>Confidential Inference via Trusted Virtual Machines</title>
    <id>ec8b697add66c774aecf4a43503c7ecf</id>
    <link href="https://www.anthropic.com/research/confidential-inference-trusted-vms"/>
    <updated>2025-06-18T13:27:00+00:00</updated>
    <category term="Announcements"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>SHADE-Arena: Evaluating sabotage and monitoring in LLM agents</title>
    <id>133edbb581215c0ea40a0e3d66e0817c</id>
    <link href="https://www.anthropic.com/research/shade-arena-sabotage-monitoring"/>
    <updated>2025-06-16T20:20:00+00:00</updated>
    <category term="Alignment"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>How we built our multi-agent research system</title>
    <id>b069c769822fc938d3d55318ea3f2d4c</id>
    <link href="https://www.anthropic.com/engineering/built-multi-agent-research-system"/>
    <updated>2025-06-13T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (engineering)</summary>
  </entry>
  <entry>
    <title>National security expert Richard Fontaine appointed to Anthropic’s long-term benefit trust</title>
    <id>523ba8d352cfd891c01ef16cdcadd755</id>
    <link href="https://www.anthropic.com/news/national-security-expert-richard-fontaine-appointed-to-anthropic-s-long-term-benefit-trust"/>
    <updated>2025-06-07T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Open-sourcing circuit tracing tools</title>
    <id>a87867f678cff6c1a79d065d6d923194</id>
    <link href="https://www.anthropic.com/research/open-source-circuit-tracing"/>
    <updated>2025-05-29T12:13:00+00:00</updated>
    <category term="Interpretability"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>Reed Hastings appointed to Anthropic’s board of directors</title>
    <id>0a1e358ba0c764f81ac393318cce56e9</id>
    <link href="https://www.anthropic.com/news/reed-hastings"/>
    <updated>2025-05-28T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>New capabilities for building agents on the Anthropic API</title>
    <id>e7782d14f332ca4ab3aa213a97facd93</id>
    <link href="https://www.anthropic.com/news/agent-capabilities-api"/>
    <updated>2025-05-22T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Anthropic Economic Index: AIâs impact on software development</title>
    <id>44dcf4df758bf55b49879de5ce638418</id>
    <link href="https://www.anthropic.com/research/impact-software-development"/>
    <updated>2025-04-28T09:36:00+00:00</updated>
    <category term="Societal Impacts"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>[HuggingFace] published a dataset</title>
    <id>aabc700736e4a91d10b812a087166928</id>
    <link href="https://huggingface.co/huggingface_anthropic"/>
    <updated>2025-04-27T03:38:34.751733+00:00</updated>
    <summary>huggingface_anthropic: published a dataset | Organization: huggingface_anthropic | Source: Anthropic Aggregated (activity) | Action: published a dataset | Related: Anthropic/values-in-the-wild</summary>
  </entry>
  <entry>
    <title>[HuggingFace] updated a dataset</title>
    <id>45899004014fcf49ff9cf560d550e331</id>
    <link href="https://huggingface.co/huggingface_anthropic"/>
    <updated>2025-04-27T03:38:34.751733+00:00</updated>
    <summary>huggingface_anthropic: updated a dataset | Organization: huggingface_anthropic | Source: Anthropic Aggregated (activity) | Action: updated a dataset | Related: Anthropic/values-in-the-wild</summary>
  </entry>
  <entry>
    <title>Exploring model welfare</title>
    <id>4e17075ddeded00589b7596b112c439d</id>
    <link href="https://www.anthropic.com/research/exploring-model-welfare"/>
    <updated>2025-04-24T10:59:00+00:00</updated>
    <category term="Alignment"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>Values in the wild: Discovering and analyzing values in real-world language model interactions</title>
    <id>bd4fc0fd335e2de5ca88162f048c8782</id>
    <link href="https://www.anthropic.com/research/values-wild"/>
    <updated>2025-04-21T11:50:00+00:00</updated>
    <category term="Societal Impacts"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>Claude Code: Best practices for agentic coding</title>
    <id>435743e6aca86798b6f507808adad396</id>
    <link href="https://www.anthropic.com/engineering/claude-code-best-practices"/>
    <updated>2025-04-18T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (engineering)</summary>
  </entry>
  <entry>
    <title>Claude takes research to new places</title>
    <id>a5f0958215646b3754781d198580cd56</id>
    <link href="https://www.anthropic.com/news/research"/>
    <updated>2025-04-15T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Anthropic Education Report: How university students use Claude</title>
    <id>1475016ec3ebb26e283128200dca68d9</id>
    <link href="https://www.anthropic.com/research/anthropic-education-report-how-university-students-use-claude"/>
    <updated>2025-04-08T15:00:00+00:00</updated>
    <category term="Announcements"/>
    <category term="Societal Impacts"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>Anthropic appoints Guillaume Princen as Head of EMEA and announces 100+ new roles across the region</title>
    <id>2db849761b7e46ec539ac124ffae6caa</id>
    <link href="https://www.anthropic.com/news/head-of-EMEA-new-roles"/>
    <updated>2025-04-08T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Reasoning models don't always say what they think</title>
    <id>30da1224fd786cf54978f4da5abad41e</id>
    <link href="https://www.anthropic.com/research/reasoning-models-dont-say-think"/>
    <updated>2025-04-03T14:32:00+00:00</updated>
    <category term="Alignment"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>Introducing Anthropic's first developer conference: Code with Claude</title>
    <id>a1c5fe2db2dddfb6b4ab6a46008858ee</id>
    <link href="https://www.anthropic.com/news/Introducing-code-with-claude"/>
    <updated>2025-04-03T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Anthropic Economic Index: Insights from Claude 3.7 Sonnet</title>
    <id>f38ffbe1db3ead38649bbf81389e1a55</id>
    <link href="https://www.anthropic.com/research/anthropic-economic-index-insights-from-claude-sonnet-3-7"/>
    <updated>2025-03-27T21:00:00+00:00</updated>
    <category term="Announcements"/>
    <category term="Societal Impacts"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>Tracing the thoughts of a large language model</title>
    <id>1dbcbbb35b503949d42a38c05c57bf3b</id>
    <link href="https://www.anthropic.com/research/tracing-thoughts-language-model"/>
    <updated>2025-03-27T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>The &quot;think&quot; tool: Enabling Claude to stop and think in complex tool use situations</title>
    <id>20d5e1508810c8c3fddb936ddd5935df</id>
    <link href="https://www.anthropic.com/engineering/claude-think-tool"/>
    <updated>2025-03-20T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (engineering)</summary>
  </entry>
  <entry>
    <title>Progress from our Frontier Red Team</title>
    <id>c78f4e9a7e70e2fd0ca878e9a4d5d5bd</id>
    <link href="https://www.anthropic.com/news/strategic-warning-for-ai-risk-progress-and-insights-from-our-frontier-red-team"/>
    <updated>2025-03-19T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Auditing language models for hidden objectives</title>
    <id>1081b411767a719b9508b2015ccdd1d9</id>
    <link href="https://www.anthropic.com/research/auditing-hidden-objectives"/>
    <updated>2025-03-13T16:00:00+00:00</updated>
    <category term="Alignment"/>
    <category term="Interpretability"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>Anthropic partners with U.S. National Labs for first 1,000 Scientist AI Jam</title>
    <id>082095a155325f9215430980421db0b8</id>
    <link href="https://www.anthropic.com/news/anthropic-partners-with-u-s-national-labs-for-first-1-000-scientist-ai-jam"/>
    <updated>2025-02-28T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Introducing Anthropic's Transparency Hub</title>
    <id>c7bd4df81015e14de6f1ae11c8d5beee</id>
    <link href="https://www.anthropic.com/news/introducing-anthropic-transparency-hub"/>
    <updated>2025-02-27T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Claude and Alexa+</title>
    <id>71d0627b336739ccadcac224d9cf54ea</id>
    <link href="https://www.anthropic.com/news/claude-and-alexa-plus"/>
    <updated>2025-02-26T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Forecasting rare language model behaviors</title>
    <id>e62a649d0883f0275eb3f460e6383dda</id>
    <link href="https://www.anthropic.com/research/forecasting-rare-behaviors"/>
    <updated>2025-02-25T20:17:00+00:00</updated>
    <category term="Alignment"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>Claudeâs extended thinking</title>
    <id>596e0640adc504df40e1eec75875d9de</id>
    <link href="https://www.anthropic.com/research/visible-extended-thinking"/>
    <updated>2025-02-24T14:38:00+00:00</updated>
    <category term="Announcements"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>Insights on Crosscoder Model Diffing</title>
    <id>42914ebe87bfbc1f47e67bc36e0c3a58</id>
    <link href="https://www.anthropic.com/research/crosscoder-model-diffing"/>
    <updated>2025-02-20T23:50:00+00:00</updated>
    <category term="Interpretability"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>Statement from Dario Amodei on the Paris AI Action Summit</title>
    <id>f8e8d44b751584fecb7dbca55f50a2b2</id>
    <link href="https://www.anthropic.com/news/paris-ai-summit"/>
    <updated>2025-02-11T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>The Anthropic Economic Index</title>
    <id>5ec185859cc74b8293c4ce8f312f48f6</id>
    <link href="https://www.anthropic.com/research/the-anthropic-economic-index"/>
    <updated>2025-02-10T13:00:00+00:00</updated>
    <category term="Announcements"/>
    <category term="Societal Impacts"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>Lyft to bring Claude to more than 40 million riders and over 1 million drivers</title>
    <id>f65e8c74f074be83feff5815a02d06b0</id>
    <link href="https://www.anthropic.com/news/lyft-announcement"/>
    <updated>2025-02-06T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Constitutional Classifiers: Defending against universal jailbreaks</title>
    <id>4d7f5867c140495f3e612b0c0dba2295</id>
    <link href="https://www.anthropic.com/research/constitutional-classifiers"/>
    <updated>2025-02-03T12:35:00+00:00</updated>
    <category term="Alignment"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>Introducing Citations on the Anthropic API</title>
    <id>ca22acfae9634b48cd23f4a8584a97db</id>
    <link href="https://www.anthropic.com/news/introducing-citations-api"/>
    <updated>2025-01-23T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Anthropic achieves ISO 42001 certification for responsible AI</title>
    <id>43ca928aabb2f7a0771cf6f8f959f878</id>
    <link href="https://www.anthropic.com/news/anthropic-achieves-iso-42001-certification-for-responsible-ai"/>
    <updated>2025-01-13T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Raising the bar on SWE-bench Verified with Claude 3.5 Sonnet</title>
    <id>5f81d6387ad1a5593752c16513a252c8</id>
    <link href="https://www.anthropic.com/engineering/swe-bench-sonnet"/>
    <updated>2025-01-06T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (engineering)</summary>
  </entry>
  <entry>
    <title>Building effective agents</title>
    <id>d8598e0c2d724836244acef020ea7e35</id>
    <link href="https://www.anthropic.com/research/building-effective-agents"/>
    <updated>2024-12-19T21:14:00+00:00</updated>
    <category term="Product"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>Building effective agents</title>
    <id>c46cc36bd21e399c23e8b40d912e0d50</id>
    <link href="https://www.anthropic.com/engineering/building-effective-agents"/>
    <updated>2024-12-19T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (engineering)</summary>
  </entry>
  <entry>
    <title>Alignment faking in large language models</title>
    <id>8e0b86c6b2e3d799758436bf41efb00f</id>
    <link href="https://www.anthropic.com/research/alignment-faking"/>
    <updated>2024-12-18T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Clio: A system for privacy-preserving insights into real-world AI use</title>
    <id>2cc555fc3d8556785dfe946c0cf6e65f</id>
    <link href="https://www.anthropic.com/research/clio"/>
    <updated>2024-12-12T13:08:00+00:00</updated>
    <category term="Societal Impacts"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>Elections and AI in 2024: observations and learnings</title>
    <id>5478e9cd2b36e732540e5c04d1609a72</id>
    <link href="https://www.anthropic.com/news/elections-ai-2024"/>
    <updated>2024-12-12T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Claude 3.5 Haiku on AWS Trainium2 and model distillation in Amazon Bedrock</title>
    <id>954725de15daa8573bb359d7eafd8438</id>
    <link href="https://www.anthropic.com/news/trainium2-and-distillation"/>
    <updated>2024-12-03T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Tailor Claude’s responses to your personal style</title>
    <id>1ee33a8d07ec13518baebd25c7c88e0f</id>
    <link href="https://www.anthropic.com/news/styles"/>
    <updated>2024-11-26T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Introducing the Model Context Protocol</title>
    <id>008ed75d22d18705a55670be7991f82f</id>
    <link href="https://www.anthropic.com/news/model-context-protocol"/>
    <updated>2024-11-25T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Powering the next generation of AI development with AWS</title>
    <id>36ec9d80b0bbabf71831c51fa06ef882</id>
    <link href="https://www.anthropic.com/news/anthropic-amazon-trainium"/>
    <updated>2024-11-22T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>A statistical approach to model evaluations</title>
    <id>008d3efc3583b39aa5dc94aa2584ef02</id>
    <link href="https://www.anthropic.com/research/statistical-approach-to-model-evals"/>
    <updated>2024-11-19T16:11:00+00:00</updated>
    <category term="Evaluations"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>Improve your prompts in the developer console</title>
    <id>6ec7a45f40458eb0247a1d1e066de8c4</id>
    <link href="https://www.anthropic.com/news/prompt-improver"/>
    <updated>2024-11-14T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>The case for targeted regulation</title>
    <id>2b4067a483b6e1c3ee56ac1be7c5b148</id>
    <link href="https://www.anthropic.com/news/the-case-for-targeted-regulation"/>
    <updated>2024-10-31T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Raising the bar on SWE-bench Verified with Claude 3.5 Sonnet</title>
    <id>b82bbaef9cd4911f50e40e88af1bd792</id>
    <link href="https://www.anthropic.com/research/swe-bench-sonnet"/>
    <updated>2024-10-30T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Claude 3.5 Sonnet on GitHub Copilot</title>
    <id>3e8747e1980280223efb7e74ee11dce2</id>
    <link href="https://www.anthropic.com/news/github-copilot"/>
    <updated>2024-10-29T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Evaluating feature steering: A case study in mitigating social biases</title>
    <id>6aef985a567ce674e82a0c1a98b60bf7</id>
    <link href="https://www.anthropic.com/research/evaluating-feature-steering"/>
    <updated>2024-10-25T13:42:00+00:00</updated>
    <category term="Societal Impacts"/>
    <category term="Interpretability"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>Introducing the analysis tool in Claude.ai</title>
    <id>1420dad87baba6c3fba6eb3468d88e9f</id>
    <link href="https://www.anthropic.com/news/analysis-tool"/>
    <updated>2024-10-24T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Developing a computer use model</title>
    <id>ddb112757419d8b04d0b5b3c6134c628</id>
    <link href="https://www.anthropic.com/research/developing-computer-use"/>
    <updated>2024-10-22T19:42:00+00:00</updated>
    <category term="Announcements"/>
    <category term="Product"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>Developing a computer use model</title>
    <id>2f319d2cd818f437152544e53c96a248</id>
    <link href="https://www.anthropic.com/news/developing-computer-use"/>
    <updated>2024-10-22T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Sabotage evaluations for frontier models</title>
    <id>3e1df9a38d75078fb92842ef2cf230dd</id>
    <link href="https://www.anthropic.com/research/sabotage-evaluations"/>
    <updated>2024-10-18T16:55:00+00:00</updated>
    <category term="Alignment"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>Using dictionary learning features as classifiers</title>
    <id>9395cc2a266696cd77ea966e514cba23</id>
    <link href="https://www.anthropic.com/research/features-as-classifiers"/>
    <updated>2024-10-16T23:49:00+00:00</updated>
    <category term="Interpretability"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>Announcing our updated Responsible Scaling Policy</title>
    <id>6e3f4a447ac94e5cd7b0b7c119c814c0</id>
    <link href="https://www.anthropic.com/news/announcing-our-updated-responsible-scaling-policy"/>
    <updated>2024-10-15T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Introducing the Message Batches API</title>
    <id>b886d525e141aab2eaa611c30560a60b</id>
    <link href="https://www.anthropic.com/news/message-batches-api"/>
    <updated>2024-10-08T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>U.S. Elections Readiness</title>
    <id>df2c692bf1bca1f672377bb1865e77a6</id>
    <link href="https://www.anthropic.com/news/us-elections-readiness"/>
    <updated>2024-10-08T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Circuits Updates â September 2024</title>
    <id>e1990ff2e1e62f797efc2806bba386ad</id>
    <link href="https://www.anthropic.com/research/circuits-updates-sept-2024"/>
    <updated>2024-10-01T09:38:00+00:00</updated>
    <category term="Interpretability"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>Fine-tuning for Claude 3 Haiku in Amazon Bedrock is now generally available</title>
    <id>9d3ef059a14b7c17886285ad7e936c86</id>
    <link href="https://www.anthropic.com/news/fine-tune-claude-3-haiku-ga"/>
    <updated>2024-09-23T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Introducing Contextual Retrieval</title>
    <id>2f5b72bbcaf81830d0313876a7f0e674</id>
    <link href="https://www.anthropic.com/news/contextual-retrieval"/>
    <updated>2024-09-19T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Introducing Contextual Retrieval</title>
    <id>8c7b5cb54b3672ac0bd694e6a59768c7</id>
    <link href="https://www.anthropic.com/engineering/contextual-retrieval"/>
    <updated>2024-09-19T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (engineering)</summary>
  </entry>
  <entry>
    <title>Workspaces in the Anthropic API Console</title>
    <id>0e0deab96e7340bb42c49f894a8cb7ec</id>
    <link href="https://www.anthropic.com/news/workspaces"/>
    <updated>2024-09-10T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Circuits Updates â August 2024</title>
    <id>6f3882fa35d3822206b94859b7cbfeac</id>
    <link href="https://www.anthropic.com/research/circuits-updates-august-2024"/>
    <updated>2024-09-06T15:36:00+00:00</updated>
    <category term="Interpretability"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>Claude for Enterprise</title>
    <id>c21624c82efc031bda46b49173ffd9cf</id>
    <link href="https://www.anthropic.com/news/claude-for-enterprise"/>
    <updated>2024-09-04T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Salesforce teams up with Anthropic to enhance Einstein capabilities with Claude</title>
    <id>2a3f4c425e40412d99d5825f1273805e</id>
    <link href="https://www.anthropic.com/news/salesforce-partnership"/>
    <updated>2024-09-03T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Artifacts are now generally available</title>
    <id>92716c49896f2bcc7f624653852c97f7</id>
    <link href="https://www.anthropic.com/news/artifacts"/>
    <updated>2024-08-27T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Prompt caching with Claude</title>
    <id>ef1dcc0efe39c1a90b50c68e8c965dad</id>
    <link href="https://www.anthropic.com/news/prompt-caching"/>
    <updated>2024-08-14T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Expanding our model safety bug bounty program</title>
    <id>6d74d1305504f75736c98189ae8fa587</id>
    <link href="https://www.anthropic.com/news/model-safety-bug-bounty"/>
    <updated>2024-08-08T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Claude is now available in Brazil</title>
    <id>fdff11d04e66473df6ff95e8c7d05e0f</id>
    <link href="https://www.anthropic.com/news/claude-brazil"/>
    <updated>2024-08-01T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Circuits Updates â July 2024</title>
    <id>0145e2d50a81bae879f80f1f6e5cbd00</id>
    <link href="https://www.anthropic.com/research/circuits-updates-july-2024"/>
    <updated>2024-07-31T19:21:00+00:00</updated>
    <category term="Interpretability"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>[HuggingFace] authored a paper</title>
    <id>944a11dfdf8ad7293fba3d535d3b47ac</id>
    <link href="https://huggingface.co/huggingface_anthropic"/>
    <updated>2024-07-27T03:38:34.751733+00:00</updated>
    <summary>huggingface_anthropic: authored a paper | Organization: huggingface_anthropic | Source: Anthropic Aggregated (activity) | Action: authored a paper | Related: Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training</summary>
  </entry>
  <entry>
    <title>Anthropic partners with Menlo Ventures to launch Anthology Fund</title>
    <id>d9f6282f2ec25811d959489440bfed2f</id>
    <link href="https://www.anthropic.com/news/anthropic-partners-with-menlo-ventures-to-launch-anthology-fund"/>
    <updated>2024-07-17T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Claude Android app</title>
    <id>734125ba52c697dfabc692f2c75f62ab</id>
    <link href="https://www.anthropic.com/news/android-app"/>
    <updated>2024-07-16T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Fine-tune Claude 3 Haiku in Amazon Bedrock</title>
    <id>d9ce27de893597f180a1276f991cd4dc</id>
    <link href="https://www.anthropic.com/news/fine-tune-claude-3-haiku"/>
    <updated>2024-07-11T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Evaluate prompts in the developer console</title>
    <id>b6be1aaddcca83152515b197b61cef13</id>
    <link href="https://www.anthropic.com/news/evaluate-prompts"/>
    <updated>2024-07-09T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>A new initiative for developing third-party model evaluations</title>
    <id>72ed3fde1dc17b925a50b153b0e01f5c</id>
    <link href="https://www.anthropic.com/news/a-new-initiative-for-developing-third-party-model-evaluations"/>
    <updated>2024-07-01T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Circuits Updates â June 2024</title>
    <id>cfe4b7f2706195ff8b11d98c8eacf293</id>
    <link href="https://www.anthropic.com/research/circuits-updates-june-2024"/>
    <updated>2024-06-28T21:43:09.349000+00:00</updated>
    <category term="Interpretability"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>Expanding access to Claude for government</title>
    <id>6349c25247f3e10bd2715a718c16861c</id>
    <link href="https://www.anthropic.com/news/expanding-access-to-claude-for-government"/>
    <updated>2024-06-26T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Collaborate with Claude on Projects</title>
    <id>6e1127162ac7c04dd26c93299e333e2d</id>
    <link href="https://www.anthropic.com/news/projects"/>
    <updated>2024-06-25T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Claude 3.5 Sonnet</title>
    <id>1aec74aee408ead8955d4d2ad6dee45c</id>
    <link href="https://www.anthropic.com/news/claude-3-5-sonnet"/>
    <updated>2024-06-21T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Sycophancy to subterfuge: Investigating reward tampering in language models </title>
    <id>91ce6e1642b8295e72d306c7591a51ba</id>
    <link href="https://www.anthropic.com/research/reward-tampering"/>
    <updated>2024-06-17T13:10:48.322000+00:00</updated>
    <category term="Alignment"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>The engineering challenges of scaling interpretability</title>
    <id>cdda5186385b7d9ea99a5e3013d757eb</id>
    <link href="https://www.anthropic.com/research/engineering-challenges-interpretability"/>
    <updated>2024-06-13T08:00:00+00:00</updated>
    <category term="Interpretability"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>Challenges in red teaming AI systems</title>
    <id>0c171ab710003a52aedffcec5c265c5e</id>
    <link href="https://www.anthropic.com/news/challenges-in-red-teaming-ai-systems"/>
    <updated>2024-06-12T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Claudeâs Character</title>
    <id>64e84a950a3b0d0c3987f7745ff602e5</id>
    <link href="https://www.anthropic.com/research/claude-character"/>
    <updated>2024-06-08T18:27:00+00:00</updated>
    <category term="Alignment"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>Testing and mitigating elections-related risks</title>
    <id>752a7fe7abdea2f7c331381fca628ad7</id>
    <link href="https://www.anthropic.com/research/testing-and-mitigating-elections-related-risks"/>
    <updated>2024-06-06T13:00:00+00:00</updated>
    <category term="Policy"/>
    <category term="Societal Impacts"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>Testing and mitigating elections-related risks</title>
    <id>719de6a37bfedba8eb5672f18c291250</id>
    <link href="https://www.anthropic.com/news/testing-and-mitigating-elections-related-risks"/>
    <updated>2024-06-06T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Introducing Claude to Canada</title>
    <id>d6b349924e49585c8539e4a2c6a9207a</id>
    <link href="https://www.anthropic.com/news/introducing-claude-to-canada"/>
    <updated>2024-06-05T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Claude can now use tools</title>
    <id>a4e78482bc1c3cd84ba54c33cc246701</id>
    <link href="https://www.anthropic.com/news/tool-use-ga"/>
    <updated>2024-05-30T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Jay Kreps appointed to Anthropic's Board of Directors</title>
    <id>5118591317cdb74feee978d721214fb8</id>
    <link href="https://www.anthropic.com/news/jay-kreps-appointed-to-board-of-directors"/>
    <updated>2024-05-29T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Golden Gate Claude</title>
    <id>112b5dc8c2f32dcf0eeddbbbcd8f82ea</id>
    <link href="https://www.anthropic.com/news/golden-gate-claude"/>
    <updated>2024-05-23T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Krishna Rao joins Anthropic as Chief Financial Officer</title>
    <id>4142f3015428dc984b5deb11f5e7441c</id>
    <link href="https://www.anthropic.com/news/krishna-rao-joins-anthropic"/>
    <updated>2024-05-21T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Mapping the Mind of a Large Language Model</title>
    <id>19b23d2b3b811de532002f91bdc8c4bd</id>
    <link href="https://www.anthropic.com/research/mapping-mind-language-model"/>
    <updated>2024-05-21T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Reflections on our Responsible Scaling Policy</title>
    <id>06c712b8844293ef1d0323bef8485e0b</id>
    <link href="https://www.anthropic.com/news/reflections-on-our-responsible-scaling-policy"/>
    <updated>2024-05-20T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Generate better prompts in the developer console</title>
    <id>934d88660a680a53bd669c3b61e979ce</id>
    <link href="https://www.anthropic.com/news/prompt-generator"/>
    <updated>2024-05-20T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Mike Krieger joins Anthropic as Chief Product Officer</title>
    <id>5489758ef954b9dcabe3e478b1450edb</id>
    <link href="https://www.anthropic.com/news/mike-krieger-joins-anthropic"/>
    <updated>2024-05-15T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Claude is now available in Europe</title>
    <id>0890727f24ada8fa3ac93e2ea5f307d2</id>
    <link href="https://www.anthropic.com/news/claude-europe"/>
    <updated>2024-05-14T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Updating our Usage Policy</title>
    <id>c2257cfc0e456aa5a170b3ee5b4b0736</id>
    <link href="https://www.anthropic.com/news/updating-our-usage-policy"/>
    <updated>2024-05-10T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Introducing the Claude Team plan and iOS app</title>
    <id>a16eeaa639fcf6c714e90ae05733c12d</id>
    <link href="https://www.anthropic.com/news/team-plan-and-ios"/>
    <updated>2024-05-01T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Circuits Updates â April 2024</title>
    <id>fd74138b532062fb4d918fafbd3d7bcf</id>
    <link href="https://www.anthropic.com/research/circuits-updates-april-2024"/>
    <updated>2024-04-26T20:24:00+00:00</updated>
    <category term="Interpretability"/>
    <category term="Research"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>Simple probes can catch sleeper agents</title>
    <id>ae0341058e456fe2ab3cd5af930ab646</id>
    <link href="https://www.anthropic.com/research/probes-catch-sleeper-agents"/>
    <updated>2024-04-23T09:42:44.093000+00:00</updated>
    <category term="Alignment"/>
    <category term="Interpretability"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>Aligning on child safety principles</title>
    <id>4de77b79174a25c49c2cd28bfb1f72f8</id>
    <link href="https://www.anthropic.com/news/child-safety-principles"/>
    <updated>2024-04-23T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Measuring the Persuasiveness of Language Models</title>
    <id>2e78ab925d81248768883b69c834d31c</id>
    <link href="https://www.anthropic.com/research/measuring-model-persuasiveness"/>
    <updated>2024-04-09T15:55:00+00:00</updated>
    <category term="Societal Impacts"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>Many-shot jailbreaking</title>
    <id>54e52f4eae66945a1849075e48955a26</id>
    <link href="https://www.anthropic.com/research/many-shot-jailbreaking"/>
    <updated>2024-04-02T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Third-party testing as a key ingredient of AI policy</title>
    <id>3f6ac047022e68c7fef9ef71ef8260fc</id>
    <link href="https://www.anthropic.com/news/third-party-testing"/>
    <updated>2024-03-25T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Anthropic, AWS, and Accenture team up to build trusted solutions for enterprises</title>
    <id>1e196ab552e49a349f8597f3b9236e66</id>
    <link href="https://www.anthropic.com/news/accenture-aws-anthropic"/>
    <updated>2024-03-20T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Claude 3 models on Vertex AI</title>
    <id>c3ce6cd998f55c3a2505291f917c7af7</id>
    <link href="https://www.anthropic.com/news/google-vertex-general-availability"/>
    <updated>2024-03-19T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Claude 3 Haiku: our fastest model yet</title>
    <id>14f325d6a83fa2e1dded3dacd768d631</id>
    <link href="https://www.anthropic.com/news/claude-3-haiku"/>
    <updated>2024-03-13T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Reflections on Qualitative Research</title>
    <id>c5e1470c7d22299cee9b38f14e2265c7</id>
    <link href="https://www.anthropic.com/research/transformer-circuits"/>
    <updated>2024-03-08T16:00:00+00:00</updated>
    <category term="Interpretability"/>
    <category term="Research"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>Introducing the next generation of Claude</title>
    <id>9f60c5bbfd1574458a828cbaea21c497</id>
    <link href="https://www.anthropic.com/news/claude-3-family"/>
    <updated>2024-03-04T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Prompt engineering for business performance</title>
    <id>7ab3d5568359c20bb246d002fa2498f9</id>
    <link href="https://www.anthropic.com/news/prompt-engineering-for-business-performance"/>
    <updated>2024-02-29T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Preparing for global elections in 2024</title>
    <id>2e25f1ba794ba182d9d5099a7755a955</id>
    <link href="https://www.anthropic.com/news/preparing-for-global-elections-in-2024"/>
    <updated>2024-02-16T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training</title>
    <id>83135a999d160b60c0d80531be84bcbc</id>
    <link href="https://www.anthropic.com/research/sleeper-agents-training-deceptive-llms-that-persist-through-safety-training"/>
    <updated>2024-01-14T22:10:00+00:00</updated>
    <category term="Alignment"/>
    <category term="Research"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>Expanded legal protections and improvements to our API</title>
    <id>f2293c26a905f42ddf3c5957a5345c89</id>
    <link href="https://www.anthropic.com/news/expanded-legal-protections-api-improvements"/>
    <updated>2023-12-19T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Evaluating and Mitigating Discrimination in Language Model Decisions</title>
    <id>baa0deea62abf51059585fa024d3f124</id>
    <link href="https://www.anthropic.com/research/evaluating-and-mitigating-discrimination-in-language-model-decisions"/>
    <updated>2023-12-07T08:50:00+00:00</updated>
    <category term="Societal Impacts"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>Long context prompting for Claude 2.1</title>
    <id>632ec432d3c1df5c7e4d4ec2864acdd4</id>
    <link href="https://www.anthropic.com/news/claude-2-1-prompting"/>
    <updated>2023-12-06T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Introducing Claude 2.1</title>
    <id>dce224e99ebe9a001ca09a3c3615fd21</id>
    <link href="https://www.anthropic.com/news/claude-2-1"/>
    <updated>2023-11-21T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Thoughts on the US Executive Order, G7 Code of Conduct, and Bletchley Park Summit</title>
    <id>43f61d863496231f3ea1669bca7e0324</id>
    <link href="https://www.anthropic.com/news/policy-recap-q4-2023"/>
    <updated>2023-11-05T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Dario Amodei’s prepared remarks from the AI Safety Summit on Anthropic’s Responsible Scaling Policy</title>
    <id>c717389b6c1974a5b129e13f9e487379</id>
    <link href="https://www.anthropic.com/news/uk-ai-safety-summit"/>
    <updated>2023-11-01T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Specific versus General Principles for Constitutional AI</title>
    <id>fdc20c21bf4e802f0f53420e5bf98598</id>
    <link href="https://www.anthropic.com/research/specific-versus-general-principles-for-constitutional-ai"/>
    <updated>2023-10-24T09:07:00+00:00</updated>
    <category term="Alignment"/>
    <category term="Research"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>Towards Understanding Sycophancy in Language Models</title>
    <id>5b53ab55afb0c374ebf133d8f6b0033e</id>
    <link href="https://www.anthropic.com/research/towards-understanding-sycophancy-in-language-models"/>
    <updated>2023-10-23T11:57:00+00:00</updated>
    <category term="Alignment"/>
    <category term="Research"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>Collective Constitutional AI: Aligning a Language Model with Public Input</title>
    <id>232c6ae6f1410565f28f1da4ff43625f</id>
    <link href="https://www.anthropic.com/research/collective-constitutional-ai-aligning-a-language-model-with-public-input"/>
    <updated>2023-10-17T00:00:00+00:00</updated>
    <category term="Policy"/>
    <category term="Societal Impacts"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>Towards Monosemanticity: Decomposing Language Models With Dictionary Learning</title>
    <id>01f9fb8859e1043216b8cfb678ccf770</id>
    <link href="https://www.anthropic.com/research/towards-monosemanticity-decomposing-language-models-with-dictionary-learning"/>
    <updated>2023-10-05T00:00:00+00:00</updated>
    <category term="Interpretability"/>
    <category term="Research"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>Decomposing Language Models Into Understandable Components</title>
    <id>427bf5b6881b571233d6e11e3bd406e0</id>
    <link href="https://www.anthropic.com/research/decomposing-language-models-into-understandable-components"/>
    <updated>2023-10-05T00:00:00+00:00</updated>
    <category term="Interpretability"/>
    <category term="Research"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>Challenges in evaluating AI systems</title>
    <id>78c61f9a7504eefcb3ed9551fb64a63d</id>
    <link href="https://www.anthropic.com/research/evaluating-ai-systems"/>
    <updated>2023-10-04T07:00:00+00:00</updated>
    <category term="Policy"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>Claude on Amazon Bedrock now available to every AWS customer</title>
    <id>b51719d61c210a8a8f79f63b998a7a3b</id>
    <link href="https://www.anthropic.com/news/amazon-bedrock-general-availability"/>
    <updated>2023-09-28T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Expanding access to safer AI with Amazon</title>
    <id>b9881568daca09d98144d8cd08422a25</id>
    <link href="https://www.anthropic.com/news/anthropic-amazon"/>
    <updated>2023-09-25T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Prompt engineering for Claude's long context window</title>
    <id>252c7b0f5b4dc0fd2fad2ebd669a463a</id>
    <link href="https://www.anthropic.com/news/prompting-long-context"/>
    <updated>2023-09-23T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Anthropic's Responsible Scaling Policy</title>
    <id>ee3abdb74b51889f2d21db5406f5a863</id>
    <link href="https://www.anthropic.com/news/anthropics-responsible-scaling-policy"/>
    <updated>2023-09-19T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>The Long-Term Benefit Trust</title>
    <id>f41d4233ea14521a61911cce7c0ae118</id>
    <link href="https://www.anthropic.com/news/the-long-term-benefit-trust"/>
    <updated>2023-09-19T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Anthropic partners with BCG</title>
    <id>95ee035084db54736218ad6dfeaf28f5</id>
    <link href="https://www.anthropic.com/news/anthropic-bcg"/>
    <updated>2023-09-14T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Introducing Claude Pro</title>
    <id>da9828030d1935283052ca5387595656</id>
    <link href="https://www.anthropic.com/news/claude-pro"/>
    <updated>2023-09-07T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Claude 2 on Amazon Bedrock</title>
    <id>c75d90f74b8299b9728555dd126a8d08</id>
    <link href="https://www.anthropic.com/news/claude-2-amazon-bedrock"/>
    <updated>2023-08-23T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>SKT Partnership Announcement</title>
    <id>d510faf60625eeac0d9d45d2bae7b823</id>
    <link href="https://www.anthropic.com/news/skt-partnership-announcement"/>
    <updated>2023-08-15T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Releasing Claude Instant 1.2</title>
    <id>d2a477057666aa6236f8800b7b299102</id>
    <link href="https://www.anthropic.com/news/releasing-claude-instant-1-2"/>
    <updated>2023-08-09T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Studying Large Language Model Generalization with Influence Functions</title>
    <id>b9db13ac93790ffcfa4ffd47a32fb066</id>
    <link href="https://www.anthropic.com/research/studying-large-language-model-generalization-with-influence-functions"/>
    <updated>2023-08-08T00:00:00+00:00</updated>
    <category term="Alignment"/>
    <category term="Research"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>Tracing Model Outputs to the Training Data</title>
    <id>119c9cfbd7889f0e289b85bc618ba1a0</id>
    <link href="https://www.anthropic.com/research/influence-functions"/>
    <updated>2023-08-08T00:00:00+00:00</updated>
    <category term="Alignment"/>
    <category term="Research"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>[HuggingFace] authored 3 papers</title>
    <id>a98f262c8a93d7ab1bac8c20afed8a5d</id>
    <link href="https://huggingface.co/huggingface_anthropic"/>
    <updated>2023-07-27T03:38:34.751733+00:00</updated>
    <summary>huggingface_anthropic: authored 3 papers | Organization: huggingface_anthropic | Source: Anthropic Aggregated (activity) | Action: authored 3 papers | Related: Specific versus General Principles for Constitutional AI, Towards Understanding Sycophancy in Language Models, Measuring Faithfulness in Chain-of-Thought Reasoning</summary>
  </entry>
  <entry>
    <title>Frontier Threats Red Teaming for AI Safety</title>
    <id>513d985aee2fb6be1dea8689a5644a8c</id>
    <link href="https://www.anthropic.com/news/frontier-threats-red-teaming-for-ai-safety"/>
    <updated>2023-07-26T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Frontier Model Security</title>
    <id>be75099157fffc3f0a5d9694d37bc276</id>
    <link href="https://www.anthropic.com/news/frontier-model-security"/>
    <updated>2023-07-25T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Question Decomposition Improves the Faithfulness of Model-Generated Reasoning</title>
    <id>d7921fb9672d1635e1003165d5373bb3</id>
    <link href="https://www.anthropic.com/research/question-decomposition-improves-the-faithfulness-of-model-generated-reasoning"/>
    <updated>2023-07-18T00:00:00+00:00</updated>
    <category term="Alignment"/>
    <category term="Research"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>Measuring Faithfulness in Chain-of-Thought Reasoning</title>
    <id>5b5851ece8cc5ff3203317151a85a0e9</id>
    <link href="https://www.anthropic.com/research/measuring-faithfulness-in-chain-of-thought-reasoning"/>
    <updated>2023-07-18T00:00:00+00:00</updated>
    <category term="Alignment"/>
    <category term="Research"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>Claude 2</title>
    <id>10c4e5b25ecd8df39241f19933188bec</id>
    <link href="https://www.anthropic.com/news/claude-2"/>
    <updated>2023-07-11T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Towards Measuring the Representation of Subjective Global Opinions in Language Models</title>
    <id>197bad1eed70f713fd65f52179689cef</id>
    <link href="https://www.anthropic.com/research/towards-measuring-the-representation-of-subjective-global-opinions-in-language-models"/>
    <updated>2023-06-29T00:00:00+00:00</updated>
    <category term="Societal Impacts"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>Charting a Path to AI Accountability</title>
    <id>40b2cc1fcd1c1baa58673af794be18b6</id>
    <link href="https://www.anthropic.com/news/charting-a-path-to-ai-accountability"/>
    <updated>2023-06-13T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Circuits Updates â May 2023</title>
    <id>09076c81fea2d749e704670ff251bea6</id>
    <link href="https://www.anthropic.com/research/circuits-updates-may-2023"/>
    <updated>2023-05-24T00:00:00+00:00</updated>
    <category term="Interpretability"/>
    <category term="Research"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>Interpretability Dreams</title>
    <id>4bcec845342f4fbccfc629cd6b485035</id>
    <link href="https://www.anthropic.com/research/interpretability-dreams"/>
    <updated>2023-05-24T00:00:00+00:00</updated>
    <category term="Interpretability"/>
    <category term="Research"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>Anthropic Raises $450 Million in Series C Funding to Scale Reliable AI Products</title>
    <id>3f7d3b23c26da625108d8e6abcd4bc63</id>
    <link href="https://www.anthropic.com/news/anthropic-series-c"/>
    <updated>2023-05-23T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Zoom Partnership and Investment in Anthropic</title>
    <id>fba2fe38143dd345853162c364e35fb0</id>
    <link href="https://www.anthropic.com/news/zoom-partnership-and-investment"/>
    <updated>2023-05-16T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Introducing 100K Context Windows</title>
    <id>0d0d63c668e3a5e3c21cc43837ed086d</id>
    <link href="https://www.anthropic.com/news/100k-context-windows"/>
    <updated>2023-05-11T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Claude’s Constitution</title>
    <id>f09a33eeda695434cdd41176c7843df9</id>
    <link href="https://www.anthropic.com/news/claudes-constitution"/>
    <updated>2023-05-09T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Distributed Representations: Composition &amp; Superposition</title>
    <id>d97a64136ed5bb8e5054adcbfcd307eb</id>
    <link href="https://www.anthropic.com/research/distributed-representations-composition-superposition"/>
    <updated>2023-05-04T00:00:00+00:00</updated>
    <category term="Interpretability"/>
    <category term="Research"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>Partnering with Scale to Bring Generative AI to Enterprises</title>
    <id>72394450b2620708c402e75f6d5bd0f5</id>
    <link href="https://www.anthropic.com/news/partnering-with-scale"/>
    <updated>2023-04-26T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>An AI Policy Tool for Today: Ambitiously Invest in NIST</title>
    <id>4c1d5b1bc2f6b5a34977acee2f348578</id>
    <link href="https://www.anthropic.com/news/an-ai-policy-tool-for-today-ambitiously-invest-in-nist"/>
    <updated>2023-04-20T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Claude, now in Slack</title>
    <id>0d03cf89d6e6a822a3e007685b3a8b49</id>
    <link href="https://www.anthropic.com/news/claude-now-in-slack"/>
    <updated>2023-03-30T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Privileged Bases in the Transformer Residual Stream</title>
    <id>c7f6ba54cee93310f41907eb186fae31</id>
    <link href="https://www.anthropic.com/research/privileged-bases-in-the-transformer-residual-stream"/>
    <updated>2023-03-16T00:00:00+00:00</updated>
    <category term="Interpretability"/>
    <category term="Research"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>Introducing Claude</title>
    <id>df28d04969ee526e43907657a82dfb55</id>
    <link href="https://www.anthropic.com/news/introducing-claude"/>
    <updated>2023-03-14T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>The Capacity for Moral Self-Correction in Large Language Models</title>
    <id>8ad10c54cd8e85a2683522ca3de5bd20</id>
    <link href="https://www.anthropic.com/research/the-capacity-for-moral-self-correction-in-large-language-models"/>
    <updated>2023-02-15T00:00:00+00:00</updated>
    <category term="Societal Impacts"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>Anthropic Partners with Google Cloud</title>
    <id>0d6070c26e11504a674938d073ad79f6</id>
    <link href="https://www.anthropic.com/news/anthropic-partners-with-google-cloud"/>
    <updated>2023-02-03T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Superposition, Memorization, and Double Descent</title>
    <id>f49a05c28c27763d987b4a8809573679</id>
    <link href="https://www.anthropic.com/research/superposition-memorization-and-double-descent"/>
    <updated>2023-01-05T00:00:00+00:00</updated>
    <category term="Interpretability"/>
    <category term="Research"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>Discovering Language Model Behaviors with Model-Written Evaluations</title>
    <id>8b0cd14c5cd39df5bc2897fff197461e</id>
    <link href="https://www.anthropic.com/research/discovering-language-model-behaviors-with-model-written-evaluations"/>
    <updated>2022-12-19T00:00:00+00:00</updated>
    <category term="Alignment"/>
    <category term="Research"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>Constitutional AI: Harmlessness from AI Feedback</title>
    <id>486ef73c11ad0d0b3ed5dbb24afbf3f8</id>
    <link href="https://www.anthropic.com/research/constitutional-ai-harmlessness-from-ai-feedback"/>
    <updated>2022-12-15T00:00:00+00:00</updated>
    <category term="Alignment"/>
    <category term="Research"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>Measuring Progress on Scalable Oversight for Large Language Models</title>
    <id>d11b50801e8e3cf370a26ce50bb428ce</id>
    <link href="https://www.anthropic.com/research/measuring-progress-on-scalable-oversight-for-large-language-models"/>
    <updated>2022-11-04T00:00:00+00:00</updated>
    <category term="Alignment"/>
    <category term="Research"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>Toy Models of Superposition</title>
    <id>f9b2638b9be95a06f0861c57ed27a6e9</id>
    <link href="https://www.anthropic.com/research/toy-models-of-superposition"/>
    <updated>2022-09-14T00:00:00+00:00</updated>
    <category term="Interpretability"/>
    <category term="Research"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>Red Teaming Language Models to Reduce Harms: Methods, Scaling Behaviors, and Lessons Learned</title>
    <id>78e9dbb51835769eb2ec44bc3b76b0db</id>
    <link href="https://www.anthropic.com/research/red-teaming-language-models-to-reduce-harms-methods-scaling-behaviors-and-lessons-learned"/>
    <updated>2022-08-22T00:00:00+00:00</updated>
    <category term="Societal Impacts"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>Language Models (Mostly) Know What They Know</title>
    <id>d4d2d598733cd1027fa19571fcc3a80f</id>
    <link href="https://www.anthropic.com/research/language-models-mostly-know-what-they-know"/>
    <updated>2022-07-11T00:00:00+00:00</updated>
    <category term="Alignment"/>
    <category term="Research"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>Softmax Linear Units</title>
    <id>99fc2b6026431b15d4d2aa293aad758a</id>
    <link href="https://www.anthropic.com/research/softmax-linear-units"/>
    <updated>2022-06-17T00:00:00+00:00</updated>
    <category term="Interpretability"/>
    <category term="Research"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>Scaling Laws and Interpretability of Learning from Repeated Data</title>
    <id>8765edac320eb650dfb67ec8438e0c0c</id>
    <link href="https://www.anthropic.com/research/scaling-laws-and-interpretability-of-learning-from-repeated-data"/>
    <updated>2022-05-21T00:00:00+00:00</updated>
    <category term="Interpretability"/>
    <category term="Research"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>Anthropic Raises Series B to build steerable, interpretable, robust AI systems</title>
    <id>c2abfd4333704d774f1c3d2be1f83122</id>
    <link href="https://www.anthropic.com/news/anthropic-raises-series-b-to-build-safe-reliable-ai"/>
    <updated>2022-04-29T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
  <entry>
    <title>Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback</title>
    <id>765072b76e2cb7c97d6a116eefae1240</id>
    <link href="https://www.anthropic.com/research/training-a-helpful-and-harmless-assistant-with-reinforcement-learning-from-human-feedback"/>
    <updated>2022-04-12T00:00:00+00:00</updated>
    <category term="Alignment"/>
    <category term="Research"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>In-context Learning and Induction Heads</title>
    <id>6d9985f2bc568aa9ffe5bdf566319097</id>
    <link href="https://www.anthropic.com/research/in-context-learning-and-induction-heads"/>
    <updated>2022-03-08T00:00:00+00:00</updated>
    <category term="Interpretability"/>
    <category term="Research"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>Predictability and Surprise in Large Generative Models</title>
    <id>48f7e904c6cc0f77f1c26b39e9fb5a8c</id>
    <link href="https://www.anthropic.com/research/predictability-and-surprise-in-large-generative-models"/>
    <updated>2022-02-15T00:00:00+00:00</updated>
    <category term="Societal Impacts"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>A Mathematical Framework for Transformer Circuits</title>
    <id>9762c39ccc99dfc1d7fe710fc66fc677</id>
    <link href="https://www.anthropic.com/research/a-mathematical-framework-for-transformer-circuits"/>
    <updated>2021-12-22T00:00:00+00:00</updated>
    <category term="Interpretability"/>
    <category term="Research"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>A General Language Assistant as a Laboratory for Alignment</title>
    <id>e159f8eda2f59a6398e6fb085171906a</id>
    <link href="https://www.anthropic.com/research/a-general-language-assistant-as-a-laboratory-for-alignment"/>
    <updated>2021-12-01T00:00:00+00:00</updated>
    <category term="Alignment"/>
    <category term="Research"/>
    <summary>Organization: Anthropic | Source: Anthropic (research)</summary>
  </entry>
  <entry>
    <title>Anthropic raises $124 million to build more reliable, general AI systems</title>
    <id>56177962c084f416a8c82e20c7dc9186</id>
    <link href="https://www.anthropic.com/news/anthropic-raises-124-million-to-build-more-reliable-general-ai-systems"/>
    <updated>2021-05-28T00:00:00+00:00</updated>
    <summary>Organization: Anthropic | Source: Anthropic (news)</summary>
  </entry>
</feed>
