<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Huggingface Daily Papers</title>
  <id>tag:ai-news-direct.local,2025:huggingface_daily_papers</id>
  <icon>https://huggingface.co/favicon.ico</icon>
  <logo>https://huggingface.co/favicon.ico</logo>
  <updated>2025-10-21T09:25:39.191829+00:00</updated>
  <author>
    <name>AI News Direct</name>
  </author>
  <link href="https://raw.githubusercontent.com/mibuhand/AI-News-Direct/main/feeds/huggingface_daily_papers.xml" rel="self"/>
  <entry>
    <title>The Dragon Hatchling: The Missing Link between the Transformer and
  Models of the Brain</title>
    <id>7a9ae43171e964d5b9a58c9a76f8c373</id>
    <link href="https://arxiv.org/abs/2509.26507"/>
    <updated>2025-09-30T12:49:01+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>The relationship between computing systems and the brain has served as
motivation for pioneering theoreticians since John von Neumann and Alan Turing.
Uniform, scale-free biological networks, such as ...&lt;br/&gt;Upvotes: 494&lt;br/&gt;GitHub Stars: 3129&lt;br/&gt;Authors: Adrian Kosowski, PrzemysÅ‚aw UznaÅ„ski, Jan Chorowski&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/pathwaycom/bdh&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2509.26507&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>Less is More: Recursive Reasoning with Tiny Networks</title>
    <id>3d55a02b14bdc7a04256ce32475eb075</id>
    <link href="https://arxiv.org/abs/2510.04871"/>
    <updated>2025-10-06T10:58:08+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>Hierarchical Reasoning Model (HRM) is a novel approach using two small neural
networks recursing at different frequencies. This biologically inspired method
beats Large Language models (LLMs) on hard ...&lt;br/&gt;Upvotes: 417&lt;br/&gt;GitHub Stars: 4978&lt;br/&gt;Authors: Alexia Jolicoeur-Martineau&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/SamsungSAILMontreal/TinyRecursiveModels&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://alexiajm.github.io/2025/09/29/tiny_recursive_models.html#&quot;&gt;Project Page&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2510.04871&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>Agent Learning via Early Experience</title>
    <id>b5eadc2228eda785fe3e8da98ea25174</id>
    <link href="https://arxiv.org/abs/2510.08558"/>
    <updated>2025-10-09T13:59:17+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>A long-term goal of language agents is to learn and improve through their own
experience, ultimately outperforming humans in complex, real-world tasks.
However, training agents from experience data wi...&lt;br/&gt;Upvotes: 233&lt;br/&gt;Authors: Kai Zhang, Xiangchao Chen, Bo Liu&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2510.08558&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>LongLive: Real-time Interactive Long Video Generation</title>
    <id>4618188e5babf65ab96739c065ddfd61</id>
    <link href="https://arxiv.org/abs/2509.22622"/>
    <updated>2025-09-26T13:48:24+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>We present LongLive, a frame-level autoregressive (AR) framework for
real-time and interactive long video generation. Long video generation presents
challenges in both efficiency and quality. Diffusio...&lt;br/&gt;Upvotes: 176&lt;br/&gt;GitHub Stars: 719&lt;br/&gt;Authors: Shuai Yang, Wei Huang, Ruihang Chu&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/NVlabs/LongLive&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://nvlabs.github.io/LongLive/&quot;&gt;Project Page&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2509.22622&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>MCPMark: A Benchmark for Stress-Testing Realistic and Comprehensive MCP
  Use</title>
    <id>652276de74e8a80281a665d98165228d</id>
    <link href="https://arxiv.org/abs/2509.24002"/>
    <updated>2025-09-28T13:53:27+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>MCP standardizes how LLMs interact with external systems, forming the
foundation for general agents. However, existing MCP benchmarks remain narrow
in scope: they focus on read-heavy tasks or tasks wi...&lt;br/&gt;Upvotes: 165&lt;br/&gt;GitHub Stars: 285&lt;br/&gt;Authors: Zijian Wu, Xiangyan Liu, Xinyuan Zhang&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/eval-sys/mcpmark&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://mcpmark.ai/&quot;&gt;Project Page&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2509.24002&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>QeRL: Beyond Efficiency -- Quantization-enhanced Reinforcement Learning
  for LLMs</title>
    <id>f5ecd82d2d6a90e1b4eb7c0d2afe9c3e</id>
    <link href="https://arxiv.org/abs/2510.11696"/>
    <updated>2025-10-13T13:55:09+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>We propose QeRL, a Quantization-enhanced Reinforcement Learning framework for
large language models (LLMs). While RL is essential for LLMs' reasoning
capabilities, it is resource-intensive, requiring ...&lt;br/&gt;Upvotes: 163&lt;br/&gt;GitHub Stars: 351&lt;br/&gt;Authors: Wei Huang, Yi Ge, Shuai Yang&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/NVlabs/QeRL&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/NVlabs/QeRL&quot;&gt;Project Page&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2510.11696&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>PaddleOCR-VL: Boosting Multilingual Document Parsing via a 0.9B
  Ultra-Compact Vision-Language Model</title>
    <id>d98bf11f4930fd1159bb5f90e3f76afd</id>
    <link href="https://arxiv.org/abs/2510.14528"/>
    <updated>2025-10-16T06:18:48+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>In this report, we propose PaddleOCR-VL, a SOTA and resource-efficient model
tailored for document parsing. Its core component is PaddleOCR-VL-0.9B, a
compact yet powerful vision-language model (VLM) ...&lt;br/&gt;Upvotes: 46&lt;br/&gt;GitHub Stars: 59750&lt;br/&gt;Authors: Cheng Cui, Ting Sun, Suyin Liang&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/PaddlePaddle/PaddleOCR&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2510.14528&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>MinerU2.5: A Decoupled Vision-Language Model for Efficient
  High-Resolution Document Parsing</title>
    <id>b1fe8132db01bc9650eda3e26023bc30</id>
    <link href="https://arxiv.org/abs/2509.22186"/>
    <updated>2025-09-26T06:45:48+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>We introduce MinerU2.5, a 1.2B-parameter document parsing vision-language
model that achieves state-of-the-art recognition accuracy while maintaining
exceptional computational efficiency. Our approach...&lt;br/&gt;Upvotes: 120&lt;br/&gt;GitHub Stars: 47064&lt;br/&gt;Authors: Junbo Niu, Zheng Liu, Zhuangcheng Gu&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/opendatalab/MinerU&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://opendatalab.github.io/MinerU/&quot;&gt;Project Page&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2509.22186&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>BitNet Distillation</title>
    <id>4477d6ceb0f6af4c535f87fb4c3e55f5</id>
    <link href="https://arxiv.org/abs/2510.13998"/>
    <updated>2025-10-15T14:28:12+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>In this paper, we present BitNet Distillation (BitDistill), a lightweight
pipeline that fine-tunes off-the-shelf full-precision LLMs (e.g., Qwen) into
1.58-bit precision (i.e., ternary weights {-1, 0,...&lt;br/&gt;Upvotes: 44&lt;br/&gt;GitHub Stars: 24267&lt;br/&gt;Authors: Xun Wu, Shaohan Huang, Wenhui Wang&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/microsoft/BitNet&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2510.13998&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>MiniCPM-V 4.5: Cooking Efficient MLLMs via Architecture, Data, and
  Training Recipe</title>
    <id>59f26db9f2ae0d3d43973c1ffbd40568</id>
    <link href="https://arxiv.org/abs/2509.18154"/>
    <updated>2025-09-16T15:41:48+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>Multimodal Large Language Models (MLLMs) are undergoing rapid progress and
represent the frontier of AI development. However, their training and inference
efficiency have emerged as a core bottleneck ...&lt;br/&gt;Upvotes: 48&lt;br/&gt;GitHub Stars: 22099&lt;br/&gt;Authors: Tianyu Yu, Zefan Wang, Chongyi Wang&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/OpenBMB/MiniCPM-V&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2509.18154&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>JoyAgent-JDGenie: Technical Report on the GAIA</title>
    <id>2fbd109d587f03077296ef20d0d7459e</id>
    <link href="https://arxiv.org/abs/2510.00510"/>
    <updated>2025-10-01T00:41:58+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>Large Language Models are increasingly deployed as autonomous agents for
complex real-world tasks, yet existing systems often focus on isolated
improvements without a unifying design for robustness an...&lt;br/&gt;Upvotes: 3&lt;br/&gt;GitHub Stars: 10762&lt;br/&gt;Authors: Jiarun Liu, Shiyue Xu, Shangkun Liu&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/jd-opensource/joyagent-jdgenie&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2510.00510&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>RAG-Anything: All-in-One RAG Framework</title>
    <id>2431e39c5ab567b865fe3f25b69b4d35</id>
    <link href="https://arxiv.org/abs/2510.12323"/>
    <updated>2025-10-14T05:25:35+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>Retrieval-Augmented Generation (RAG) has emerged as a fundamental paradigm
for expanding Large Language Models beyond their static training limitations.
However, a critical misalignment exists between...&lt;br/&gt;Upvotes: 28&lt;br/&gt;GitHub Stars: 9065&lt;br/&gt;Authors: Zirui Guo, Xubin Ren, Lingrui Xu&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/HKUDS/RAG-Anything&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2510.12323&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
</feed>
