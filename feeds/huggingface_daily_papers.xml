<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Huggingface Daily Papers</title>
  <id>tag:ai-news-direct.local,2025:huggingface_daily_papers</id>
  <icon>https://huggingface.co/favicon.ico</icon>
  <logo>https://huggingface.co/favicon.ico</logo>
  <updated>2026-01-04T09:24:14.334321+00:00</updated>
  <author>
    <name>AI News Direct</name>
  </author>
  <link href="https://raw.githubusercontent.com/mibuhand/AI-News-Direct/main/feeds/huggingface_daily_papers.xml" rel="self"/>
  <entry>
    <title>DataFlow: An LLM-Driven Framework for Unified Data Preparation and Workflow Automation in the Era of Data-Centric AI</title>
    <id>adcafb2025f84cc88e13db2e967d246f</id>
    <link href="https://arxiv.org/abs/2512.16676"/>
    <updated>2025-12-18T10:46:15+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>The rapidly growing demand for high-quality data in Large Language Models (LLMs) has intensified the need for scalable, reliable, and semantically rich data preparation pipelines. However, current pra...&lt;br/&gt;Upvotes: 200&lt;br/&gt;GitHub Stars: 2021&lt;br/&gt;Authors: Hao Liang, Xiaochen Ma, Zhou Liu&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/OpenDCAI/DataFlow&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/OpenDCAI/DataFlow&quot;&gt;Project Page&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2512.16676&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>mHC: Manifold-Constrained Hyper-Connections</title>
    <id>2d9fe809957806c0d1ec27e6e37053aa</id>
    <link href="https://arxiv.org/abs/2512.24880"/>
    <updated>2025-12-31T09:16:26+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>Recently, studies exemplified by Hyper-Connections (HC) have extended the ubiquitous residual connection paradigm established over the past decade by expanding the residual stream width and diversifyi...&lt;br/&gt;Upvotes: 168&lt;br/&gt;Authors: Zhenda Xie, Yixuan Wei, Huanqi Cao&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2512.24880&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>Live Avatar: Streaming Real-time Audio-Driven Avatar Generation with Infinite Length</title>
    <id>bdd6e066d5b32b9c61996386576f3682</id>
    <link href="https://arxiv.org/abs/2512.04677"/>
    <updated>2025-12-04T06:11:24+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>Existing diffusion-based video generation methods are fundamentally constrained by sequential computation and long-horizon inconsistency, limiting their practical adoption in real-time, streaming audi...&lt;br/&gt;Upvotes: 167&lt;br/&gt;GitHub Stars: 1298&lt;br/&gt;Authors: Yubo Huang, Hailong Guo, Fangtai Wu&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/Alibaba-Quark/LiveAvatar&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://liveavatar.github.io/&quot;&gt;Project Page&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2512.04677&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>Kling-Omni Technical Report</title>
    <id>8328813bd23f18dae6c4e2c63c9de3c9</id>
    <link href="https://arxiv.org/abs/2512.16776"/>
    <updated>2025-12-18T12:08:12+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>We present Kling-Omni, a generalist generative framework designed to synthesize high-fidelity videos directly from multimodal visual language inputs. Adopting an end-to-end perspective, Kling-Omni bri...&lt;br/&gt;Upvotes: 163&lt;br/&gt;Authors: Kling Team, Jialu Chen, Yuanzheng Ci&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2512.16776&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>DAComp: Benchmarking Data Agents across the Full Data Intelligence Lifecycle</title>
    <id>d7ac04c5b6b75ab304cbc5a5329966c8</id>
    <link href="https://arxiv.org/abs/2512.04324"/>
    <updated>2025-12-03T18:21:28+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>Real-world enterprise data intelligence workflows encompass data engineering that turns raw sources into analytical-ready tables and data analysis that convert those tables into decision-oriented insi...&lt;br/&gt;Upvotes: 150&lt;br/&gt;GitHub Stars: 327&lt;br/&gt;Authors: Fangyu Lei, Jinxiang Meng, Yiming Huang&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/ByteDance-Seed/DAComp&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://da-comp.github.io/&quot;&gt;Project Page&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2512.04324&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>Wan-Move: Motion-controllable Video Generation via Latent Trajectory Guidance</title>
    <id>00865636816805dd176a5123d69c4b66</id>
    <link href="https://arxiv.org/abs/2512.08765"/>
    <updated>2025-12-09T11:13:55+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>We present Wan-Move, a simple and scalable framework that brings motion control to video generative models. Existing motion-controllable methods typically suffer from coarse control granularity and li...&lt;br/&gt;Upvotes: 128&lt;br/&gt;GitHub Stars: 500&lt;br/&gt;Authors: Ruihang Chu, Yefei He, Zhekai Chen&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/ali-vilab/Wan-Move&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://wan-move.github.io/&quot;&gt;Project Page&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2512.08765&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>DeepCode: Open Agentic Coding</title>
    <id>84e0c9ab3b32b3eab139bdd727fe4f8c</id>
    <link href="https://arxiv.org/abs/2512.07921"/>
    <updated>2025-12-08T11:07:13+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>Recent advances in large language models (LLMs) have given rise to powerful coding agents, making it possible for code assistants to evolve into code engineers. However, existing methods still face si...&lt;br/&gt;Upvotes: 31&lt;br/&gt;GitHub Stars: 13327&lt;br/&gt;Authors: Zongwei Li, Zhonghang Li, Zirui Guo&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/HKUDS/DeepCode&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2512.07921&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>Sharp Monocular View Synthesis in Less Than a Second</title>
    <id>b0feeb7f591514204e557e85f0c2b6ca</id>
    <link href="https://arxiv.org/abs/2512.10685"/>
    <updated>2025-12-11T09:34:11+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>We present SHARP, an approach to photorealistic view synthesis from a single image. Given a single photograph, SHARP regresses the parameters of a 3D Gaussian representation of the depicted scene. Thi...&lt;br/&gt;Upvotes: 25&lt;br/&gt;GitHub Stars: 6411&lt;br/&gt;Authors: Lars Mescheder, Wei Dong, Shiwei Li&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/apple/ml-sharp&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://apple.github.io/ml-sharp/&quot;&gt;Project Page&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2512.10685&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>TurboDiffusion: Accelerating Video Diffusion Models by 100-200 Times</title>
    <id>5bb778f47e493a1d7bcf12aaaec0e25e</id>
    <link href="https://arxiv.org/abs/2512.16093"/>
    <updated>2025-12-17T21:21:30+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>We introduce TurboDiffusion, a video generation acceleration framework that can speed up end-to-end diffusion generation by 100-200x while maintaining video quality. TurboDiffusion mainly relies on se...&lt;br/&gt;Upvotes: 90&lt;br/&gt;GitHub Stars: 2993&lt;br/&gt;Authors: Jintao Zhang, Kaiwen Zheng, Kai Jiang&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/thu-ml/TurboDiffusion&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/thu-ml/TurboDiffusion&quot;&gt;Project Page&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2512.16093&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>SAM Audio: Segment Anything in Audio</title>
    <id>1c5e2b4f68f2d0420edc475a4ac95129</id>
    <link href="https://arxiv.org/abs/2512.18099"/>
    <updated>2025-12-19T17:14:23+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>General audio source separation is a key capability for multimodal AI systems that can perceive and reason about sound. Despite substantial progress in recent years, existing separation models are eit...&lt;br/&gt;Upvotes: 21&lt;br/&gt;GitHub Stars: 2718&lt;br/&gt;Authors: Bowen Shi, Andros Tjandra, John Hoffman&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/facebookresearch/sam-audio&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://ai.meta.com/samaudio/&quot;&gt;Project Page&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2512.18099&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>Step-GUI Technical Report</title>
    <id>c5594c0f22e32e8bb34b27ab240dc8cb</id>
    <link href="https://arxiv.org/abs/2512.15431"/>
    <updated>2025-12-17T08:26:30+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>Recent advances in multimodal large language models unlock unprecedented opportunities for GUI automation. However, a fundamental challenge remains: how to efficiently acquire high-quality training da...&lt;br/&gt;Upvotes: 126&lt;br/&gt;GitHub Stars: 1812&lt;br/&gt;Authors: Haolong Yan, Jia Wang, Xin Huang&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/stepfun-ai/gelab-zero&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://opengelab.github.io/&quot;&gt;Project Page&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2512.15431&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
</feed>
