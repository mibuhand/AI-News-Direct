<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Huggingface Daily Papers</title>
  <id>tag:ai-news-direct.local,2025:huggingface_daily_papers</id>
  <icon>https://huggingface.co/favicon.ico</icon>
  <logo>https://huggingface.co/favicon.ico</logo>
  <updated>2025-11-19T09:27:23.977512+00:00</updated>
  <author>
    <name>AI News Direct</name>
  </author>
  <link href="https://raw.githubusercontent.com/mibuhand/AI-News-Direct/main/feeds/huggingface_daily_papers.xml" rel="self"/>
  <entry>
    <title>Scaling Latent Reasoning via Looped Language Models</title>
    <id>8c7bb673a7c23605ce494554bc937b12</id>
    <link href="https://arxiv.org/abs/2510.25741"/>
    <updated>2025-10-29T13:45:42+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>Modern LLMs are trained to &quot;think&quot; primarily via explicit text generation,
such as chain-of-thought (CoT), which defers reasoning to post-training and
under-leverages pre-training data. We present and...&lt;br/&gt;Upvotes: 211&lt;br/&gt;Authors: Rui-Jie Zhu, Zixuan Wang, Kai Hua&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://ouro-llm.github.io/&quot;&gt;Project Page&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2510.25741&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>Thinking with Video: Video Generation as a Promising Multimodal
  Reasoning Paradigm</title>
    <id>b81e62a9e2bd28a9fe78c760c27308b6</id>
    <link href="https://arxiv.org/abs/2511.04570"/>
    <updated>2025-11-06T12:25:23+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>&quot;Thinking with Text&quot; and &quot;Thinking with Images&quot; paradigm significantly
improve the reasoning ability of large language models (LLMs) and Vision
Language Models (VLMs). However, these paradigms have in...&lt;br/&gt;Upvotes: 191&lt;br/&gt;GitHub Stars: 188&lt;br/&gt;Authors: Jingqi Tong, Yurong Mou, Hangcheng Li&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/tongjingqi/Thinking-with-Video&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://thinking-with-video.github.io/&quot;&gt;Project Page&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2511.04570&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>Concerto: Joint 2D-3D Self-Supervised Learning Emerges Spatial
  Representations</title>
    <id>9f97533076b36bd588d78f78c4352369</id>
    <link href="https://arxiv.org/abs/2510.23607"/>
    <updated>2025-10-27T13:59:59+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>Humans learn abstract concepts through multisensory synergy, and once formed,
such representations can often be recalled from a single modality. Inspired by
this principle, we introduce Concerto, a mi...&lt;br/&gt;Upvotes: 172&lt;br/&gt;GitHub Stars: 419&lt;br/&gt;Authors: Yujia Zhang, Xiaoyang Wu, Yixing Lao&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/Pointcept/Concerto&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://pointcept.github.io/Concerto/&quot;&gt;Project Page&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2510.23607&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>Lumine: An Open Recipe for Building Generalist Agents in 3D Open Worlds</title>
    <id>4622a47084403f1652a1baac4335b4fa</id>
    <link href="https://arxiv.org/abs/2511.08892"/>
    <updated>2025-11-11T21:01:26+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>We introduce Lumine, the first open recipe for developing generalist agents capable of completing hours-long complex missions in real time within challenging 3D open-world environments. Lumine adopts ...&lt;br/&gt;Upvotes: 163&lt;br/&gt;Authors: Weihao Tan, Xiangyang Li, Yunhao Fang&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://www.lumine-ai.org/&quot;&gt;Project Page&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2511.08892&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>A Theoretical Study on Bridging Internal Probability and
  Self-Consistency for LLM Reasoning</title>
    <id>fa71d4f57dc7d25049e28fe9f9644922</id>
    <link href="https://arxiv.org/abs/2510.15444"/>
    <updated>2025-10-17T04:59:30+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>Test-time scaling seeks to improve the reasoning performance of large
language models (LLMs) by adding computational resources. A prevalent approach
within the field is sampling-based test-time scalin...&lt;br/&gt;Upvotes: 145&lt;br/&gt;GitHub Stars: 13&lt;br/&gt;Authors: Zhi Zhou, Yuhao Tan, Zenan Li&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/WNJXYK/RPC&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://wnjxyk.github.io/RPC&quot;&gt;Project Page&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2510.15444&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>MiroThinker: Pushing the Performance Boundaries of Open-Source Research Agents via Model, Context, and Interactive Scaling</title>
    <id>0a60cb0f535685cc7eb12b1b01de62bc</id>
    <link href="https://arxiv.org/abs/2511.11793"/>
    <updated>2025-11-14T13:52:07+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>We present MiroThinker v1.0, an open-source research agent designed to advance tool-augmented reasoning and information-seeking capabilities. Unlike previous agents that only scale up model size or co...&lt;br/&gt;Upvotes: 127&lt;br/&gt;GitHub Stars: 789&lt;br/&gt;Authors: MiroMind Team, Song Bai, Lidong Bing&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/MiroMindAI/MiroThinker&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://dr.miromind.ai/&quot;&gt;Project Page&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2511.11793&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>FAPO: Flawed-Aware Policy Optimization for Efficient and Reliable
  Reasoning</title>
    <id>bf88f955951ceb1c5ba0121481fe4bf5</id>
    <link href="https://arxiv.org/abs/2510.22543"/>
    <updated>2025-10-26T01:49:38+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>Reinforcement learning with verifiable rewards (RLVR) has emerged as a
promising paradigm for enhancing the reasoning capabilities of large language
models (LLMs). In this context, models explore reas...&lt;br/&gt;Upvotes: 7&lt;br/&gt;GitHub Stars: 16066&lt;br/&gt;Authors: Yuyang Ding, Chi Zhang, Juntao Li&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/volcengine/verl/tree/main/recipe/fapo&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://fapo-rl.github.io/&quot;&gt;Project Page&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2510.22543&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>UFO^3: Weaving the Digital Agent Galaxy</title>
    <id>f37a636c7cc5f515c6866d60bda27643</id>
    <link href="https://arxiv.org/abs/2511.11332"/>
    <updated>2025-11-14T09:05:31+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>Large language model (LLM)-powered agents are transforming digital devices from passive tools into proactive intelligent collaborators. However, most existing frameworks remain confined to a single OS...&lt;br/&gt;Upvotes: 17&lt;br/&gt;GitHub Stars: 7724&lt;br/&gt;Authors: Chaoyun Zhang, Liqun Li, He Huang&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/microsoft/UFO/&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://microsoft.github.io/UFO/&quot;&gt;Project Page&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2511.11332&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>Chronos-2: From Univariate to Universal Forecasting</title>
    <id>32811c5aee11a368e90161a3c41bd70b</id>
    <link href="https://arxiv.org/abs/2510.15821"/>
    <updated>2025-10-17T13:00:53+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>Pretrained time series models have enabled inference-only forecasting systems
that produce accurate predictions without task-specific training. However,
existing approaches largely focus on univariate...&lt;br/&gt;Upvotes: 19&lt;br/&gt;GitHub Stars: 4335&lt;br/&gt;Authors: Abdul Fatir Ansari, Oleksandr Shchur, Jaris KÃ¼ken&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/amazon-science/chronos-forecasting&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/amazon/chronos-2&quot;&gt;Project Page&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2510.15821&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>Black-Box On-Policy Distillation of Large Language Models</title>
    <id>56964b5c4b70a7c48e204a4541b8da35</id>
    <link href="https://arxiv.org/abs/2511.10643"/>
    <updated>2025-11-13T13:58:37+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>Black-box distillation creates student large language models (LLMs) by learning from a proprietary teacher model's text outputs alone, without access to its internal logits or parameters. In this work...&lt;br/&gt;Upvotes: 39&lt;br/&gt;GitHub Stars: 4191&lt;br/&gt;Authors: Tianzhu Ye, Li Dong, Zewen Chi&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/microsoft/LMOps/tree/main/gad&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://aka.ms/GAD-project&quot;&gt;Project Page&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2511.10643&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>Depth Anything 3: Recovering the Visual Space from Any Views</title>
    <id>516eebe0ff75c447a2516832b9987a1b</id>
    <link href="https://arxiv.org/abs/2511.10647"/>
    <updated>2025-11-13T13:59:53+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>We present Depth Anything 3 (DA3), a model that predicts spatially consistent geometry from an arbitrary number of visual inputs, with or without known camera poses. In pursuit of minimal modeling, DA...&lt;br/&gt;Upvotes: 64&lt;br/&gt;GitHub Stars: 2138&lt;br/&gt;Authors: Haotong Lin, Sili Chen, Junhao Liew&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/ByteDance-Seed/depth-anything-3&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://depth-anything-3.github.io/&quot;&gt;Project Page&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2511.10647&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>DeepAnalyze: Agentic Large Language Models for Autonomous Data Science</title>
    <id>1f8425376c830b061c351b993f70d01b</id>
    <link href="https://arxiv.org/abs/2510.16872"/>
    <updated>2025-10-19T11:13:42+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>Autonomous data science, from raw data sources to analyst-grade deep research
reports, has been a long-standing challenge, and is now becoming feasible with
the emergence of powerful large language mo...&lt;br/&gt;Upvotes: 98&lt;br/&gt;GitHub Stars: 2132&lt;br/&gt;Authors: Shaolei Zhang, Ju Fan, Meihao Fan&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/ruc-datalab/DeepAnalyze&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://ruc-deepanalyze.github.io/&quot;&gt;Project Page&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2510.16872&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
</feed>
