<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Huggingface Daily Papers</title>
  <id>tag:ai-news-direct.local,2025:huggingface_daily_papers</id>
  <icon>https://huggingface.co/favicon.ico</icon>
  <logo>https://huggingface.co/favicon.ico</logo>
  <updated>2026-01-12T21:22:54.598602+00:00</updated>
  <author>
    <name>AI News Direct</name>
  </author>
  <link href="https://raw.githubusercontent.com/mibuhand/AI-News-Direct/main/feeds/huggingface_daily_papers.xml" rel="self"/>
  <entry>
    <title>mHC: Manifold-Constrained Hyper-Connections</title>
    <id>2d9fe809957806c0d1ec27e6e37053aa</id>
    <link href="https://arxiv.org/abs/2512.24880"/>
    <updated>2025-12-31T09:16:26+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>Recently, studies exemplified by Hyper-Connections (HC) have extended the ubiquitous residual connection paradigm established over the past decade by expanding the residual stream width and diversifyi...&lt;br/&gt;Upvotes: 240&lt;br/&gt;Authors: Zhenda Xie, Yixuan Wei, Huanqi Cao&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2512.24880&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>DataFlow: An LLM-Driven Framework for Unified Data Preparation and Workflow Automation in the Era of Data-Centric AI</title>
    <id>adcafb2025f84cc88e13db2e967d246f</id>
    <link href="https://arxiv.org/abs/2512.16676"/>
    <updated>2025-12-18T10:46:15+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>The rapidly growing demand for high-quality data in Large Language Models (LLMs) has intensified the need for scalable, reliable, and semantically rich data preparation pipelines. However, current pra...&lt;br/&gt;Upvotes: 204&lt;br/&gt;GitHub Stars: 2312&lt;br/&gt;Authors: Hao Liang, Xiaochen Ma, Zhou Liu&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/OpenDCAI/DataFlow&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/OpenDCAI/DataFlow&quot;&gt;Project Page&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2512.16676&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>Kling-Omni Technical Report</title>
    <id>8328813bd23f18dae6c4e2c63c9de3c9</id>
    <link href="https://arxiv.org/abs/2512.16776"/>
    <updated>2025-12-18T12:08:12+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>We present Kling-Omni, a generalist generative framework designed to synthesize high-fidelity videos directly from multimodal visual language inputs. Adopting an end-to-end perspective, Kling-Omni bri...&lt;br/&gt;Upvotes: 164&lt;br/&gt;Authors: Kling Team, Jialu Chen, Yuanzheng Ci&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2512.16776&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>GDPO: Group reward-Decoupled Normalization Policy Optimization for Multi-reward RL Optimization</title>
    <id>9f022f923749f1889fd7797edcd67136</id>
    <link href="https://arxiv.org/abs/2601.05242"/>
    <updated>2026-01-08T13:59:24+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>As language models become increasingly capable, users expect them to provide not only accurate responses but also behaviors aligned with diverse human preferences across a variety of scenarios. To ach...&lt;br/&gt;Upvotes: 154&lt;br/&gt;GitHub Stars: 173&lt;br/&gt;Authors: Shih-Yang Liu, Xin Dong, Ximing Lu&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/NVlabs/GDPO&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://nvlabs.github.io/GDPO/&quot;&gt;Project Page&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2601.05242&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>Memory in the Age of AI Agents</title>
    <id>7e91c360c930c55d2bb71f49e0548368</id>
    <link href="https://arxiv.org/abs/2512.13564"/>
    <updated>2025-12-15T12:22:34+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>Memory has emerged, and will continue to remain, a core capability of foundation model-based agents. As research on agent memory rapidly expands and attracts unprecedented attention, the field has als...&lt;br/&gt;Upvotes: 136&lt;br/&gt;GitHub Stars: 756&lt;br/&gt;Authors: Yuyang Hu, Shichun Liu, Yanwei Yue&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/Shichun-Liu/Agent-Memory-Paper-List&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2512.13564&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>Youtu-LLM: Unlocking the Native Agentic Potential for Lightweight Large Language Models</title>
    <id>137390ef0a270b1435b825365ec94a3a</id>
    <link href="https://arxiv.org/abs/2512.24618"/>
    <updated>2025-12-30T23:25:11+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>We introduce Youtu-LLM, a lightweight yet powerful language model that harmonizes high computational efficiency with native agentic intelligence. Unlike typical small models that rely on distillation,...&lt;br/&gt;Upvotes: 130&lt;br/&gt;GitHub Stars: 398&lt;br/&gt;Authors: Junru Lu, Jiarui Qin, Lingfeng Qiao&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/TencentCloudADP/youtu-tip&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://youtu-tip.com/#llm&quot;&gt;Project Page&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2512.24618&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>Sharp Monocular View Synthesis in Less Than a Second</title>
    <id>b0feeb7f591514204e557e85f0c2b6ca</id>
    <link href="https://arxiv.org/abs/2512.10685"/>
    <updated>2025-12-11T09:34:11+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>We present SHARP, an approach to photorealistic view synthesis from a single image. Given a single photograph, SHARP regresses the parameters of a 3D Gaussian representation of the depicted scene. Thi...&lt;br/&gt;Upvotes: 26&lt;br/&gt;GitHub Stars: 6765&lt;br/&gt;Authors: Lars Mescheder, Wei Dong, Shiwei Li&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/apple/ml-sharp&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://apple.github.io/ml-sharp/&quot;&gt;Project Page&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2512.10685&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>Youtu-Agent: Scaling Agent Productivity with Automated Generation and Hybrid Policy Optimization</title>
    <id>4abe591dec20d02c68570faea169dfcb</id>
    <link href="https://arxiv.org/abs/2512.24615"/>
    <updated>2025-12-30T23:17:36+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>Existing Large Language Model (LLM) agent frameworks face two significant challenges: high configuration costs and static capabilities. Building a high-quality agent often requires extensive manual ef...&lt;br/&gt;Upvotes: 108&lt;br/&gt;GitHub Stars: 4207&lt;br/&gt;Authors: Yuchen Shi, Yuzheng Cai, Siqi Cai&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/TencentCloudADP/youtu-agent&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://tencentcloudadp.github.io/youtu-agent/&quot;&gt;Project Page&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2512.24615&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>TurboDiffusion: Accelerating Video Diffusion Models by 100-200 Times</title>
    <id>5bb778f47e493a1d7bcf12aaaec0e25e</id>
    <link href="https://arxiv.org/abs/2512.16093"/>
    <updated>2025-12-17T21:21:30+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>We introduce TurboDiffusion, a video generation acceleration framework that can speed up end-to-end diffusion generation by 100-200x while maintaining video quality. TurboDiffusion mainly relies on se...&lt;br/&gt;Upvotes: 93&lt;br/&gt;GitHub Stars: 3168&lt;br/&gt;Authors: Jintao Zhang, Kaiwen Zheng, Kai Jiang&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/thu-ml/TurboDiffusion&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/thu-ml/TurboDiffusion&quot;&gt;Project Page&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2512.16093&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>SAM Audio: Segment Anything in Audio</title>
    <id>1c5e2b4f68f2d0420edc475a4ac95129</id>
    <link href="https://arxiv.org/abs/2512.18099"/>
    <updated>2025-12-19T17:14:23+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>General audio source separation is a key capability for multimodal AI systems that can perceive and reason about sound. Despite substantial progress in recent years, existing separation models are eit...&lt;br/&gt;Upvotes: 22&lt;br/&gt;GitHub Stars: 2995&lt;br/&gt;Authors: Bowen Shi, Andros Tjandra, John Hoffman&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/facebookresearch/sam-audio&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://ai.meta.com/samaudio/&quot;&gt;Project Page&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2512.18099&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>Let It Flow: Agentic Crafting on Rock and Roll, Building the ROME Model within an Open Agentic Learning Ecosystem</title>
    <id>1f04a85a317b82f2c574c078f215f35e</id>
    <link href="https://arxiv.org/abs/2512.24873"/>
    <updated>2025-12-31T09:03:39+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>Agentic crafting requires LLMs to operate in real-world environments over multiple turns by taking actions, observing outcomes, and iteratively refining artifacts. Despite its importance, the open-sou...&lt;br/&gt;Upvotes: 96&lt;br/&gt;GitHub Stars: 2624&lt;br/&gt;Authors: Weixun Wang, XiaoXiao Xu, Wanhe An&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/alibaba/ROLL&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2512.24873&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
</feed>
