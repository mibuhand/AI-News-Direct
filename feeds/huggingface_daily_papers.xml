<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Huggingface Daily Papers</title>
  <id>tag:ai-news-direct.local,2025:huggingface_daily_papers</id>
  <icon>https://huggingface.co/favicon.ico</icon>
  <logo>https://huggingface.co/favicon.ico</logo>
  <updated>2025-12-14T21:19:19.848941+00:00</updated>
  <author>
    <name>AI News Direct</name>
  </author>
  <link href="https://raw.githubusercontent.com/mibuhand/AI-News-Direct/main/feeds/huggingface_daily_papers.xml" rel="self"/>
  <entry>
    <title>From Code Foundation Models to Agents and Applications: A Practical Guide to Code Intelligence</title>
    <id>7e43a061a51737f2587e45e69aa58ff1</id>
    <link href="https://arxiv.org/abs/2511.18538"/>
    <updated>2025-11-23T12:09:34+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>Large language models (LLMs) have fundamentally transformed automated software development by enabling direct translation of natural language descriptions into functional code, driving commercial adop...&lt;br/&gt;Upvotes: 263&lt;br/&gt;Authors: Jian Yang, Xianglong Liu, Weifeng Lv&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2511.18538&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>Kandinsky 5.0: A Family of Foundation Models for Image and Video Generation</title>
    <id>0139ab6619114102f84bcc9c449fd176</id>
    <link href="https://arxiv.org/abs/2511.14993"/>
    <updated>2025-11-18T19:23:22+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>This report introduces Kandinsky 5.0, a family of state-of-the-art foundation models for high-resolution image and 10-second video synthesis. The framework comprises three core line-up of models: Kand...&lt;br/&gt;Upvotes: 222&lt;br/&gt;GitHub Stars: 565&lt;br/&gt;Authors: Vladimir Arkhipkin, Vladimir Korviakov, Nikolai Gerasimenko&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/kandinskylab/kandinsky-5&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://kandinskylab.ai/&quot;&gt;Project Page&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2511.14993&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>DeepSeek-V3.2: Pushing the Frontier of Open Large Language Models</title>
    <id>c360b805a86862ca56d4316aea6a684d</id>
    <link href="https://arxiv.org/abs/2512.02556"/>
    <updated>2025-12-02T04:25:14+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>We introduce DeepSeek-V3.2, a model that harmonizes high computational efficiency with superior reasoning and agent performance. The key technical breakthroughs of DeepSeek-V3.2 are as follows: (1) De...&lt;br/&gt;Upvotes: 208&lt;br/&gt;Authors: DeepSeek-AI, Aixin Liu, Aoxue Mei&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2512.02556&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>Z-Image: An Efficient Image Generation Foundation Model with Single-Stream Diffusion Transformer</title>
    <id>8e9429d7feaa43a78c484db81c3eddf8</id>
    <link href="https://arxiv.org/abs/2511.22699"/>
    <updated>2025-11-27T13:52:07+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>The landscape of high-performance image generation models is currently dominated by proprietary systems, such as Nano Banana Pro and Seedream 4.0. Leading open-source alternatives, including Qwen-Imag...&lt;br/&gt;Upvotes: 193&lt;br/&gt;GitHub Stars: 6853&lt;br/&gt;Authors: Z-Image Team, Huanqia Cai, Sihan Cao&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/Tongyi-MAI/Z-Image&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://tongyi-mai.github.io/Z-Image-blog/&quot;&gt;Project Page&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2511.22699&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>Live Avatar: Streaming Real-time Audio-Driven Avatar Generation with Infinite Length</title>
    <id>bdd6e066d5b32b9c61996386576f3682</id>
    <link href="https://arxiv.org/abs/2512.04677"/>
    <updated>2025-12-04T06:11:24+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>Existing diffusion-based video generation methods are fundamentally constrained by sequential computation and long-horizon inconsistency, limiting their practical adoption in real-time, streaming audi...&lt;br/&gt;Upvotes: 166&lt;br/&gt;GitHub Stars: 956&lt;br/&gt;Authors: Yubo Huang, Hailong Guo, Fangtai Wu&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/Alibaba-Quark/LiveAvatar&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://liveavatar.github.io/&quot;&gt;Project Page&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2512.04677&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>MiroThinker: Pushing the Performance Boundaries of Open-Source Research Agents via Model, Context, and Interactive Scaling</title>
    <id>0a60cb0f535685cc7eb12b1b01de62bc</id>
    <link href="https://arxiv.org/abs/2511.11793"/>
    <updated>2025-11-14T13:52:07+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>We present MiroThinker v1.0, an open-source research agent designed to advance tool-augmented reasoning and information-seeking capabilities. Unlike previous agents that only scale up model size or co...&lt;br/&gt;Upvotes: 161&lt;br/&gt;GitHub Stars: 1305&lt;br/&gt;Authors: MiroMind Team, Song Bai, Lidong Bing&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/MiroMindAI/MiroThinker&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://dr.miromind.ai/&quot;&gt;Project Page&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2511.11793&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>DeepCode: Open Agentic Coding</title>
    <id>84e0c9ab3b32b3eab139bdd727fe4f8c</id>
    <link href="https://arxiv.org/abs/2512.07921"/>
    <updated>2025-12-08T11:07:13+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>Recent advances in large language models (LLMs) have given rise to powerful coding agents, making it possible for code assistants to evolve into code engineers. However, existing methods still face si...&lt;br/&gt;Upvotes: 19&lt;br/&gt;GitHub Stars: 12035&lt;br/&gt;Authors: Zongwei Li, Zhonghang Li, Zirui Guo&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/HKUDS/DeepCode&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2512.07921&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>UFO^3: Weaving the Digital Agent Galaxy</title>
    <id>f37a636c7cc5f515c6866d60bda27643</id>
    <link href="https://arxiv.org/abs/2511.11332"/>
    <updated>2025-11-14T09:05:31+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>Large language model (LLM)-powered agents are transforming digital devices from passive tools into proactive intelligent collaborators. However, most existing frameworks remain confined to a single OS...&lt;br/&gt;Upvotes: 18&lt;br/&gt;GitHub Stars: 7784&lt;br/&gt;Authors: Chaoyun Zhang, Liqun Li, He Huang&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/microsoft/UFO/&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://microsoft.github.io/UFO/&quot;&gt;Project Page&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2511.11332&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>Decoupled DMD: CFG Augmentation as the Spear, Distribution Matching as the Shield</title>
    <id>18503dda198b1fcbf7bb01dbf7296d31</id>
    <link href="https://arxiv.org/abs/2511.22677"/>
    <updated>2025-11-27T13:24:28+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>Diffusion model distillation has emerged as a powerful technique for creating efficient few-step and single-step generators. Among these, Distribution Matching Distillation (DMD) and its variants stan...&lt;br/&gt;Upvotes: 24&lt;br/&gt;GitHub Stars: 6861&lt;br/&gt;Authors: Dongyang Liu, Peng Gao, David Liu&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/Tongyi-MAI/Z-Image/tree/main&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://tongyi-mai.github.io/Z-Image-blog/&quot;&gt;Project Page&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2511.22677&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>SAM 3: Segment Anything with Concepts</title>
    <id>3c094172f9e0e4e808f9c218d4d266f1</id>
    <link href="https://arxiv.org/abs/2511.16719"/>
    <updated>2025-11-20T13:59:56+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>We present Segment Anything Model (SAM) 3, a unified model that detects, segments, and tracks objects in images and videos based on concept prompts, which we define as either short noun phrases (e.g.,...&lt;br/&gt;Upvotes: 112&lt;br/&gt;GitHub Stars: 5812&lt;br/&gt;Authors: Nicolas Carion, Laura Gustafson, Yuan-Ting Hu&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/facebookresearch/sam3&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://ai.meta.com/sam3/&quot;&gt;Project Page&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2511.16719&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>SAM 3D: 3Dfy Anything in Images</title>
    <id>979bc288b697d0a635887e56b67befef</id>
    <link href="https://arxiv.org/abs/2511.16624"/>
    <updated>2025-11-20T13:31:46+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>We present SAM 3D, a generative model for visually grounded 3D object reconstruction, predicting geometry, texture, and layout from a single image. SAM 3D excels in natural images, where occlusion and...&lt;br/&gt;Upvotes: 107&lt;br/&gt;GitHub Stars: 4819&lt;br/&gt;Authors: SAM 3D Team, Xingyu Chen, Fu-Jen Chu&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/facebookresearch/sam-3d-objects&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://ai.meta.com/sam3d/&quot;&gt;Project Page&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2511.16624&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
</feed>
