<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Huggingface Daily Papers</title>
  <id>tag:ai-news-direct.local,2025:huggingface_daily_papers</id>
  <icon>https://huggingface.co/favicon.ico</icon>
  <logo>https://huggingface.co/favicon.ico</logo>
  <updated>2025-12-17T21:21:51.606135+00:00</updated>
  <author>
    <name>AI News Direct</name>
  </author>
  <link href="https://raw.githubusercontent.com/mibuhand/AI-News-Direct/main/feeds/huggingface_daily_papers.xml" rel="self"/>
  <entry>
    <title>From Code Foundation Models to Agents and Applications: A Practical Guide to Code Intelligence</title>
    <id>7e43a061a51737f2587e45e69aa58ff1</id>
    <link href="https://arxiv.org/abs/2511.18538"/>
    <updated>2025-11-23T12:09:34+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>Large language models (LLMs) have fundamentally transformed automated software development by enabling direct translation of natural language descriptions into functional code, driving commercial adop...&lt;br/&gt;Upvotes: 265&lt;br/&gt;Authors: Jian Yang, Xianglong Liu, Weifeng Lv&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2511.18538&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>Kandinsky 5.0: A Family of Foundation Models for Image and Video Generation</title>
    <id>0139ab6619114102f84bcc9c449fd176</id>
    <link href="https://arxiv.org/abs/2511.14993"/>
    <updated>2025-11-18T19:23:22+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>This report introduces Kandinsky 5.0, a family of state-of-the-art foundation models for high-resolution image and 10-second video synthesis. The framework comprises three core line-up of models: Kand...&lt;br/&gt;Upvotes: 224&lt;br/&gt;GitHub Stars: 579&lt;br/&gt;Authors: Vladimir Arkhipkin, Vladimir Korviakov, Nikolai Gerasimenko&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/kandinskylab/kandinsky-5&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://kandinskylab.ai/&quot;&gt;Project Page&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2511.14993&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>DeepSeek-V3.2: Pushing the Frontier of Open Large Language Models</title>
    <id>c360b805a86862ca56d4316aea6a684d</id>
    <link href="https://arxiv.org/abs/2512.02556"/>
    <updated>2025-12-02T04:25:14+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>We introduce DeepSeek-V3.2, a model that harmonizes high computational efficiency with superior reasoning and agent performance. The key technical breakthroughs of DeepSeek-V3.2 are as follows: (1) De...&lt;br/&gt;Upvotes: 213&lt;br/&gt;Authors: DeepSeek-AI, Aixin Liu, Aoxue Mei&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2512.02556&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>Z-Image: An Efficient Image Generation Foundation Model with Single-Stream Diffusion Transformer</title>
    <id>8e9429d7feaa43a78c484db81c3eddf8</id>
    <link href="https://arxiv.org/abs/2511.22699"/>
    <updated>2025-11-27T13:52:07+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>The landscape of high-performance image generation models is currently dominated by proprietary systems, such as Nano Banana Pro and Seedream 4.0. Leading open-source alternatives, including Qwen-Imag...&lt;br/&gt;Upvotes: 200&lt;br/&gt;GitHub Stars: 7227&lt;br/&gt;Authors: Z-Image Team, Huanqia Cai, Sihan Cao&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/Tongyi-MAI/Z-Image&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://tongyi-mai.github.io/Z-Image-blog/&quot;&gt;Project Page&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2511.22699&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>Live Avatar: Streaming Real-time Audio-Driven Avatar Generation with Infinite Length</title>
    <id>bdd6e066d5b32b9c61996386576f3682</id>
    <link href="https://arxiv.org/abs/2512.04677"/>
    <updated>2025-12-04T06:11:24+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>Existing diffusion-based video generation methods are fundamentally constrained by sequential computation and long-horizon inconsistency, limiting their practical adoption in real-time, streaming audi...&lt;br/&gt;Upvotes: 167&lt;br/&gt;GitHub Stars: 1042&lt;br/&gt;Authors: Yubo Huang, Hailong Guo, Fangtai Wu&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/Alibaba-Quark/LiveAvatar&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://liveavatar.github.io/&quot;&gt;Project Page&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2512.04677&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>MiroThinker: Pushing the Performance Boundaries of Open-Source Research Agents via Model, Context, and Interactive Scaling</title>
    <id>0a60cb0f535685cc7eb12b1b01de62bc</id>
    <link href="https://arxiv.org/abs/2511.11793"/>
    <updated>2025-11-14T13:52:07+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>We present MiroThinker v1.0, an open-source research agent designed to advance tool-augmented reasoning and information-seeking capabilities. Unlike previous agents that only scale up model size or co...&lt;br/&gt;Upvotes: 161&lt;br/&gt;GitHub Stars: 1327&lt;br/&gt;Authors: MiroMind Team, Song Bai, Lidong Bing&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/MiroMindAI/MiroThinker&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://dr.miromind.ai/&quot;&gt;Project Page&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2511.11793&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>Qwen3-VL Technical Report</title>
    <id>5b6ff13ede65701e5f764a0267eca8df</id>
    <link href="https://arxiv.org/abs/2511.21631"/>
    <updated>2025-11-26T12:59:08+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>We introduce Qwen3-VL, the most capable vision-language model in the Qwen series to date, achieving superior performance across a broad range of multimodal benchmarks. It natively supports interleaved...&lt;br/&gt;Upvotes: 126&lt;br/&gt;GitHub Stars: 17234&lt;br/&gt;Authors: Shuai Bai, Yuxuan Cai, Ruizhe Chen&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/QwenLM/Qwen3-VL&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://chat.qwen.ai&quot;&gt;Project Page&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2511.21631&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>DeepCode: Open Agentic Coding</title>
    <id>84e0c9ab3b32b3eab139bdd727fe4f8c</id>
    <link href="https://arxiv.org/abs/2512.07921"/>
    <updated>2025-12-08T11:07:13+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>Recent advances in large language models (LLMs) have given rise to powerful coding agents, making it possible for code assistants to evolve into code engineers. However, existing methods still face si...&lt;br/&gt;Upvotes: 29&lt;br/&gt;GitHub Stars: 12657&lt;br/&gt;Authors: Zongwei Li, Zhonghang Li, Zirui Guo&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/HKUDS/DeepCode&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2512.07921&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>Agent READMEs: An Empirical Study of Context Files for Agentic Coding</title>
    <id>98c3fb1b14f6bd881158862a97b49d56</id>
    <link href="https://arxiv.org/abs/2511.12884"/>
    <updated>2025-11-16T21:18:55+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>Agentic coding tools receive goals written in natural language as input, break them down into specific tasks, and write or execute the actual code with minimal human intervention. Central to this proc...&lt;br/&gt;Upvotes: 8&lt;br/&gt;GitHub Stars: 12267&lt;br/&gt;Authors: Worawalan Chatlatanagulchai, Hao Li, Yutaro Kashiwa&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/openai/agents.md&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://agents.md&quot;&gt;Project Page&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2511.12884&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>Soft Adaptive Policy Optimization</title>
    <id>4a2bfe8d09c1cb8d7f0252ad4b16ac1e</id>
    <link href="https://arxiv.org/abs/2511.20347"/>
    <updated>2025-11-25T09:25:19+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>Reinforcement learning (RL) plays an increasingly important role in enhancing the reasoning capabilities of large language models (LLMs), yet stable and performant policy optimization remains challeng...&lt;br/&gt;Upvotes: 41&lt;br/&gt;GitHub Stars: 11710&lt;br/&gt;Authors: Chang Gao, Chujie Zheng, Xiong-Hui Chen&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/modelscope/ms-swift&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://swift.readthedocs.io/en/latest/Instruction/GRPO/AdvancedResearch/SAPO.html&quot;&gt;Project Page&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2511.20347&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>UFO^3: Weaving the Digital Agent Galaxy</title>
    <id>f37a636c7cc5f515c6866d60bda27643</id>
    <link href="https://arxiv.org/abs/2511.11332"/>
    <updated>2025-11-14T09:05:31+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>Large language model (LLM)-powered agents are transforming digital devices from passive tools into proactive intelligent collaborators. However, most existing frameworks remain confined to a single OS...&lt;br/&gt;Upvotes: 18&lt;br/&gt;GitHub Stars: 7814&lt;br/&gt;Authors: Chaoyun Zhang, Liqun Li, He Huang&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/microsoft/UFO/&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://microsoft.github.io/UFO/&quot;&gt;Project Page&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2511.11332&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>Decoupled DMD: CFG Augmentation as the Spear, Distribution Matching as the Shield</title>
    <id>18503dda198b1fcbf7bb01dbf7296d31</id>
    <link href="https://arxiv.org/abs/2511.22677"/>
    <updated>2025-11-27T13:24:28+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>Diffusion model distillation has emerged as a powerful technique for creating efficient few-step and single-step generators. Among these, Distribution Matching Distillation (DMD) and its variants stan...&lt;br/&gt;Upvotes: 27&lt;br/&gt;GitHub Stars: 7235&lt;br/&gt;Authors: Dongyang Liu, Peng Gao, David Liu&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/Tongyi-MAI/Z-Image/tree/main&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://tongyi-mai.github.io/Z-Image-blog/&quot;&gt;Project Page&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2511.22677&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
</feed>
