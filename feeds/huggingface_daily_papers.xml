<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Huggingface Daily Papers</title>
  <id>tag:ai-news-direct.local,2025:huggingface_daily_papers</id>
  <icon>https://huggingface.co/favicon.ico</icon>
  <logo>https://huggingface.co/favicon.ico</logo>
  <updated>2025-09-29T21:16:58.761447+00:00</updated>
  <author>
    <name>AI News Direct</name>
  </author>
  <link href="https://raw.githubusercontent.com/mibuhand/AI-News-Direct/main/feeds/huggingface_daily_papers.xml" rel="self"/>
  <entry>
    <title>Sharing is Caring: Efficient LM Post-Training with Collective RL
  Experience Sharing</title>
    <id>8ccd2aceeb4aa375ae3aaa881748eeca</id>
    <link href="https://arxiv.org/abs/2509.08721"/>
    <updated>2025-09-10T12:14:20+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>Post-training language models (LMs) with reinforcement learning (RL) can
enhance their complex reasoning capabilities without supervised fine-tuning, as
demonstrated by DeepSeek-R1-Zero. However, effe...&lt;br/&gt;Upvotes: 633&lt;br/&gt;GitHub Stars: 1459&lt;br/&gt;Authors: Jeffrey Amico, Gabriel Passamani Andrade, John Donaghy&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/gensyn-ai/rl-swarm&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://blog.gensyn.ai/sapo-efficient-lm-post-training-with-collective-rl/&quot;&gt;Project Page&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2509.08721&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>A.S.E: A Repository-Level Benchmark for Evaluating Security in
  AI-Generated Code</title>
    <id>f4b634605f28912c3f352503c72078a6</id>
    <link href="https://arxiv.org/abs/2508.18106"/>
    <updated>2025-08-25T11:11:11+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>The increasing adoption of large language models (LLMs) in software
engineering necessitates rigorous security evaluation of their generated code.
However, existing benchmarks often lack relevance to ...&lt;br/&gt;Upvotes: 342&lt;br/&gt;GitHub Stars: 367&lt;br/&gt;Authors: Keke Lian, Bin Wang, Lei Zhang&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/Tencent/AICGSecEval&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://aicgseceval.tencent.com/home&quot;&gt;Project Page&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2508.18106&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>VLA-Adapter: An Effective Paradigm for Tiny-Scale Vision-Language-Action
  Model</title>
    <id>a785dc23394ddf009c4095e44be6b818</id>
    <link href="https://arxiv.org/abs/2509.09372"/>
    <updated>2025-09-11T07:42:21+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>Vision-Language-Action (VLA) models typically bridge the gap between
perceptual and action spaces by pre-training a large-scale Vision-Language
Model (VLM) on robotic data. While this approach greatly...&lt;br/&gt;Upvotes: 215&lt;br/&gt;GitHub Stars: 557&lt;br/&gt;Authors: Yihao Wang, Pengxiang Ding, Lingxiao Li&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/OpenHelix-Team/VLA-Adapter&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://vla-adapter.github.io/&quot;&gt;Project Page&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2509.09372&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>The Landscape of Agentic Reinforcement Learning for LLMs: A Survey</title>
    <id>b3695a804f022da86db7e28029ec25d4</id>
    <link href="https://arxiv.org/abs/2509.02547"/>
    <updated>2025-09-02T13:46:26+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>The emergence of agentic reinforcement learning (Agentic RL) marks a paradigm
shift from conventional reinforcement learning applied to large language models
(LLM RL), reframing LLMs from passive sequ...&lt;br/&gt;Upvotes: 210&lt;br/&gt;GitHub Stars: 836&lt;br/&gt;Authors: Guibin Zhang, Hejia Geng, Xiaohang Yu&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/xhyumiracle/Awesome-AgenticLLM-RL-Papers&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2509.02547&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>Drivel-ology: Challenging LLMs with Interpreting Nonsense with Depth</title>
    <id>2a53ea33f47888c723fab2a38e7d2442</id>
    <link href="https://arxiv.org/abs/2509.03867"/>
    <updated>2025-09-03T23:58:55+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>We introduce Drivelology, a unique linguistic phenomenon characterised as
&quot;nonsense with depth&quot;, utterances that are syntactically coherent yet
pragmatically paradoxical, emotionally loaded, or rhetor...&lt;br/&gt;Upvotes: 204&lt;br/&gt;GitHub Stars: 6&lt;br/&gt;Authors: Yang Wang, Chenghao Xiao, Chia-Yi Hsiao&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/ExtraOrdinaryLab/drivelology&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/datasets/extraordinarylab/drivel-hub&quot;&gt;Project Page&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2509.03867&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>Why Language Models Hallucinate</title>
    <id>f7bf7ea1a54c9f21c1a3c2958aa1d217</id>
    <link href="https://arxiv.org/abs/2509.04664"/>
    <updated>2025-09-04T17:26:31+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>Like students facing hard exam questions, large language models sometimes
guess when uncertain, producing plausible yet incorrect statements instead of
admitting uncertainty. Such &quot;hallucinations&quot; per...&lt;br/&gt;Upvotes: 179&lt;br/&gt;Authors: Adam Tauman Kalai, Ofir Nachum, Santosh S. Vempala&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2509.04664&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>MiniCPM-V 4.5: Cooking Efficient MLLMs via Architecture, Data, and
  Training Recipe</title>
    <id>59f26db9f2ae0d3d43973c1ffbd40568</id>
    <link href="https://arxiv.org/abs/2509.18154"/>
    <updated>2025-09-16T15:41:48+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>Multimodal Large Language Models (MLLMs) are undergoing rapid progress and
represent the frontier of AI development. However, their training and inference
efficiency have emerged as a core bottleneck ...&lt;br/&gt;Upvotes: 46&lt;br/&gt;GitHub Stars: 22011&lt;br/&gt;Authors: Tianyu Yu, Zefan Wang, Chongyi Wang&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/OpenBMB/MiniCPM-V&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2509.18154&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>Scaling Agents via Continual Pre-training</title>
    <id>17d435d0d4a4864c8247d4e12399b781</id>
    <link href="https://arxiv.org/abs/2509.13310"/>
    <updated>2025-09-16T13:57:19+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>Large language models (LLMs) have evolved into agentic systems capable of
autonomous tool use and multi-step reasoning for complex problem-solving.
However, post-training approaches building upon gene...&lt;br/&gt;Upvotes: 106&lt;br/&gt;GitHub Stars: 15138&lt;br/&gt;Authors: Liangcai Su, Zhen Zhang, Guangyu Li&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/Alibaba-NLP/DeepResearch///&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://tongyi-agent.github.io/blog/&quot;&gt;Project Page&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2509.13310&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>WebWeaver: Structuring Web-Scale Evidence with Dynamic Outlines for
  Open-Ended Deep Research</title>
    <id>27945bd6f1634bfd914ab287d0fdaf8e</id>
    <link href="https://arxiv.org/abs/2509.13312"/>
    <updated>2025-09-16T13:57:21+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>This paper tackles open-ended deep research (OEDR), a complex challenge where
AI agents must synthesize vast web-scale information into insightful reports.
Current approaches are plagued by dual-fold ...&lt;br/&gt;Upvotes: 100&lt;br/&gt;GitHub Stars: 15138&lt;br/&gt;Authors: Zijian Li, Xin Guan, Bo Zhang&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/Alibaba-NLP/DeepResearch&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://tongyi-agent.github.io/blog/&quot;&gt;Project Page&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2509.13312&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>WebSailor-V2: Bridging the Chasm to Proprietary Agents via Synthetic
  Data and Scalable Reinforcement Learning</title>
    <id>d4b4f91354d2792a0826158fb9d00e0b</id>
    <link href="https://arxiv.org/abs/2509.13305"/>
    <updated>2025-09-16T13:57:03+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>Transcending human cognitive limitations represents a critical frontier in
LLM training. Proprietary agentic systems like DeepResearch have demonstrated
superhuman capabilities on extremely complex in...&lt;br/&gt;Upvotes: 83&lt;br/&gt;GitHub Stars: 15138&lt;br/&gt;Authors: Kuan Li, Zhongwang Zhang, Huifeng Yin&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/Alibaba-NLP/DeepResearch/&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://tongyi-agent.github.io/blog/&quot;&gt;Project Page&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2509.13305&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>ReSum: Unlocking Long-Horizon Search Intelligence via Context
  Summarization</title>
    <id>56ef9e3095cf3666002acddf23dee4ac</id>
    <link href="https://arxiv.org/abs/2509.13313"/>
    <updated>2025-09-16T13:57:22+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>Large Language Model (LLM)-based web agents demonstrate strong performance on
knowledge-intensive tasks but are hindered by context window limitations in
paradigms like ReAct. Complex queries involvin...&lt;br/&gt;Upvotes: 72&lt;br/&gt;GitHub Stars: 15138&lt;br/&gt;Authors: Xixi Wu, Kuan Li, Yida Zhao&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/Alibaba-NLP/DeepResearch//&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://tongyi-agent.github.io/blog/&quot;&gt;Project Page&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2509.13313&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>UI-S1: Advancing GUI Automation via Semi-online Reinforcement Learning</title>
    <id>f5dd4977eb4232fa774b69a50071202a</id>
    <link href="https://arxiv.org/abs/2509.11543"/>
    <updated>2025-09-14T23:24:08+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>Graphical User Interface (GUI) agents have demonstrated remarkable progress
in automating complex user interface interactions through reinforcement
learning. However, current approaches face a fundame...&lt;br/&gt;Upvotes: 46&lt;br/&gt;GitHub Stars: 5933&lt;br/&gt;Authors: Zhengxi Lu, Jiabo Ye, Fei Tang&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/X-PLUG/MobileAgent/tree/main/UI-S1&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2509.11543&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
</feed>
