<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Huggingface Daily Papers</title>
  <id>tag:ai-news-direct.local,2025:huggingface_daily_papers</id>
  <icon>https://huggingface.co/favicon.ico</icon>
  <logo>https://huggingface.co/favicon.ico</logo>
  <updated>2025-09-22T21:16:49.678880+00:00</updated>
  <author>
    <name>AI News Direct</name>
  </author>
  <link href="https://raw.githubusercontent.com/mibuhand/AI-News-Direct/main/feeds/huggingface_daily_papers.xml" rel="self"/>
  <entry>
    <title>Sharing is Caring: Efficient LM Post-Training with Collective RL
  Experience Sharing</title>
    <id>8ccd2aceeb4aa375ae3aaa881748eeca</id>
    <link href="https://arxiv.org/abs/2509.08721"/>
    <updated>2025-09-10T12:14:20+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>Post-training language models (LMs) with reinforcement learning (RL) can
enhance their complex reasoning capabilities without supervised fine-tuning, as
demonstrated by DeepSeek-R1-Zero. However, effe...&lt;br/&gt;Upvotes: 599&lt;br/&gt;GitHub Stars: 1427&lt;br/&gt;Authors: Jeffrey Amico, Gabriel Passamani Andrade, John Donaghy&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/gensyn-ai/rl-swarm&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://blog.gensyn.ai/sapo-efficient-lm-post-training-with-collective-rl/&quot;&gt;Project Page&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2509.08721&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>A.S.E: A Repository-Level Benchmark for Evaluating Security in
  AI-Generated Code</title>
    <id>f4b634605f28912c3f352503c72078a6</id>
    <link href="https://arxiv.org/abs/2508.18106"/>
    <updated>2025-08-25T11:11:11+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>The increasing adoption of large language models (LLMs) in software
engineering necessitates rigorous security evaluation of their generated code.
However, existing benchmarks often lack relevance to ...&lt;br/&gt;Upvotes: 339&lt;br/&gt;GitHub Stars: 332&lt;br/&gt;Authors: Keke Lian, Bin Wang, Lei Zhang&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/Tencent/AICGSecEval&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://aicgseceval.tencent.com/home&quot;&gt;Project Page&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2508.18106&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>Drivel-ology: Challenging LLMs with Interpreting Nonsense with Depth</title>
    <id>2a53ea33f47888c723fab2a38e7d2442</id>
    <link href="https://arxiv.org/abs/2509.03867"/>
    <updated>2025-09-03T23:58:55+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>We introduce Drivelology, a unique linguistic phenomenon characterised as
&quot;nonsense with depth&quot;, utterances that are syntactically coherent yet
pragmatically paradoxical, emotionally loaded, or rhetor...&lt;br/&gt;Upvotes: 203&lt;br/&gt;GitHub Stars: 6&lt;br/&gt;Authors: Yang Wang, Chenghao Xiao, Chia-Yi Hsiao&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/ExtraOrdinaryLab/drivelology&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/datasets/extraordinarylab/drivel-hub&quot;&gt;Project Page&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2509.03867&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>The Landscape of Agentic Reinforcement Learning for LLMs: A Survey</title>
    <id>b3695a804f022da86db7e28029ec25d4</id>
    <link href="https://arxiv.org/abs/2509.02547"/>
    <updated>2025-09-02T13:46:26+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>The emergence of agentic reinforcement learning (Agentic RL) marks a paradigm
shift from conventional reinforcement learning applied to large language models
(LLM RL), reframing LLMs from passive sequ...&lt;br/&gt;Upvotes: 199&lt;br/&gt;GitHub Stars: 774&lt;br/&gt;Authors: Guibin Zhang, Hejia Geng, Xiaohang Yu&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/xhyumiracle/Awesome-AgenticLLM-RL-Papers&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2509.02547&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>InternVL3.5: Advancing Open-Source Multimodal Models in Versatility,
  Reasoning, and Efficiency</title>
    <id>6d87464070be7e367c0d00a7450fa0ba</id>
    <link href="https://arxiv.org/abs/2508.18265"/>
    <updated>2025-08-25T13:58:17+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>We introduce InternVL 3.5, a new family of open-source multimodal models that
significantly advances versatility, reasoning capability, and inference
efficiency along the InternVL series. A key innova...&lt;br/&gt;Upvotes: 191&lt;br/&gt;GitHub Stars: 9206&lt;br/&gt;Authors: Weiyun Wang, Zhangwei Gao, Lixin Gu&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/OpenGVLab/InternVL&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://chat.intern-ai.org.cn/&quot;&gt;Project Page&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2508.18265&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>VLA-Adapter: An Effective Paradigm for Tiny-Scale Vision-Language-Action
  Model</title>
    <id>a785dc23394ddf009c4095e44be6b818</id>
    <link href="https://arxiv.org/abs/2509.09372"/>
    <updated>2025-09-11T07:42:21+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>Vision-Language-Action (VLA) models typically bridge the gap between
perceptual and action spaces by pre-training a large-scale Vision-Language
Model (VLM) on robotic data. While this approach greatly...&lt;br/&gt;Upvotes: 190&lt;br/&gt;GitHub Stars: 144&lt;br/&gt;Authors: Yihao Wang, Pengxiang Ding, Lingxiao Li&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/OpenHelix-Team/VLA-Adapter&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://vla-adapter.github.io/&quot;&gt;Project Page&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2509.09372&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>WebWeaver: Structuring Web-Scale Evidence with Dynamic Outlines for
  Open-Ended Deep Research</title>
    <id>27945bd6f1634bfd914ab287d0fdaf8e</id>
    <link href="https://arxiv.org/abs/2509.13312"/>
    <updated>2025-09-16T13:57:21+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>This paper tackles open-ended deep research (OEDR), a complex challenge where
AI agents must synthesize vast web-scale information into insightful reports.
Current approaches are plagued by dual-fold ...&lt;br/&gt;Upvotes: 96&lt;br/&gt;GitHub Stars: 13720&lt;br/&gt;Authors: Zijian Li, Xin Guan, Bo Zhang&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/Alibaba-NLP/DeepResearch&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://tongyi-agent.github.io/blog/&quot;&gt;Project Page&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2509.13312&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>Scaling Agents via Continual Pre-training</title>
    <id>17d435d0d4a4864c8247d4e12399b781</id>
    <link href="https://arxiv.org/abs/2509.13310"/>
    <updated>2025-09-16T13:57:19+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>Large language models (LLMs) have evolved into agentic systems capable of
autonomous tool use and multi-step reasoning for complex problem-solving.
However, post-training approaches building upon gene...&lt;br/&gt;Upvotes: 95&lt;br/&gt;GitHub Stars: 13720&lt;br/&gt;Authors: Liangcai Su, Zhen Zhang, Guangyu Li&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/Alibaba-NLP/DeepResearch///&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://tongyi-agent.github.io/blog/&quot;&gt;Project Page&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2509.13310&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>WebSailor-V2: Bridging the Chasm to Proprietary Agents via Synthetic
  Data and Scalable Reinforcement Learning</title>
    <id>d4b4f91354d2792a0826158fb9d00e0b</id>
    <link href="https://arxiv.org/abs/2509.13305"/>
    <updated>2025-09-16T13:57:03+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>Transcending human cognitive limitations represents a critical frontier in
LLM training. Proprietary agentic systems like DeepResearch have demonstrated
superhuman capabilities on extremely complex in...&lt;br/&gt;Upvotes: 75&lt;br/&gt;GitHub Stars: 13720&lt;br/&gt;Authors: Kuan Li, Zhongwang Zhang, Huifeng Yin&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/Alibaba-NLP/DeepResearch/&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://tongyi-agent.github.io/blog/&quot;&gt;Project Page&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2509.13305&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>ReSum: Unlocking Long-Horizon Search Intelligence via Context
  Summarization</title>
    <id>56ef9e3095cf3666002acddf23dee4ac</id>
    <link href="https://arxiv.org/abs/2509.13313"/>
    <updated>2025-09-16T13:57:22+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>Large Language Model (LLM)-based web agents demonstrate strong performance on
knowledge-intensive tasks but are hindered by context window limitations in
paradigms like ReAct. Complex queries involvin...&lt;br/&gt;Upvotes: 65&lt;br/&gt;GitHub Stars: 13720&lt;br/&gt;Authors: Xixi Wu, Kuan Li, Yida Zhao&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/Alibaba-NLP/DeepResearch//&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://tongyi-agent.github.io/blog/&quot;&gt;Project Page&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2509.13313&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
  <entry>
    <title>AgentScope 1.0: A Developer-Centric Framework for Building Agentic
  Applications</title>
    <id>0ed9910aac99440f4f67d70de1502ed7</id>
    <link href="https://arxiv.org/abs/2508.16279"/>
    <updated>2025-08-22T06:35:56+00:00</updated>
    <category term="research"/>
    <category term="paper"/>
    <summary>Driven by rapid advancements of Large Language Models (LLMs), agents are
empowered to combine intrinsic knowledge with dynamic tool use, greatly
enhancing their capacity to address real-world tasks. I...&lt;br/&gt;Upvotes: 49&lt;br/&gt;GitHub Stars: 12267&lt;br/&gt;Authors: Dawei Gao, Zitao Li, Yuexiang Xie&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://github.com/agentscope-ai/agentscope&quot;&gt;GitHub&lt;/a&gt;&lt;br/&gt;ðŸ”— &lt;a href=&quot;https://huggingface.co/papers/2508.16279&quot;&gt;Hugging Face&lt;/a&gt;</summary>
  </entry>
</feed>
