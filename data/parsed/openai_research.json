[
    {
        "id": "76786030386ff19d3670fbfb28012430",
        "source": "openai",
        "type": "research",
        "title": "Understanding neural networks through sparse circuits",
        "description": "OpenAI is exploring mechanistic interpretability to understand how neural networks reason. Our new sparse model approach could make AI systems more transparent and support safer, more reliable behavior.",
        "url": "https://openai.com/index/understanding-neural-networks-through-sparse-circuits/",
        "published_date": "2025-11-13T10:00:00+00:00",
        "categories": [
            "Research"
        ],
        "organization": "OpenAI",
        "metadata": {
            "post_type": "Research"
        },
        "objects": []
    },
    {
        "id": "c3387415a5e1df503bd503201d90ecaa",
        "source": "openai",
        "type": "product",
        "title": "GPT-5.1: A smarter, more conversational ChatGPT",
        "description": "We\u2019re upgrading the GPT-5 series with warmer, more capable models and new ways to customize ChatGPT\u2019s tone and style. GPT-5.1 starts rolling out today to paid users.",
        "url": "https://openai.com/index/gpt-5-1/",
        "published_date": "2025-11-12T00:00:00+00:00",
        "categories": [
            "Product"
        ],
        "organization": "OpenAI",
        "metadata": {
            "post_type": "Product"
        },
        "objects": []
    },
    {
        "id": "a37acfed24a908a166f997aceb9fcb06",
        "source": "openai",
        "type": "publication",
        "title": "GPT-5.1 Instant and GPT-5.1 Thinking System Card Addendum",
        "description": "This GPT-5 system card addendum provides updated safety metrics for GPT-5.1 Instant and Thinking, including new evaluations for mental health and emotional reliance.",
        "url": "https://openai.com/index/gpt-5-system-card-addendum-gpt-5-1/",
        "published_date": "2025-11-12T00:00:00+00:00",
        "categories": [
            "Publication"
        ],
        "organization": "OpenAI",
        "metadata": {
            "post_type": "Publication"
        },
        "objects": []
    },
    {
        "id": "f76988be9f427fe14d5d5feaf1f5ef98",
        "source": "openai",
        "type": "research",
        "title": "Introducing IndQA",
        "description": "OpenAI introduces IndQA, a new benchmark for evaluating AI systems in Indian languages. Built with domain experts, IndQA tests cultural understanding and reasoning across 12 languages and 10 knowledge areas.",
        "url": "https://openai.com/index/introducing-indqa/",
        "published_date": "2025-11-03T22:30:00+00:00",
        "categories": [
            "Research"
        ],
        "organization": "OpenAI",
        "metadata": {
            "post_type": "Research"
        },
        "objects": []
    },
    {
        "id": "005c42f69c4969517b32b0b141cec5ab",
        "source": "openai",
        "type": "research",
        "title": "Introducing Aardvark: OpenAI\u2019s agentic security researcher",
        "description": "OpenAI introduces Aardvark, an AI-powered security researcher that autonomously finds, validates, and helps fix software vulnerabilities at scale. The system is in private beta\u2014sign up to join early testing.",
        "url": "https://openai.com/index/introducing-aardvark/",
        "published_date": "2025-10-30T11:00:00+00:00",
        "categories": [
            "Research"
        ],
        "organization": "OpenAI",
        "metadata": {
            "post_type": "Research"
        },
        "objects": []
    },
    {
        "id": "3601f3ad341eb27939506c0f5e361225",
        "source": "openai",
        "type": "product",
        "title": "Introducing gpt-oss-safeguard",
        "description": "OpenAI introduces gpt-oss-safeguard\u2014open-weight reasoning models for safety classification that let developers apply and iterate on custom policies.",
        "url": "https://openai.com/index/introducing-gpt-oss-safeguard/",
        "published_date": "2025-10-29T00:00:00+00:00",
        "categories": [
            "Product"
        ],
        "organization": "OpenAI",
        "metadata": {
            "post_type": "Product"
        },
        "objects": []
    },
    {
        "id": "954f63c357c5dc716c95f20c1fc7d84f",
        "source": "openai",
        "type": "safety",
        "title": "Technical Report: Performance and baseline evaluations of gpt-oss-safeguard-120b",
        "description": "and gpt-oss-safeguard-20bgpt-oss-safeguard-120b and gpt-oss-safeguard-20b are two open-weight reasoning models post-trained from the gpt-oss models and trained to reason from a provided policy in order to label content under that policy. In this report, we describe gpt-oss-safeguard\u2019s capabilities and provide our baseline safety evaluations on the gpt-oss-safeguard models, using the underlying gpt-oss models as a baseline. For more information about the development and architecture of the underlying gpt-oss models, see the original gpt-oss model model card\u2060.",
        "url": "https://openai.com/index/gpt-oss-safeguard-technical-report/",
        "published_date": "2025-10-29T00:00:00+00:00",
        "categories": [
            "Safety"
        ],
        "organization": "OpenAI",
        "metadata": {
            "post_type": "Safety"
        },
        "objects": []
    },
    {
        "id": "2fad364d831037ee94c4b914d2314855",
        "source": "openai",
        "type": "safety",
        "title": "Addendum to GPT-5 System Card: Sensitive conversations",
        "description": "This system card details GPT-5\u2019s improvements in handling sensitive conversations, including new benchmarks for emotional reliance, mental health, and jailbreak resistance.",
        "url": "https://openai.com/index/gpt-5-system-card-sensitive-conversations/",
        "published_date": "2025-10-27T10:00:00+00:00",
        "categories": [
            "Safety"
        ],
        "organization": "OpenAI",
        "metadata": {
            "post_type": "Safety"
        },
        "objects": []
    },
    {
        "id": "d1962a3e021e8e22e6986ad0c3c73d35",
        "source": "openai",
        "type": "research",
        "title": "Defining and evaluating political bias in LLMs",
        "description": "Learn how OpenAI evaluates political bias in ChatGPT through new real-world testing methods that improve objectivity and reduce bias.",
        "url": "https://openai.com/index/defining-and-evaluating-political-bias-in-llms/",
        "published_date": "2025-10-09T13:00:00+00:00",
        "categories": [
            "Research"
        ],
        "organization": "OpenAI",
        "metadata": {
            "post_type": "Research"
        },
        "objects": []
    }
]