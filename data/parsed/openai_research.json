[
    {
        "id": "3601f3ad341eb27939506c0f5e361225",
        "source": "openai",
        "type": "product",
        "title": "Introducing gpt-oss-safeguard",
        "description": "OpenAI introduces gpt-oss-safeguard\u2014open-weight reasoning models for safety classification that let developers apply and iterate on custom policies.",
        "url": "https://openai.com/index/introducing-gpt-oss-safeguard/",
        "published_date": "2025-10-29T00:00:00+00:00",
        "categories": [
            "Product"
        ],
        "organization": "OpenAI",
        "metadata": {
            "post_type": "Product"
        },
        "objects": []
    },
    {
        "id": "954f63c357c5dc716c95f20c1fc7d84f",
        "source": "openai",
        "type": "safety",
        "title": "Technical Report: Performance and baseline evaluations of gpt-oss-safeguard-120b",
        "description": "and gpt-oss-safeguard-20bgpt-oss-safeguard-120b and gpt-oss-safeguard-20b are two open-weight reasoning models post-trained from the gpt-oss models and trained to reason from a provided policy in order to label content under that policy. In this report, we describe gpt-oss-safeguard\u2019s capabilities and provide our baseline safety evaluations on the gpt-oss-safeguard models, using the underlying gpt-oss models as a baseline. For more information about the development and architecture of the underlying gpt-oss models, see the original gpt-oss model model card\u2060.",
        "url": "https://openai.com/index/gpt-oss-safeguard-technical-report/",
        "published_date": "2025-10-29T00:00:00+00:00",
        "categories": [
            "Safety"
        ],
        "organization": "OpenAI",
        "metadata": {
            "post_type": "Safety"
        },
        "objects": []
    },
    {
        "id": "2fad364d831037ee94c4b914d2314855",
        "source": "openai",
        "type": "safety",
        "title": "Addendum to GPT-5 System Card: Sensitive conversations",
        "description": "This system card details GPT-5\u2019s improvements in handling sensitive conversations, including new benchmarks for emotional reliance, mental health, and jailbreak resistance.",
        "url": "https://openai.com/index/gpt-5-system-card-sensitive-conversations/",
        "published_date": "2025-10-27T10:00:00+00:00",
        "categories": [
            "Safety"
        ],
        "organization": "OpenAI",
        "metadata": {
            "post_type": "Safety"
        },
        "objects": []
    },
    {
        "id": "d1962a3e021e8e22e6986ad0c3c73d35",
        "source": "openai",
        "type": "research",
        "title": "Defining and evaluating political bias in LLMs",
        "description": "Learn how OpenAI evaluates political bias in ChatGPT through new real-world testing methods that improve objectivity and reduce bias.",
        "url": "https://openai.com/index/defining-and-evaluating-political-bias-in-llms/",
        "published_date": "2025-10-09T13:00:00+00:00",
        "categories": [
            "Research"
        ],
        "organization": "OpenAI",
        "metadata": {
            "post_type": "Research"
        },
        "objects": []
    },
    {
        "id": "ce22613b413df56e8aef16bec72be34e",
        "source": "openai",
        "type": "product",
        "title": "Codex is now generally available",
        "description": "OpenAI Codex is now generally available with powerful new features for developers: a Slack integration, Codex SDK, and admin tools like usage dashboards and workspace management\u2014making Codex easier to use and manage at scale.",
        "url": "https://openai.com/index/codex-now-generally-available/",
        "published_date": "2025-10-06T10:50:00+00:00",
        "categories": [
            "Product"
        ],
        "organization": "OpenAI",
        "metadata": {
            "post_type": "Product"
        },
        "objects": []
    },
    {
        "id": "2a0868a53977d4037f6e3c736298134c",
        "source": "openai",
        "type": "publication",
        "title": "Sora 2 System Card",
        "description": "Sora 2 is our new state of the art video and audio generation model. Building on the foundation of Sora, this new model introduces capabilities that have been difficult for prior video models to achieve\u2013 such as more accurate physics, sharper realism, synchronized audio, enhanced steerability, and an expanded stylistic range.",
        "url": "https://openai.com/index/sora-2-system-card/",
        "published_date": "2025-09-30T00:00:00+00:00",
        "categories": [
            "Publication"
        ],
        "organization": "OpenAI",
        "metadata": {
            "post_type": "Publication"
        },
        "objects": []
    },
    {
        "id": "46e9bb4fd850bff9a07c7ca3f6ae5e2d",
        "source": "openai",
        "type": "research",
        "title": "Sora 2 is here",
        "description": "Our latest video generation model is more physically accurate, realistic, and controllable than prior systems. It also features synchronized dialogue and sound effects. Create with it in the new Sora app.",
        "url": "https://openai.com/index/sora-2/",
        "published_date": "2025-09-30T00:00:00+00:00",
        "categories": [
            "Research"
        ],
        "organization": "OpenAI",
        "metadata": {
            "post_type": "Research"
        },
        "objects": []
    },
    {
        "id": "26670c67b9bec0773a4f12068a53a83e",
        "source": "openai",
        "type": "publication",
        "title": "Measuring the performance of our models on real-world tasks",
        "description": "OpenAI introduces GDPval, a new evaluation that measures model performance on real-world economically valuable tasks across 44 occupations.",
        "url": "https://openai.com/index/gdpval/",
        "published_date": "2025-09-25T09:00:00+00:00",
        "categories": [
            "Publication"
        ],
        "organization": "OpenAI",
        "metadata": {
            "post_type": "Publication"
        },
        "objects": []
    },
    {
        "id": "aca4dbe0bbebe47c36d11f5a4710396a",
        "source": "openai",
        "type": "publication",
        "title": "Detecting and reducing scheming in AI models",
        "description": "Apollo Research and OpenAI developed evaluations for hidden misalignment (\u201cscheming\u201d) and found behaviors consistent with scheming in controlled tests across frontier models. The team shared concrete examples and stress tests of an early method to reduce scheming.",
        "url": "https://openai.com/index/detecting-and-reducing-scheming-in-ai-models/",
        "published_date": "2025-09-17T00:00:00+00:00",
        "categories": [
            "Publication"
        ],
        "organization": "OpenAI",
        "metadata": {
            "post_type": "Publication"
        },
        "objects": []
    }
]