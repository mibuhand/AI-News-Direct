[
  {
    "id": "8ccd2aceeb4aa375ae3aaa881748eeca",
    "source": "huggingface",
    "type": "paper",
    "title": "Sharing is Caring: Efficient LM Post-Training with Collective RL\n  Experience Sharing",
    "description": "Post-training language models (LMs) with reinforcement learning (RL) can\nenhance their complex reasoning capabilities without supervised fine-tuning, as\ndemonstrated by DeepSeek-R1-Zero. However, effe...<br/>Upvotes: 608<br/>GitHub Stars: 1428<br/>Authors: Jeffrey Amico, Gabriel Passamani Andrade, John Donaghy<br/>ðŸ”— <a href=\"https://github.com/gensyn-ai/rl-swarm\">GitHub</a><br/>ðŸ”— <a href=\"https://blog.gensyn.ai/sapo-efficient-lm-post-training-with-collective-rl/\">Project Page</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2509.08721\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2509.08721",
    "external_url": "https://github.com/gensyn-ai/rl-swarm",
    "published_date": "2025-09-10T12:14:20.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2509.08721",
      "upvotes": 608,
      "github_stars": 1428,
      "github_url": "https://github.com/gensyn-ai/rl-swarm",
      "project_url": "https://blog.gensyn.ai/sapo-efficient-lm-post-training-with-collective-rl/",
      "authors": [
        "Jeffrey Amico",
        "Gabriel Passamani Andrade",
        "John Donaghy",
        "Ben Fielding",
        "Tristin Forbus",
        "Harry Grieve",
        "Semih Kara",
        "Jari Kolehmainen",
        "Yihua Lou",
        "Christopher Nies",
        "Edward Phillip Flores NuÃ±o",
        "Diogo Ortega",
        "Shikhar Rastogi",
        "Austin Virts",
        "Matthew J. Wright"
      ],
      "summary": "Post-training language models (LMs) with reinforcement learning (RL) can\nenhance their complex reasoning capabilities without supervised fine-tuning, as\ndemonstrated by DeepSeek-R1-Zero. However, effectively utilizing RL for LMs\nrequires significant parallelization to scale-up inference, which introduces\nnon-trivial technical challenges (e.g. latency, memory, and reliability)\nalongside ever-growing financial costs. We present Swarm sAmpling Policy\nOptimization (SAPO), a fully decentralized and asynchronous RL post-training\nalgorithm. SAPO is designed for decentralized networks of heterogenous compute\nnodes, where each node manages its own policy model(s) while \"sharing\" rollouts\nwith others in the network; no explicit assumptions about latency, model\nhomogeneity, or hardware are required and nodes can operate in silo if desired.\nAs a result, the algorithm avoids common bottlenecks in scaling RL\npost-training while also allowing (and even encouraging) new possibilities. By\nsampling rollouts \"shared\" across the network, it enables \"Aha moments\" to\npropagate, thereby bootstrapping the learning process. In this paper we show\nSAPO achieved cumulative reward gains of up to 94% in controlled experiments.\nWe also share insights from tests on a network with thousands of nodes\ncontributed by Gensyn community members running the algorithm on diverse\nhardware and models during an open-source demo.",
      "fetch_date": "2025-09-10",
      "num_comments": 52,
      "ai_summary": "Swarm sAmpling Policy Optimization (SAPO) is a decentralized and asynchronous RL algorithm that enhances post-training language models without supervised fine-tuning, achieving significant reward gains and scalability across diverse hardware.",
      "ai_keywords": [
        "reinforcement learning",
        "post-training",
        "language models",
        "DeepSeek-R1-Zero",
        "Swarm sAmpling Policy Optimization",
        "SAPO",
        "decentralized networks",
        "heterogenous compute nodes",
        "policy models",
        "rollouts",
        "cumulative reward gains"
      ]
    }
  },
  {
    "id": "f4b634605f28912c3f352503c72078a6",
    "source": "huggingface",
    "type": "paper",
    "title": "A.S.E: A Repository-Level Benchmark for Evaluating Security in\n  AI-Generated Code",
    "description": "The increasing adoption of large language models (LLMs) in software\nengineering necessitates rigorous security evaluation of their generated code.\nHowever, existing benchmarks often lack relevance to ...<br/>Upvotes: 340<br/>GitHub Stars: 333<br/>Authors: Keke Lian, Bin Wang, Lei Zhang<br/>ðŸ”— <a href=\"https://github.com/Tencent/AICGSecEval\">GitHub</a><br/>ðŸ”— <a href=\"https://aicgseceval.tencent.com/home\">Project Page</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2508.18106\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2508.18106",
    "external_url": "https://github.com/Tencent/AICGSecEval",
    "published_date": "2025-08-25T11:11:11.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2508.18106",
      "upvotes": 340,
      "github_stars": 333,
      "github_url": "https://github.com/Tencent/AICGSecEval",
      "project_url": "https://aicgseceval.tencent.com/home",
      "authors": [
        "Keke Lian",
        "Bin Wang",
        "Lei Zhang",
        "Libo Chen",
        "Junjie Wang",
        "Ziming Zhao",
        "Yujiu Yang",
        "Haotong Duan",
        "Haoran Zhao",
        "Shuang Liao",
        "Mingda Guo",
        "Jiazheng Quan",
        "Yilu Zhong",
        "Chenhao He",
        "Zichuan Chen",
        "Jie Wu",
        "Haoling Li",
        "Zhaoxuan Li",
        "Jiongchi Yu",
        "Hui Li",
        "Dong Zhang"
      ],
      "summary": "The increasing adoption of large language models (LLMs) in software\nengineering necessitates rigorous security evaluation of their generated code.\nHowever, existing benchmarks often lack relevance to real-world AI programming\nscenarios, making them inadequate for assessing the practical security risks\nassociated with AI-generated code in production environments. To address this\ngap, we introduce A.S.E (AI Code Generation Security Evaluation), a\nrepository-level evaluation benchmark designed to closely mirror real-world AI\nprogramming tasks, offering a comprehensive and reliable framework for\nassessing the security of AI-generated code. Our evaluation of leading LLMs on\nA.S.E reveals several key findings. In particular, current LLMs still struggle\nwith secure coding. The complexity in repository-level scenarios presents\nchallenges for LLMs that typically perform well on snippet-level tasks.\nMorever, a larger reasoning budget does not necessarily lead to better code\ngeneration. These observations offer valuable insights into the current state\nof AI code generation, assisting developers in selecting the most appropriate\nmodels for practical tasks, while laying the foundation for refining LLMs to\ngenerate secure and efficient code in real-world applications.",
      "fetch_date": "2025-09-01",
      "num_comments": 4,
      "ai_summary": "A.S.E is a repository-level benchmark for evaluating the security of AI-generated code, highlighting challenges in secure coding and the limitations of LLMs in real-world scenarios.",
      "ai_keywords": [
        "large language models",
        "LLMs",
        "AI code generation",
        "security evaluation",
        "repository-level evaluation",
        "secure coding",
        "reasoning budget"
      ]
    }
  },
  {
    "id": "2a53ea33f47888c723fab2a38e7d2442",
    "source": "huggingface",
    "type": "paper",
    "title": "Drivel-ology: Challenging LLMs with Interpreting Nonsense with Depth",
    "description": "We introduce Drivelology, a unique linguistic phenomenon characterised as\n\"nonsense with depth\", utterances that are syntactically coherent yet\npragmatically paradoxical, emotionally loaded, or rhetor...<br/>Upvotes: 203<br/>GitHub Stars: 6<br/>Authors: Yang Wang, Chenghao Xiao, Chia-Yi Hsiao<br/>ðŸ”— <a href=\"https://github.com/ExtraOrdinaryLab/drivelology\">GitHub</a><br/>ðŸ”— <a href=\"https://huggingface.co/datasets/extraordinarylab/drivel-hub\">Project Page</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2509.03867\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2509.03867",
    "external_url": "https://github.com/ExtraOrdinaryLab/drivelology",
    "published_date": "2025-09-03T23:58:55.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2509.03867",
      "upvotes": 203,
      "github_stars": 6,
      "github_url": "https://github.com/ExtraOrdinaryLab/drivelology",
      "project_url": "https://huggingface.co/datasets/extraordinarylab/drivel-hub",
      "authors": [
        "Yang Wang",
        "Chenghao Xiao",
        "Chia-Yi Hsiao",
        "Zi Yan Chang",
        "Chi-Li Chen",
        "Tyler Loakman",
        "Chenghua Lin"
      ],
      "summary": "We introduce Drivelology, a unique linguistic phenomenon characterised as\n\"nonsense with depth\", utterances that are syntactically coherent yet\npragmatically paradoxical, emotionally loaded, or rhetorically subversive.\nWhile such expressions may resemble surface-level nonsense, they encode\nimplicit meaning requiring contextual inference, moral reasoning, or emotional\ninterpretation. We find that current large language models (LLMs), despite\nexcelling at many natural language processing (NLP) tasks, consistently fail to\ngrasp the layered semantics of Drivelological text. To investigate this, we\nconstruct a small but diverse benchmark dataset of over 1,200 meticulously\ncurated examples, with select instances in English, Mandarin, Spanish, French,\nJapanese, and Korean. Annotation was especially challenging: each of the\nexamples required careful expert review to verify that it truly reflected\nDrivelological characteristics. The process involved multiple rounds of\ndiscussion and adjudication to address disagreements, highlighting the subtle\nand subjective nature of the Drivelology. We evaluate a range of LLMs on\nclassification, generation, and reasoning tasks. Our results reveal clear\nlimitations of LLMs: models often confuse Drivelology with shallow nonsense,\nproduce incoherent justifications, or miss the implied rhetorical function\naltogether. These findings highlight a deeper representational gap in LLMs'\npragmatic understanding and challenge the assumption that statistical fluency\nimplies cognitive comprehension. We release our dataset and code to facilitate\nfurther research in modelling linguistic depth beyond surface-level coherence.",
      "fetch_date": "2025-09-05",
      "num_comments": 10,
      "ai_summary": "LLMs struggle with understanding the nuanced, context-dependent meanings of Drivelological text, which appears nonsensical but contains deeper semantic layers.",
      "ai_keywords": [
        "Drivelology",
        "large language models",
        "LLMs",
        "natural language processing",
        "NLP",
        "benchmark dataset",
        "Drivelological text",
        "classification",
        "generation",
        "reasoning tasks",
        "pragmatic understanding",
        "cognitive comprehension"
      ]
    }
  },
  {
    "id": "b3695a804f022da86db7e28029ec25d4",
    "source": "huggingface",
    "type": "paper",
    "title": "The Landscape of Agentic Reinforcement Learning for LLMs: A Survey",
    "description": "The emergence of agentic reinforcement learning (Agentic RL) marks a paradigm\nshift from conventional reinforcement learning applied to large language models\n(LLM RL), reframing LLMs from passive sequ...<br/>Upvotes: 200<br/>GitHub Stars: 786<br/>Authors: Guibin Zhang, Hejia Geng, Xiaohang Yu<br/>ðŸ”— <a href=\"https://github.com/xhyumiracle/Awesome-AgenticLLM-RL-Papers\">GitHub</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2509.02547\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2509.02547",
    "external_url": "https://github.com/xhyumiracle/Awesome-AgenticLLM-RL-Papers",
    "published_date": "2025-09-02T13:46:26.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2509.02547",
      "upvotes": 200,
      "github_stars": 786,
      "github_url": "https://github.com/xhyumiracle/Awesome-AgenticLLM-RL-Papers",
      "project_url": "",
      "authors": [
        "Guibin Zhang",
        "Hejia Geng",
        "Xiaohang Yu",
        "Zhenfei Yin",
        "Zaibin Zhang",
        "Zelin Tan",
        "Heng Zhou",
        "Zhongzhi Li",
        "Xiangyuan Xue",
        "Yijiang Li",
        "Yifan Zhou",
        "Yang Chen",
        "Chen Zhang",
        "Yutao Fan",
        "Zihu Wang",
        "Songtao Huang",
        "Yue Liao",
        "Hongru Wang",
        "Mengyue Yang",
        "Heng Ji",
        "Michael Littman",
        "Jun Wang",
        "Shuicheng Yan",
        "Philip Torr",
        "Lei Bai"
      ],
      "summary": "The emergence of agentic reinforcement learning (Agentic RL) marks a paradigm\nshift from conventional reinforcement learning applied to large language models\n(LLM RL), reframing LLMs from passive sequence generators into autonomous,\ndecision-making agents embedded in complex, dynamic worlds. This survey\nformalizes this conceptual shift by contrasting the degenerate single-step\nMarkov Decision Processes (MDPs) of LLM-RL with the temporally extended,\npartially observable Markov decision processes (POMDPs) that define Agentic RL.\nBuilding on this foundation, we propose a comprehensive twofold taxonomy: one\norganized around core agentic capabilities, including planning, tool use,\nmemory, reasoning, self-improvement, and perception, and the other around their\napplications across diverse task domains. Central to our thesis is that\nreinforcement learning serves as the critical mechanism for transforming these\ncapabilities from static, heuristic modules into adaptive, robust agentic\nbehavior. To support and accelerate future research, we consolidate the\nlandscape of open-source environments, benchmarks, and frameworks into a\npractical compendium. By synthesizing over five hundred recent works, this\nsurvey charts the contours of this rapidly evolving field and highlights the\nopportunities and challenges that will shape the development of scalable,\ngeneral-purpose AI agents.",
      "fetch_date": "2025-09-03",
      "num_comments": 3,
      "ai_summary": "Agentic reinforcement learning transforms large language models into autonomous decision-making agents by leveraging temporally extended POMDPs, enhancing capabilities like planning and reasoning through reinforcement learning.",
      "ai_keywords": [
        "agentic reinforcement learning",
        "LLM RL",
        "Markov Decision Processes",
        "POMDPs",
        "planning",
        "tool use",
        "memory",
        "reasoning",
        "self-improvement",
        "perception",
        "reinforcement learning",
        "open-source environments",
        "benchmarks",
        "frameworks"
      ]
    }
  },
  {
    "id": "a785dc23394ddf009c4095e44be6b818",
    "source": "huggingface",
    "type": "paper",
    "title": "VLA-Adapter: An Effective Paradigm for Tiny-Scale Vision-Language-Action\n  Model",
    "description": "Vision-Language-Action (VLA) models typically bridge the gap between\nperceptual and action spaces by pre-training a large-scale Vision-Language\nModel (VLM) on robotic data. While this approach greatly...<br/>Upvotes: 191<br/>GitHub Stars: 265<br/>Authors: Yihao Wang, Pengxiang Ding, Lingxiao Li<br/>ðŸ”— <a href=\"https://github.com/OpenHelix-Team/VLA-Adapter\">GitHub</a><br/>ðŸ”— <a href=\"https://vla-adapter.github.io/\">Project Page</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2509.09372\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2509.09372",
    "external_url": "https://github.com/OpenHelix-Team/VLA-Adapter",
    "published_date": "2025-09-11T07:42:21.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2509.09372",
      "upvotes": 191,
      "github_stars": 265,
      "github_url": "https://github.com/OpenHelix-Team/VLA-Adapter",
      "project_url": "https://vla-adapter.github.io/",
      "authors": [
        "Yihao Wang",
        "Pengxiang Ding",
        "Lingxiao Li",
        "Can Cui",
        "Zirui Ge",
        "Xinyang Tong",
        "Wenxuan Song",
        "Han Zhao",
        "Wei Zhao",
        "Pengxu Hou",
        "Siteng Huang",
        "Yifan Tang",
        "Wenhui Wang",
        "Ru Zhang",
        "Jianyi Liu",
        "Donglin Wang"
      ],
      "summary": "Vision-Language-Action (VLA) models typically bridge the gap between\nperceptual and action spaces by pre-training a large-scale Vision-Language\nModel (VLM) on robotic data. While this approach greatly enhances performance,\nit also incurs significant training costs. In this paper, we investigate how to\neffectively bridge vision-language (VL) representations to action (A). We\nintroduce VLA-Adapter, a novel paradigm designed to reduce the reliance of VLA\nmodels on large-scale VLMs and extensive pre-training. To this end, we first\nsystematically analyze the effectiveness of various VL conditions and present\nkey findings on which conditions are essential for bridging perception and\naction spaces. Based on these insights, we propose a lightweight Policy module\nwith Bridge Attention, which autonomously injects the optimal condition into\nthe action space. In this way, our method achieves high performance using only\na 0.5B-parameter backbone, without any robotic data pre-training. Extensive\nexperiments on both simulated and real-world robotic benchmarks demonstrate\nthat VLA-Adapter not only achieves state-of-the-art level performance, but also\noffers the fast inference speed reported to date. Furthermore, thanks to the\nproposed advanced bridging paradigm, VLA-Adapter enables the training of a\npowerful VLA model in just 8 hours on a single consumer-grade GPU, greatly\nlowering the barrier to deploying the VLA model. Project page:\nhttps://vla-adapter.github.io/.",
      "fetch_date": "2025-09-12",
      "num_comments": 4,
      "ai_summary": "VLA-Adapter reduces reliance on large-scale VLMs and extensive pre-training by using a lightweight Policy module with Bridge Attention, achieving state-of-the-art performance and fast inference speed with minimal computational resources.",
      "ai_keywords": [
        "VLA models",
        "Vision-Language Model (VLM)",
        "robotic data",
        "VL conditions",
        "Policy module",
        "Bridge Attention",
        "parameter backbone",
        "simulated benchmarks",
        "real-world benchmarks",
        "inference speed",
        "consumer-grade GPU"
      ]
    }
  },
  {
    "id": "6d87464070be7e367c0d00a7450fa0ba",
    "source": "huggingface",
    "type": "paper",
    "title": "InternVL3.5: Advancing Open-Source Multimodal Models in Versatility,\n  Reasoning, and Efficiency",
    "description": "We introduce InternVL 3.5, a new family of open-source multimodal models that\nsignificantly advances versatility, reasoning capability, and inference\nefficiency along the InternVL series. A key innova...<br/>Upvotes: 191<br/>GitHub Stars: 9218<br/>Authors: Weiyun Wang, Zhangwei Gao, Lixin Gu<br/>ðŸ”— <a href=\"https://github.com/OpenGVLab/InternVL\">GitHub</a><br/>ðŸ”— <a href=\"https://chat.intern-ai.org.cn/\">Project Page</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2508.18265\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2508.18265",
    "external_url": "https://github.com/OpenGVLab/InternVL",
    "published_date": "2025-08-25T13:58:17.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2508.18265",
      "upvotes": 191,
      "github_stars": 9218,
      "github_url": "https://github.com/OpenGVLab/InternVL",
      "project_url": "https://chat.intern-ai.org.cn/",
      "authors": [
        "Weiyun Wang",
        "Zhangwei Gao",
        "Lixin Gu",
        "Hengjun Pu",
        "Long Cui",
        "Xingguang Wei",
        "Zhaoyang Liu",
        "Linglin Jing",
        "Shenglong Ye",
        "Jie Shao",
        "Zhaokai Wang",
        "Zhe Chen",
        "Hongjie Zhang",
        "Ganlin Yang",
        "Haomin Wang",
        "Qi Wei",
        "Jinhui Yin",
        "Wenhao Li",
        "Erfei Cui",
        "Guanzhou Chen",
        "Zichen Ding",
        "Changyao Tian",
        "Zhenyu Wu",
        "Jingjing Xie",
        "Zehao Li",
        "Bowen Yang",
        "Yuchen Duan",
        "Xuehui Wang",
        "Songze Li",
        "Xiangyu Zhao",
        "Haodong Duan",
        "Nianchen Deng",
        "Bin Fu",
        "Yinan He",
        "Yi Wang",
        "Conghui He",
        "Botian Shi",
        "Junjun He",
        "Yingtong Xiong",
        "Han Lv",
        "Lijun Wu",
        "Wenqi Shao",
        "Kaipeng Zhang",
        "Huipeng Deng",
        "Biqing Qi",
        "Jiaye Ge",
        "Qipeng Guo",
        "Wenwei Zhang",
        "Wanli Ouyang",
        "Limin Wang",
        "Min Dou",
        "Xizhou Zhu",
        "Tong Lu",
        "Dahua Lin",
        "Jifeng Dai",
        "Bowen Zhou",
        "Weijie Su",
        "Kai Chen",
        "Yu Qiao",
        "Wenhai Wang",
        "Gen Luo"
      ],
      "summary": "We introduce InternVL 3.5, a new family of open-source multimodal models that\nsignificantly advances versatility, reasoning capability, and inference\nefficiency along the InternVL series. A key innovation is the Cascade\nReinforcement Learning (Cascade RL) framework, which enhances reasoning through\na two-stage process: offline RL for stable convergence and online RL for\nrefined alignment. This coarse-to-fine training strategy leads to substantial\nimprovements on downstream reasoning tasks, e.g., MMMU and MathVista. To\noptimize efficiency, we propose a Visual Resolution Router (ViR) that\ndynamically adjusts the resolution of visual tokens without compromising\nperformance. Coupled with ViR, our Decoupled Vision-Language Deployment (DvD)\nstrategy separates the vision encoder and language model across different GPUs,\neffectively balancing computational load. These contributions collectively\nenable InternVL3.5 to achieve up to a +16.0\\% gain in overall reasoning\nperformance and a 4.05times inference speedup compared to its predecessor,\ni.e., InternVL3. In addition, InternVL3.5 supports novel capabilities such as\nGUI interaction and embodied agency. Notably, our largest model, i.e.,\nInternVL3.5-241B-A28B, attains state-of-the-art results among open-source MLLMs\nacross general multimodal, reasoning, text, and agentic tasks -- narrowing the\nperformance gap with leading commercial models like GPT-5. All models and code\nare publicly released.",
      "fetch_date": "2025-08-26",
      "num_comments": 8,
      "ai_summary": "InternVL 3.5 introduces Cascade RL, ViR, and DvD to enhance reasoning, efficiency, and performance in multimodal models.",
      "ai_keywords": [
        "Cascade RL",
        "offline RL",
        "online RL",
        "Visual Resolution Router",
        "ViR",
        "Decoupled Vision-Language Deployment",
        "DvD",
        "multimodal models",
        "reasoning performance",
        "inference speedup",
        "GUI interaction",
        "embodied agency"
      ]
    }
  },
  {
    "id": "27945bd6f1634bfd914ab287d0fdaf8e",
    "source": "huggingface",
    "type": "paper",
    "title": "WebWeaver: Structuring Web-Scale Evidence with Dynamic Outlines for\n  Open-Ended Deep Research",
    "description": "This paper tackles open-ended deep research (OEDR), a complex challenge where\nAI agents must synthesize vast web-scale information into insightful reports.\nCurrent approaches are plagued by dual-fold ...<br/>Upvotes: 97<br/>GitHub Stars: 14153<br/>Authors: Zijian Li, Xin Guan, Bo Zhang<br/>ðŸ”— <a href=\"https://github.com/Alibaba-NLP/DeepResearch\">GitHub</a><br/>ðŸ”— <a href=\"https://tongyi-agent.github.io/blog/\">Project Page</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2509.13312\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2509.13312",
    "external_url": "https://github.com/Alibaba-NLP/DeepResearch",
    "published_date": "2025-09-16T13:57:21.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2509.13312",
      "upvotes": 97,
      "github_stars": 14153,
      "github_url": "https://github.com/Alibaba-NLP/DeepResearch",
      "project_url": "https://tongyi-agent.github.io/blog/",
      "authors": [
        "Zijian Li",
        "Xin Guan",
        "Bo Zhang",
        "Shen Huang",
        "Houquan Zhou",
        "Shaopeng Lai",
        "Ming Yan",
        "Yong Jiang",
        "Pengjun Xie",
        "Fei Huang",
        "Jun Zhang",
        "Jingren Zhou"
      ],
      "summary": "This paper tackles open-ended deep research (OEDR), a complex challenge where\nAI agents must synthesize vast web-scale information into insightful reports.\nCurrent approaches are plagued by dual-fold limitations: static research\npipelines that decouple planning from evidence acquisition and one-shot\ngeneration paradigms that easily suffer from long-context failure issues like\n\"loss in the middle\" and hallucinations. To address these challenges, we\nintroduce WebWeaver, a novel dual-agent framework that emulates the human\nresearch process. The planner operates in a dynamic cycle, iteratively\ninterleaving evidence acquisition with outline optimization to produce a\ncomprehensive, source-grounded outline linking to a memory bank of evidence.\nThe writer then executes a hierarchical retrieval and writing process,\ncomposing the report section by section. By performing targeted retrieval of\nonly the necessary evidence from the memory bank for each part, it effectively\nmitigates long-context issues. Our framework establishes a new state-of-the-art\nacross major OEDR benchmarks, including DeepResearch Bench, DeepConsult, and\nDeepResearchGym. These results validate our human-centric, iterative\nmethodology, demonstrating that adaptive planning and focused synthesis are\ncrucial for producing high-quality, reliable, and well-structured reports.",
      "fetch_date": "2025-09-17",
      "num_comments": 5,
      "ai_summary": "WebWeaver, a dual-agent framework, addresses open-ended deep research challenges by integrating adaptive planning and focused synthesis to produce high-quality, reliable reports.",
      "ai_keywords": [
        "open-ended deep research",
        "AI agents",
        "static research pipelines",
        "one-shot generation",
        "long-context failure",
        "loss in the middle",
        "hallucinations",
        "dual-agent framework",
        "human research process",
        "planner",
        "evidence acquisition",
        "outline optimization",
        "memory bank",
        "writer",
        "hierarchical retrieval",
        "writing process",
        "DeepResearch Bench",
        "DeepConsult",
        "DeepResearchGym"
      ]
    }
  },
  {
    "id": "17d435d0d4a4864c8247d4e12399b781",
    "source": "huggingface",
    "type": "paper",
    "title": "Scaling Agents via Continual Pre-training",
    "description": "Large language models (LLMs) have evolved into agentic systems capable of\nautonomous tool use and multi-step reasoning for complex problem-solving.\nHowever, post-training approaches building upon gene...<br/>Upvotes: 97<br/>GitHub Stars: 14153<br/>Authors: Liangcai Su, Zhen Zhang, Guangyu Li<br/>ðŸ”— <a href=\"https://github.com/Alibaba-NLP/DeepResearch///\">GitHub</a><br/>ðŸ”— <a href=\"https://tongyi-agent.github.io/blog/\">Project Page</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2509.13310\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2509.13310",
    "external_url": "https://github.com/Alibaba-NLP/DeepResearch///",
    "published_date": "2025-09-16T13:57:19.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2509.13310",
      "upvotes": 97,
      "github_stars": 14153,
      "github_url": "https://github.com/Alibaba-NLP/DeepResearch///",
      "project_url": "https://tongyi-agent.github.io/blog/",
      "authors": [
        "Liangcai Su",
        "Zhen Zhang",
        "Guangyu Li",
        "Zhuo Chen",
        "Chenxi Wang",
        "Maojia Song",
        "Xinyu Wang",
        "Kuan Li",
        "Jialong Wu",
        "Xuanzhong Chen",
        "Zile Qiao",
        "Zhongwang Zhang",
        "Huifeng Yin",
        "Shihao Cai",
        "Runnan Fang",
        "Zhengwei Tao",
        "Wenbiao Yin",
        "Chenxiong Qian",
        "Yong Jiang",
        "Pengjun Xie",
        "Fei Huang",
        "Jingren Zhou"
      ],
      "summary": "Large language models (LLMs) have evolved into agentic systems capable of\nautonomous tool use and multi-step reasoning for complex problem-solving.\nHowever, post-training approaches building upon general-purpose foundation\nmodels consistently underperform in agentic tasks, particularly in open-source\nimplementations. We identify the root cause: the absence of robust agentic\nfoundation models forces models during post-training to simultaneously learn\ndiverse agentic behaviors while aligning them to expert demonstrations, thereby\ncreating fundamental optimization tensions. To this end, we are the first to\npropose incorporating Agentic Continual Pre-training (Agentic CPT) into the\ndeep research agents training pipeline to build powerful agentic foundational\nmodels. Based on this approach, we develop a deep research agent model named\nAgentFounder. We evaluate our AgentFounder-30B on 10 benchmarks and achieve\nstate-of-the-art performance while retains strong tool-use ability, notably\n39.9% on BrowseComp-en, 43.3% on BrowseComp-zh, and 31.5% Pass@1 on HLE.",
      "fetch_date": "2025-09-17",
      "num_comments": 9,
      "ai_summary": "AgentFounder, a deep research agent model incorporating Agentic Continual Pre-training, achieves state-of-the-art performance in agentic tasks while maintaining strong tool-use ability.",
      "ai_keywords": [
        "Large language models",
        "agentic systems",
        "autonomous tool use",
        "multi-step reasoning",
        "post-training approaches",
        "general-purpose foundation models",
        "agentic foundation models",
        "Agentic Continual Pre-training",
        "deep research agents",
        "AgentFounder",
        "BrowseComp-en",
        "BrowseComp-zh",
        "HLE"
      ]
    }
  },
  {
    "id": "d4b4f91354d2792a0826158fb9d00e0b",
    "source": "huggingface",
    "type": "paper",
    "title": "WebSailor-V2: Bridging the Chasm to Proprietary Agents via Synthetic\n  Data and Scalable Reinforcement Learning",
    "description": "Transcending human cognitive limitations represents a critical frontier in\nLLM training. Proprietary agentic systems like DeepResearch have demonstrated\nsuperhuman capabilities on extremely complex in...<br/>Upvotes: 78<br/>GitHub Stars: 14153<br/>Authors: Kuan Li, Zhongwang Zhang, Huifeng Yin<br/>ðŸ”— <a href=\"https://github.com/Alibaba-NLP/DeepResearch/\">GitHub</a><br/>ðŸ”— <a href=\"https://tongyi-agent.github.io/blog/\">Project Page</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2509.13305\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2509.13305",
    "external_url": "https://github.com/Alibaba-NLP/DeepResearch/",
    "published_date": "2025-09-16T13:57:03.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2509.13305",
      "upvotes": 78,
      "github_stars": 14153,
      "github_url": "https://github.com/Alibaba-NLP/DeepResearch/",
      "project_url": "https://tongyi-agent.github.io/blog/",
      "authors": [
        "Kuan Li",
        "Zhongwang Zhang",
        "Huifeng Yin",
        "Rui Ye",
        "Yida Zhao",
        "Liwen Zhang",
        "Litu Ou",
        "Dingchu Zhang",
        "Xixi Wu",
        "Jialong Wu",
        "Xinyu Wang",
        "Zile Qiao",
        "Zhen Zhang",
        "Yong Jiang",
        "Pengjun Xie",
        "Fei Huang",
        "Jingren Zhou"
      ],
      "summary": "Transcending human cognitive limitations represents a critical frontier in\nLLM training. Proprietary agentic systems like DeepResearch have demonstrated\nsuperhuman capabilities on extremely complex information-seeking benchmarks\nsuch as BrowseComp, a feat previously unattainable. We posit that their success\nhinges on a sophisticated reasoning pattern absent in open-source models: the\nability to systematically reduce extreme uncertainty when navigating vast\ninformation landscapes. Based on this insight, we introduce WebSailor, a\ncomplete post-training methodology designed to instill this crucial capability.\nOur approach involves generating novel, high-uncertainty tasks through\nstructured sampling and information obfuscation, RFT cold start, and an\nefficient agentic RL training algorithm, Duplicating Sampling Policy\nOptimization (DUPO). With this integrated pipeline, WebSailor significantly\noutperforms all open-source agents in complex information-seeking tasks,\nmatching proprietary agents' performance and closing the capability gap.",
      "fetch_date": "2025-09-17",
      "num_comments": 4,
      "ai_summary": "WebSailor, a post-training methodology, enhances open-source models with systematic uncertainty reduction, matching proprietary agents' performance in complex information-seeking tasks.",
      "ai_keywords": [
        "LLM training",
        "DeepResearch",
        "BrowseComp",
        "reasoning pattern",
        "high-uncertainty tasks",
        "structured sampling",
        "information obfuscation",
        "RFT cold start",
        "agentic RL training",
        "Duplicating Sampling Policy Optimization",
        "DUPO"
      ]
    }
  },
  {
    "id": "56ef9e3095cf3666002acddf23dee4ac",
    "source": "huggingface",
    "type": "paper",
    "title": "ReSum: Unlocking Long-Horizon Search Intelligence via Context\n  Summarization",
    "description": "Large Language Model (LLM)-based web agents demonstrate strong performance on\nknowledge-intensive tasks but are hindered by context window limitations in\nparadigms like ReAct. Complex queries involvin...<br/>Upvotes: 67<br/>GitHub Stars: 14153<br/>Authors: Xixi Wu, Kuan Li, Yida Zhao<br/>ðŸ”— <a href=\"https://github.com/Alibaba-NLP/DeepResearch//\">GitHub</a><br/>ðŸ”— <a href=\"https://tongyi-agent.github.io/blog/\">Project Page</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2509.13313\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2509.13313",
    "external_url": "https://github.com/Alibaba-NLP/DeepResearch//",
    "published_date": "2025-09-16T13:57:22.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2509.13313",
      "upvotes": 67,
      "github_stars": 14153,
      "github_url": "https://github.com/Alibaba-NLP/DeepResearch//",
      "project_url": "https://tongyi-agent.github.io/blog/",
      "authors": [
        "Xixi Wu",
        "Kuan Li",
        "Yida Zhao",
        "Liwen Zhang",
        "Litu Ou",
        "Huifeng Yin",
        "Zhongwang Zhang",
        "Yong Jiang",
        "Pengjun Xie",
        "Fei Huang",
        "Minhao Cheng",
        "Shuai Wang",
        "Hong Cheng",
        "Jingren Zhou"
      ],
      "summary": "Large Language Model (LLM)-based web agents demonstrate strong performance on\nknowledge-intensive tasks but are hindered by context window limitations in\nparadigms like ReAct. Complex queries involving multiple entities, intertwined\nrelationships, and high uncertainty demand extensive search cycles that rapidly\nexhaust context budgets before reaching complete solutions. To overcome this\nchallenge, we introduce ReSum, a novel paradigm that enables indefinite\nexploration through periodic context summarization. ReSum converts growing\ninteraction histories into compact reasoning states, maintaining awareness of\nprior discoveries while bypassing context constraints. For paradigm adaptation,\nwe propose ReSum-GRPO, integrating GRPO with segmented trajectory training and\nadvantage broadcasting to familiarize agents with summary-conditioned\nreasoning. Extensive experiments on web agents of varying scales across three\nbenchmarks demonstrate that ReSum delivers an average absolute improvement of\n4.5\\% over ReAct, with further gains of up to 8.2\\% following ReSum-GRPO\ntraining. Notably, with only 1K training samples, our WebResummer-30B (a\nReSum-GRPO-trained version of WebSailor-30B) achieves 33.3\\% Pass@1 on\nBrowseComp-zh and 18.3\\% on BrowseComp-en, surpassing existing open-source web\nagents.",
      "fetch_date": "2025-09-17",
      "num_comments": 5,
      "ai_summary": "ReSum, a novel paradigm with periodic context summarization, enhances web agents' performance on knowledge-intensive tasks by overcoming context window limitations, achieving significant improvements over ReAct.",
      "ai_keywords": [
        "Large Language Model",
        "LLM",
        "web agents",
        "knowledge-intensive tasks",
        "context window limitations",
        "ReAct",
        "ReSum",
        "context summarization",
        "reasoning states",
        "GRPO",
        "segmented trajectory training",
        "advantage broadcasting",
        "ReSum-GRPO",
        "WebResummer-30B",
        "WebSailor-30B",
        "BrowseComp-zh",
        "BrowseComp-en",
        "Pass@1"
      ]
    }
  },
  {
    "id": "0ed9910aac99440f4f67d70de1502ed7",
    "source": "huggingface",
    "type": "paper",
    "title": "AgentScope 1.0: A Developer-Centric Framework for Building Agentic\n  Applications",
    "description": "Driven by rapid advancements of Large Language Models (LLMs), agents are\nempowered to combine intrinsic knowledge with dynamic tool use, greatly\nenhancing their capacity to address real-world tasks. I...<br/>Upvotes: 49<br/>GitHub Stars: 12329<br/>Authors: Dawei Gao, Zitao Li, Yuexiang Xie<br/>ðŸ”— <a href=\"https://github.com/agentscope-ai/agentscope\">GitHub</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2508.16279\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2508.16279",
    "external_url": "https://github.com/agentscope-ai/agentscope",
    "published_date": "2025-08-22T06:35:56.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2508.16279",
      "upvotes": 49,
      "github_stars": 12329,
      "github_url": "https://github.com/agentscope-ai/agentscope",
      "project_url": "",
      "authors": [
        "Dawei Gao",
        "Zitao Li",
        "Yuexiang Xie",
        "Weirui Kuang",
        "Liuyi Yao",
        "Bingchen Qian",
        "Zhijian Ma",
        "Yue Cui",
        "Haohao Luo",
        "Shen Li",
        "Lu Yi",
        "Yi Yu",
        "Shiqi He",
        "Zhiling Luo",
        "Wenmeng Zhou",
        "Zhicheng Zhang",
        "Xuguang He",
        "Ziqian Chen",
        "Weikai Liao",
        "Farruh Isakulovich Kushnazarov",
        "Yaliang Li",
        "Bolin Ding",
        "Jingren Zhou"
      ],
      "summary": "Driven by rapid advancements of Large Language Models (LLMs), agents are\nempowered to combine intrinsic knowledge with dynamic tool use, greatly\nenhancing their capacity to address real-world tasks. In line with such an\nevolution, AgentScope introduces major improvements in a new version (1.0),\ntowards comprehensively supporting flexible and efficient tool-based\nagent-environment interactions for building agentic applications. Specifically,\nwe abstract foundational components essential for agentic applications and\nprovide unified interfaces and extensible modules, enabling developers to\neasily leverage the latest progress, such as new models and MCPs. Furthermore,\nwe ground agent behaviors in the ReAct paradigm and offer advanced agent-level\ninfrastructure based on a systematic asynchronous design, which enriches both\nhuman-agent and agent-agent interaction patterns while improving execution\nefficiency. Building on this foundation, we integrate several built-in agents\ntailored to specific practical scenarios. AgentScope also includes robust\nengineering support for developer-friendly experiences. We provide a scalable\nevaluation module with a visual studio interface, making the development of\nlong-trajectory agentic applications more manageable and easier to trace. In\naddition, AgentScope offers a runtime sandbox to ensure safe agent execution\nand facilitates rapid deployment in production environments. With these\nenhancements, AgentScope provides a practical foundation for building scalable,\nadaptive, and effective agentic applications.",
      "fetch_date": "2025-08-25",
      "num_comments": 4,
      "ai_summary": "AgentScope enhances agentic applications by providing flexible tool-based interactions, unified interfaces, and advanced infrastructure based on the ReAct paradigm, supporting efficient and safe development and deployment.",
      "ai_keywords": [
        "Large Language Models",
        "LLMs",
        "AgentScope",
        "tool-based agent-environment interactions",
        "ReAct paradigm",
        "asynchronous design",
        "human-agent interactions",
        "agent-agent interactions",
        "built-in agents",
        "scalable evaluation module",
        "visual studio interface",
        "runtime sandbox"
      ]
    }
  }
]