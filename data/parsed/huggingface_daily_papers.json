[
  {
    "id": "8ccd2aceeb4aa375ae3aaa881748eeca",
    "source": "huggingface",
    "type": "paper",
    "title": "Sharing is Caring: Efficient LM Post-Training with Collective RL\n  Experience Sharing",
    "description": "Post-training language models (LMs) with reinforcement learning (RL) can\nenhance their complex reasoning capabilities without supervised fine-tuning, as\ndemonstrated by DeepSeek-R1-Zero. However, effe...<br/>Upvotes: 669<br/>GitHub Stars: 1492<br/>Authors: Jeffrey Amico, Gabriel Passamani Andrade, John Donaghy<br/>ðŸ”— <a href=\"https://github.com/gensyn-ai/rl-swarm\">GitHub</a><br/>ðŸ”— <a href=\"https://blog.gensyn.ai/sapo-efficient-lm-post-training-with-collective-rl/\">Project Page</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2509.08721\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2509.08721",
    "external_url": "https://github.com/gensyn-ai/rl-swarm",
    "published_date": "2025-09-10T12:14:20.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2509.08721",
      "upvotes": 669,
      "github_stars": 1492,
      "github_url": "https://github.com/gensyn-ai/rl-swarm",
      "project_url": "https://blog.gensyn.ai/sapo-efficient-lm-post-training-with-collective-rl/",
      "authors": [
        "Jeffrey Amico",
        "Gabriel Passamani Andrade",
        "John Donaghy",
        "Ben Fielding",
        "Tristin Forbus",
        "Harry Grieve",
        "Semih Kara",
        "Jari Kolehmainen",
        "Yihua Lou",
        "Christopher Nies",
        "Edward Phillip Flores NuÃ±o",
        "Diogo Ortega",
        "Shikhar Rastogi",
        "Austin Virts",
        "Matthew J. Wright"
      ],
      "summary": "Post-training language models (LMs) with reinforcement learning (RL) can\nenhance their complex reasoning capabilities without supervised fine-tuning, as\ndemonstrated by DeepSeek-R1-Zero. However, effectively utilizing RL for LMs\nrequires significant parallelization to scale-up inference, which introduces\nnon-trivial technical challenges (e.g. latency, memory, and reliability)\nalongside ever-growing financial costs. We present Swarm sAmpling Policy\nOptimization (SAPO), a fully decentralized and asynchronous RL post-training\nalgorithm. SAPO is designed for decentralized networks of heterogenous compute\nnodes, where each node manages its own policy model(s) while \"sharing\" rollouts\nwith others in the network; no explicit assumptions about latency, model\nhomogeneity, or hardware are required and nodes can operate in silo if desired.\nAs a result, the algorithm avoids common bottlenecks in scaling RL\npost-training while also allowing (and even encouraging) new possibilities. By\nsampling rollouts \"shared\" across the network, it enables \"Aha moments\" to\npropagate, thereby bootstrapping the learning process. In this paper we show\nSAPO achieved cumulative reward gains of up to 94% in controlled experiments.\nWe also share insights from tests on a network with thousands of nodes\ncontributed by Gensyn community members running the algorithm on diverse\nhardware and models during an open-source demo.",
      "fetch_date": "2025-09-10",
      "num_comments": 53,
      "ai_summary": "Swarm sAmpling Policy Optimization (SAPO) is a decentralized and asynchronous RL algorithm that enhances post-training language models without supervised fine-tuning, achieving significant reward gains and scalability across diverse hardware.",
      "ai_keywords": [
        "reinforcement learning",
        "post-training",
        "language models",
        "DeepSeek-R1-Zero",
        "Swarm sAmpling Policy Optimization",
        "SAPO",
        "decentralized networks",
        "heterogenous compute nodes",
        "policy models",
        "rollouts",
        "cumulative reward gains"
      ]
    }
  },
  {
    "id": "7a9ae43171e964d5b9a58c9a76f8c373",
    "source": "huggingface",
    "type": "paper",
    "title": "The Dragon Hatchling: The Missing Link between the Transformer and\n  Models of the Brain",
    "description": "The relationship between computing systems and the brain has served as\nmotivation for pioneering theoreticians since John von Neumann and Alan Turing.\nUniform, scale-free biological networks, such as ...<br/>Upvotes: 449<br/>GitHub Stars: 3004<br/>Authors: Adrian Kosowski, PrzemysÅ‚aw UznaÅ„ski, Jan Chorowski<br/>ðŸ”— <a href=\"https://github.com/pathwaycom/bdh\">GitHub</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2509.26507\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2509.26507",
    "external_url": "https://github.com/pathwaycom/bdh",
    "published_date": "2025-09-30T12:49:01.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2509.26507",
      "upvotes": 449,
      "github_stars": 3004,
      "github_url": "https://github.com/pathwaycom/bdh",
      "project_url": "",
      "authors": [
        "Adrian Kosowski",
        "PrzemysÅ‚aw UznaÅ„ski",
        "Jan Chorowski",
        "Zuzanna Stamirowska",
        "MichaÅ‚ Bartoszkiewicz"
      ],
      "summary": "The relationship between computing systems and the brain has served as\nmotivation for pioneering theoreticians since John von Neumann and Alan Turing.\nUniform, scale-free biological networks, such as the brain, have powerful\nproperties, including generalizing over time, which is the main barrier for\nMachine Learning on the path to Universal Reasoning Models.\n  We introduce `Dragon Hatchling' (BDH), a new Large Language Model\narchitecture based on a scale-free biologically inspired network of \\n\nlocally-interacting neuron particles. BDH couples strong theoretical\nfoundations and inherent interpretability without sacrificing Transformer-like\nperformance.\n  BDH is a practical, performant state-of-the-art attention-based state space\nsequence learning architecture. In addition to being a graph model, BDH admits\na GPU-friendly formulation. It exhibits Transformer-like scaling laws:\nempirically BDH rivals GPT2 performance on language and translation tasks, at\nthe same number of parameters (10M to 1B), for the same training data.\n  BDH can be represented as a brain model. The working memory of BDH during\ninference entirely relies on synaptic plasticity with Hebbian learning using\nspiking neurons. We confirm empirically that specific, individual synapses\nstrengthen connection whenever BDH hears or reasons about a specific concept\nwhile processing language inputs. The neuron interaction network of BDH is a\ngraph of high modularity with heavy-tailed degree distribution. The BDH model\nis biologically plausible, explaining one possible mechanism which human\nneurons could use to achieve speech.\n  BDH is designed for interpretability. Activation vectors of BDH are sparse\nand positive. We demonstrate monosemanticity in BDH on language tasks.\nInterpretability of state, which goes beyond interpretability of neurons and\nmodel parameters, is an inherent feature of the BDH architecture.",
      "fetch_date": "2025-10-01",
      "num_comments": 14,
      "ai_summary": "BDH, a biologically inspired Large Language Model, combines scale-free network architecture with Hebbian learning to achieve Transformer-like performance while maintaining interpretability.",
      "ai_keywords": [
        "Large Language Model",
        "scale-free network",
        "Hebbian learning",
        "synaptic plasticity",
        "spiking neurons",
        "graph model",
        "GPU-friendly",
        "Transformer-like scaling laws",
        "monosemanticity",
        "interpretability"
      ]
    }
  },
  {
    "id": "3d55a02b14bdc7a04256ce32475eb075",
    "source": "huggingface",
    "type": "paper",
    "title": "Less is More: Recursive Reasoning with Tiny Networks",
    "description": "Hierarchical Reasoning Model (HRM) is a novel approach using two small neural\nnetworks recursing at different frequencies. This biologically inspired method\nbeats Large Language models (LLMs) on hard ...<br/>Upvotes: 246<br/>GitHub Stars: 2969<br/>Authors: Alexia Jolicoeur-Martineau<br/>ðŸ”— <a href=\"https://github.com/SamsungSAILMontreal/TinyRecursiveModels\">GitHub</a><br/>ðŸ”— <a href=\"https://alexiajm.github.io/2025/09/29/tiny_recursive_models.html#\">Project Page</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2510.04871\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2510.04871",
    "external_url": "https://github.com/SamsungSAILMontreal/TinyRecursiveModels",
    "published_date": "2025-10-06T10:58:08.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2510.04871",
      "upvotes": 246,
      "github_stars": 2969,
      "github_url": "https://github.com/SamsungSAILMontreal/TinyRecursiveModels",
      "project_url": "https://alexiajm.github.io/2025/09/29/tiny_recursive_models.html#",
      "authors": [
        "Alexia Jolicoeur-Martineau"
      ],
      "summary": "Hierarchical Reasoning Model (HRM) is a novel approach using two small neural\nnetworks recursing at different frequencies. This biologically inspired method\nbeats Large Language models (LLMs) on hard puzzle tasks such as Sudoku, Maze,\nand ARC-AGI while trained with small models (27M parameters) on small data\n(around 1000 examples). HRM holds great promise for solving hard problems with\nsmall networks, but it is not yet well understood and may be suboptimal. We\npropose Tiny Recursive Model (TRM), a much simpler recursive reasoning approach\nthat achieves significantly higher generalization than HRM, while using a\nsingle tiny network with only 2 layers. With only 7M parameters, TRM obtains\n45% test-accuracy on ARC-AGI-1 and 8% on ARC-AGI-2, higher than most LLMs\n(e.g., Deepseek R1, o3-mini, Gemini 2.5 Pro) with less than 0.01% of the\nparameters.",
      "fetch_date": "2025-10-08",
      "num_comments": 11,
      "ai_summary": "Tiny Recursive Model (TRM) achieves high generalization on complex puzzle tasks using a small, two-layer network with minimal parameters, outperforming larger language models.",
      "ai_keywords": [
        "Hierarchical Reasoning Model",
        "HRM",
        "Tiny Recursive Model",
        "TRM",
        "recursive reasoning",
        "neural networks",
        "ARC-AGI",
        "Deepseek R1",
        "o3-mini",
        "Gemini 2.5 Pro"
      ]
    }
  },
  {
    "id": "a785dc23394ddf009c4095e44be6b818",
    "source": "huggingface",
    "type": "paper",
    "title": "VLA-Adapter: An Effective Paradigm for Tiny-Scale Vision-Language-Action\n  Model",
    "description": "Vision-Language-Action (VLA) models typically bridge the gap between\nperceptual and action spaces by pre-training a large-scale Vision-Language\nModel (VLM) on robotic data. While this approach greatly...<br/>Upvotes: 224<br/>GitHub Stars: 915<br/>Authors: Yihao Wang, Pengxiang Ding, Lingxiao Li<br/>ðŸ”— <a href=\"https://github.com/OpenHelix-Team/VLA-Adapter\">GitHub</a><br/>ðŸ”— <a href=\"https://vla-adapter.github.io/\">Project Page</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2509.09372\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2509.09372",
    "external_url": "https://github.com/OpenHelix-Team/VLA-Adapter",
    "published_date": "2025-09-11T07:42:21.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2509.09372",
      "upvotes": 224,
      "github_stars": 915,
      "github_url": "https://github.com/OpenHelix-Team/VLA-Adapter",
      "project_url": "https://vla-adapter.github.io/",
      "authors": [
        "Yihao Wang",
        "Pengxiang Ding",
        "Lingxiao Li",
        "Can Cui",
        "Zirui Ge",
        "Xinyang Tong",
        "Wenxuan Song",
        "Han Zhao",
        "Wei Zhao",
        "Pengxu Hou",
        "Siteng Huang",
        "Yifan Tang",
        "Wenhui Wang",
        "Ru Zhang",
        "Jianyi Liu",
        "Donglin Wang"
      ],
      "summary": "Vision-Language-Action (VLA) models typically bridge the gap between\nperceptual and action spaces by pre-training a large-scale Vision-Language\nModel (VLM) on robotic data. While this approach greatly enhances performance,\nit also incurs significant training costs. In this paper, we investigate how to\neffectively bridge vision-language (VL) representations to action (A). We\nintroduce VLA-Adapter, a novel paradigm designed to reduce the reliance of VLA\nmodels on large-scale VLMs and extensive pre-training. To this end, we first\nsystematically analyze the effectiveness of various VL conditions and present\nkey findings on which conditions are essential for bridging perception and\naction spaces. Based on these insights, we propose a lightweight Policy module\nwith Bridge Attention, which autonomously injects the optimal condition into\nthe action space. In this way, our method achieves high performance using only\na 0.5B-parameter backbone, without any robotic data pre-training. Extensive\nexperiments on both simulated and real-world robotic benchmarks demonstrate\nthat VLA-Adapter not only achieves state-of-the-art level performance, but also\noffers the fast inference speed reported to date. Furthermore, thanks to the\nproposed advanced bridging paradigm, VLA-Adapter enables the training of a\npowerful VLA model in just 8 hours on a single consumer-grade GPU, greatly\nlowering the barrier to deploying the VLA model. Project page:\nhttps://vla-adapter.github.io/.",
      "fetch_date": "2025-09-12",
      "num_comments": 6,
      "ai_summary": "VLA-Adapter reduces reliance on large-scale VLMs and extensive pre-training by using a lightweight Policy module with Bridge Attention, achieving state-of-the-art performance and fast inference speed with minimal computational resources.",
      "ai_keywords": [
        "VLA models",
        "Vision-Language Model (VLM)",
        "robotic data",
        "VL conditions",
        "Policy module",
        "Bridge Attention",
        "parameter backbone",
        "simulated benchmarks",
        "real-world benchmarks",
        "inference speed",
        "consumer-grade GPU"
      ]
    }
  },
  {
    "id": "5b09690dc892c88c31036888ff90135f",
    "source": "huggingface",
    "type": "paper",
    "title": "A Survey of Reinforcement Learning for Large Reasoning Models",
    "description": "In this paper, we survey recent advances in Reinforcement Learning (RL) for\nreasoning with Large Language Models (LLMs). RL has achieved remarkable success\nin advancing the frontier of LLM capabilitie...<br/>Upvotes: 177<br/>GitHub Stars: 1721<br/>Authors: Kaiyan Zhang, Yuxin Zuo, Bingxiang He<br/>ðŸ”— <a href=\"https://github.com/TsinghuaC3I/Awesome-RL-for-LRMs\">GitHub</a><br/>ðŸ”— <a href=\"https://github.com/TsinghuaC3I/Awesome-RL-for-LRMs\">Project Page</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2509.08827\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2509.08827",
    "external_url": "https://github.com/TsinghuaC3I/Awesome-RL-for-LRMs",
    "published_date": "2025-09-10T13:59:43.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2509.08827",
      "upvotes": 177,
      "github_stars": 1721,
      "github_url": "https://github.com/TsinghuaC3I/Awesome-RL-for-LRMs",
      "project_url": "https://github.com/TsinghuaC3I/Awesome-RL-for-LRMs",
      "authors": [
        "Kaiyan Zhang",
        "Yuxin Zuo",
        "Bingxiang He",
        "Youbang Sun",
        "Runze Liu",
        "Che Jiang",
        "Yuchen Fan",
        "Kai Tian",
        "Guoli Jia",
        "Pengfei Li",
        "Yu Fu",
        "Xingtai Lv",
        "Yuchen Zhang",
        "Sihang Zeng",
        "Shang Qu",
        "Haozhan Li",
        "Shijie Wang",
        "Yuru Wang",
        "Xinwei Long",
        "Fangfu Liu",
        "Xiang Xu",
        "Jiaze Ma",
        "Xuekai Zhu",
        "Ermo Hua",
        "Yihao Liu",
        "Zonglin Li",
        "Huayu Chen",
        "Xiaoye Qu",
        "Yafu Li",
        "Weize Chen",
        "Zhenzhao Yuan",
        "Junqi Gao",
        "Dong Li",
        "Zhiyuan Ma",
        "Ganqu Cui",
        "Zhiyuan Liu",
        "Biqing Qi",
        "Ning Ding",
        "Bowen Zhou"
      ],
      "summary": "In this paper, we survey recent advances in Reinforcement Learning (RL) for\nreasoning with Large Language Models (LLMs). RL has achieved remarkable success\nin advancing the frontier of LLM capabilities, particularly in addressing\ncomplex logical tasks such as mathematics and coding. As a result, RL has\nemerged as a foundational methodology for transforming LLMs into LRMs. With the\nrapid progress of the field, further scaling of RL for LRMs now faces\nfoundational challenges not only in computational resources but also in\nalgorithm design, training data, and infrastructure. To this end, it is timely\nto revisit the development of this domain, reassess its trajectory, and explore\nstrategies to enhance the scalability of RL toward Artificial SuperIntelligence\n(ASI). In particular, we examine research applying RL to LLMs and LRMs for\nreasoning abilities, especially since the release of DeepSeek-R1, including\nfoundational components, core problems, training resources, and downstream\napplications, to identify future opportunities and directions for this rapidly\nevolving area. We hope this review will promote future research on RL for\nbroader reasoning models. Github:\nhttps://github.com/TsinghuaC3I/Awesome-RL-for-LRMs",
      "fetch_date": "2025-09-11",
      "num_comments": 5,
      "ai_summary": "Reinforcement Learning enhances Large Language Models for complex reasoning tasks, facing challenges in scalability and infrastructure as the field advances.",
      "ai_keywords": [
        "Reinforcement Learning",
        "Large Language Models",
        "LRMs",
        "DeepSeek-R1",
        "Artificial SuperIntelligence"
      ]
    }
  },
  {
    "id": "4618188e5babf65ab96739c065ddfd61",
    "source": "huggingface",
    "type": "paper",
    "title": "LongLive: Real-time Interactive Long Video Generation",
    "description": "We present LongLive, a frame-level autoregressive (AR) framework for\nreal-time and interactive long video generation. Long video generation presents\nchallenges in both efficiency and quality. Diffusio...<br/>Upvotes: 174<br/>GitHub Stars: 638<br/>Authors: Shuai Yang, Wei Huang, Ruihang Chu<br/>ðŸ”— <a href=\"https://github.com/NVlabs/LongLive\">GitHub</a><br/>ðŸ”— <a href=\"https://nvlabs.github.io/LongLive/\">Project Page</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2509.22622\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2509.22622",
    "external_url": "https://github.com/NVlabs/LongLive",
    "published_date": "2025-09-26T13:48:24.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2509.22622",
      "upvotes": 174,
      "github_stars": 638,
      "github_url": "https://github.com/NVlabs/LongLive",
      "project_url": "https://nvlabs.github.io/LongLive/",
      "authors": [
        "Shuai Yang",
        "Wei Huang",
        "Ruihang Chu",
        "Yicheng Xiao",
        "Yuyang Zhao",
        "Xianbang Wang",
        "Muyang Li",
        "Enze Xie",
        "Yingcong Chen",
        "Yao Lu",
        "Song Han",
        "Yukang Chen"
      ],
      "summary": "We present LongLive, a frame-level autoregressive (AR) framework for\nreal-time and interactive long video generation. Long video generation presents\nchallenges in both efficiency and quality. Diffusion and Diffusion-Forcing\nmodels can produce high-quality videos but suffer from low efficiency due to\nbidirectional attention. Causal attention AR models support KV caching for\nfaster inference, but often degrade in quality on long videos due to memory\nchallenges during long-video training. In addition, beyond static prompt-based\ngeneration, interactive capabilities, such as streaming prompt inputs, are\ncritical for dynamic content creation, enabling users to guide narratives in\nreal time. This interactive requirement significantly increases complexity,\nespecially in ensuring visual consistency and semantic coherence during prompt\ntransitions. To address these challenges, LongLive adopts a causal, frame-level\nAR design that integrates a KV-recache mechanism that refreshes cached states\nwith new prompts for smooth, adherent switches; streaming long tuning to enable\nlong video training and to align training and inference (train-long-test-long);\nand short window attention paired with a frame-level attention sink, shorten as\nframe sink, preserving long-range consistency while enabling faster generation.\nWith these key designs, LongLive fine-tunes a 1.3B-parameter short-clip model\nto minute-long generation in just 32 GPU-days. At inference, LongLive sustains\n20.7 FPS on a single NVIDIA H100, achieves strong performance on VBench in both\nshort and long videos. LongLive supports up to 240-second videos on a single\nH100 GPU. LongLive further supports INT8-quantized inference with only marginal\nquality loss.",
      "fetch_date": "2025-09-29",
      "num_comments": 2,
      "ai_summary": "LongLive is a frame-level autoregressive framework for real-time and interactive long video generation, addressing efficiency and quality challenges through causal attention, KV-recache, streaming long tuning, and short window attention.",
      "ai_keywords": [
        "frame-level autoregressive",
        "diffusion models",
        "diffusion-forcing models",
        "bidirectional attention",
        "causal attention",
        "KV caching",
        "interactive capabilities",
        "streaming prompt inputs",
        "KV-recache mechanism",
        "streaming long tuning",
        "short window attention",
        "frame-level attention sink",
        "frame sink",
        "long-range consistency",
        "VBench",
        "INT8-quantized inference"
      ]
    }
  },
  {
    "id": "b1fe8132db01bc9650eda3e26023bc30",
    "source": "huggingface",
    "type": "paper",
    "title": "MinerU2.5: A Decoupled Vision-Language Model for Efficient\n  High-Resolution Document Parsing",
    "description": "We introduce MinerU2.5, a 1.2B-parameter document parsing vision-language\nmodel that achieves state-of-the-art recognition accuracy while maintaining\nexceptional computational efficiency. Our approach...<br/>Upvotes: 101<br/>GitHub Stars: 45583<br/>Authors: Junbo Niu, Zheng Liu, Zhuangcheng Gu<br/>ðŸ”— <a href=\"https://github.com/opendatalab/MinerU\">GitHub</a><br/>ðŸ”— <a href=\"https://opendatalab.github.io/MinerU/\">Project Page</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2509.22186\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2509.22186",
    "external_url": "https://github.com/opendatalab/MinerU",
    "published_date": "2025-09-26T06:45:48.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2509.22186",
      "upvotes": 101,
      "github_stars": 45583,
      "github_url": "https://github.com/opendatalab/MinerU",
      "project_url": "https://opendatalab.github.io/MinerU/",
      "authors": [
        "Junbo Niu",
        "Zheng Liu",
        "Zhuangcheng Gu",
        "Bin Wang",
        "Linke Ouyang",
        "Zhiyuan Zhao",
        "Tao Chu",
        "Tianyao He",
        "Fan Wu",
        "Qintong Zhang",
        "Zhenjiang Jin",
        "Guang Liang",
        "Rui Zhang",
        "Wenzheng Zhang",
        "Yuan Qu",
        "Zhifei Ren",
        "Yuefeng Sun",
        "Yuanhong Zheng",
        "Dongsheng Ma",
        "Zirui Tang",
        "Boyu Niu",
        "Ziyang Miao",
        "Hejun Dong",
        "Siyi Qian",
        "Junyuan Zhang",
        "Jingzhou Chen",
        "Fangdong Wang",
        "Xiaomeng Zhao",
        "Liqun Wei",
        "Wei Li",
        "Shasha Wang",
        "Ruiliang Xu",
        "Yuanyuan Cao",
        "Lu Chen",
        "Qianqian Wu",
        "Huaiyu Gu",
        "Lindong Lu",
        "Keming Wang",
        "Dechen Lin",
        "Guanlin Shen",
        "Xuanhe Zhou",
        "Linfeng Zhang",
        "Yuhang Zang",
        "Xiaoyi Dong",
        "Jiaqi Wang",
        "Bo Zhang",
        "Lei Bai",
        "Pei Chu",
        "Weijia Li",
        "Jiang Wu",
        "Lijun Wu",
        "Zhenxiang Li",
        "Guangyu Wang",
        "Zhongying Tu",
        "Chao Xu",
        "Kai Chen",
        "Yu Qiao",
        "Bowen Zhou",
        "Dahua Lin",
        "Wentao Zhang",
        "Conghui He"
      ],
      "summary": "We introduce MinerU2.5, a 1.2B-parameter document parsing vision-language\nmodel that achieves state-of-the-art recognition accuracy while maintaining\nexceptional computational efficiency. Our approach employs a coarse-to-fine,\ntwo-stage parsing strategy that decouples global layout analysis from local\ncontent recognition. In the first stage, the model performs efficient layout\nanalysis on downsampled images to identify structural elements, circumventing\nthe computational overhead of processing high-resolution inputs. In the second\nstage, guided by the global layout, it performs targeted content recognition on\nnative-resolution crops extracted from the original image, preserving\nfine-grained details in dense text, complex formulas, and tables. To support\nthis strategy, we developed a comprehensive data engine that generates diverse,\nlarge-scale training corpora for both pretraining and fine-tuning. Ultimately,\nMinerU2.5 demonstrates strong document parsing ability, achieving\nstate-of-the-art performance on multiple benchmarks, surpassing both\ngeneral-purpose and domain-specific models across various recognition tasks,\nwhile maintaining significantly lower computational overhead.",
      "fetch_date": "2025-09-29",
      "num_comments": 2,
      "ai_summary": "MinerU2.5, a 1.2B-parameter document parsing vision-language model, achieves state-of-the-art recognition accuracy with computational efficiency through a coarse-to-fine parsing strategy.",
      "ai_keywords": [
        "document parsing",
        "vision-language model",
        "coarse-to-fine",
        "two-stage parsing",
        "layout analysis",
        "content recognition",
        "downsampled images",
        "native-resolution crops",
        "data engine",
        "pretraining",
        "fine-tuning",
        "state-of-the-art performance",
        "computational overhead"
      ]
    }
  },
  {
    "id": "59f26db9f2ae0d3d43973c1ffbd40568",
    "source": "huggingface",
    "type": "paper",
    "title": "MiniCPM-V 4.5: Cooking Efficient MLLMs via Architecture, Data, and\n  Training Recipe",
    "description": "Multimodal Large Language Models (MLLMs) are undergoing rapid progress and\nrepresent the frontier of AI development. However, their training and inference\nefficiency have emerged as a core bottleneck ...<br/>Upvotes: 46<br/>GitHub Stars: 22058<br/>Authors: Tianyu Yu, Zefan Wang, Chongyi Wang<br/>ðŸ”— <a href=\"https://github.com/OpenBMB/MiniCPM-V\">GitHub</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2509.18154\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2509.18154",
    "external_url": "https://github.com/OpenBMB/MiniCPM-V",
    "published_date": "2025-09-16T15:41:48.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2509.18154",
      "upvotes": 46,
      "github_stars": 22058,
      "github_url": "https://github.com/OpenBMB/MiniCPM-V",
      "project_url": "",
      "authors": [
        "Tianyu Yu",
        "Zefan Wang",
        "Chongyi Wang",
        "Fuwei Huang",
        "Wenshuo Ma",
        "Zhihui He",
        "Tianchi Cai",
        "Weize Chen",
        "Yuxiang Huang",
        "Yuanqian Zhao",
        "Bokai Xu",
        "Junbo Cui",
        "Yingjing Xu",
        "Liqing Ruan",
        "Luoyuan Zhang",
        "Hanyu Liu",
        "Jingkun Tang",
        "Hongyuan Liu",
        "Qining Guo",
        "Wenhao Hu",
        "Bingxiang He",
        "Jie Zhou",
        "Jie Cai",
        "Ji Qi",
        "Zonghao Guo",
        "Chi Chen",
        "Guoyang Zeng",
        "Yuxuan Li",
        "Ganqu Cui",
        "Ning Ding",
        "Xu Han",
        "Yuan Yao",
        "Zhiyuan Liu",
        "Maosong Sun"
      ],
      "summary": "Multimodal Large Language Models (MLLMs) are undergoing rapid progress and\nrepresent the frontier of AI development. However, their training and inference\nefficiency have emerged as a core bottleneck in making MLLMs more accessible\nand scalable. To address the challenges, we present MiniCPM-V 4.5, an 8B\nparameter model designed for high efficiency and strong performance. We\nintroduce three core improvements in model architecture, data strategy and\ntraining method: a unified 3D-Resampler model architecture for highly compact\nencoding over images and videos, a unified learning paradigm for document\nknowledge and text recognition without heavy data engineering, and a hybrid\nreinforcement learning strategy for proficiency in both short and long\nreasoning modes. Comprehensive experimental results in OpenCompass evaluation\nshow that MiniCPM-V 4.5 surpasses widely used proprietary models such as\nGPT-4o-latest, and significantly larger open-source models such as Qwen2.5-VL\n72B. Notably, the strong performance is achieved with remarkable efficiency.\nFor example, on the widely adopted VideoMME benchmark, MiniCPM-V 4.5 achieves\nstate-of-the-art performance among models under 30B size, using just 46.7\\% GPU\nmemory cost and 8.7\\% inference time of Qwen2.5-VL 7B.",
      "fetch_date": "2025-09-24",
      "num_comments": 4,
      "ai_summary": "MiniCPM-V 4.5, a 8B parameter multimodal large language model, achieves high performance and efficiency through a unified 3D-Resampler architecture, a unified learning paradigm, and a hybrid reinforcement learning strategy.",
      "ai_keywords": [
        "3D-Resampler",
        "unified learning paradigm",
        "hybrid reinforcement learning strategy",
        "multimodal large language models",
        "OpenCompass evaluation",
        "VideoMME benchmark"
      ]
    }
  },
  {
    "id": "17d435d0d4a4864c8247d4e12399b781",
    "source": "huggingface",
    "type": "paper",
    "title": "Scaling Agents via Continual Pre-training",
    "description": "Large language models (LLMs) have evolved into agentic systems capable of\nautonomous tool use and multi-step reasoning for complex problem-solving.\nHowever, post-training approaches building upon gene...<br/>Upvotes: 109<br/>GitHub Stars: 15711<br/>Authors: Liangcai Su, Zhen Zhang, Guangyu Li<br/>ðŸ”— <a href=\"https://github.com/Alibaba-NLP/DeepResearch///\">GitHub</a><br/>ðŸ”— <a href=\"https://tongyi-agent.github.io/blog/\">Project Page</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2509.13310\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2509.13310",
    "external_url": "https://github.com/Alibaba-NLP/DeepResearch///",
    "published_date": "2025-09-16T13:57:19.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2509.13310",
      "upvotes": 109,
      "github_stars": 15711,
      "github_url": "https://github.com/Alibaba-NLP/DeepResearch///",
      "project_url": "https://tongyi-agent.github.io/blog/",
      "authors": [
        "Liangcai Su",
        "Zhen Zhang",
        "Guangyu Li",
        "Zhuo Chen",
        "Chenxi Wang",
        "Maojia Song",
        "Xinyu Wang",
        "Kuan Li",
        "Jialong Wu",
        "Xuanzhong Chen",
        "Zile Qiao",
        "Zhongwang Zhang",
        "Huifeng Yin",
        "Shihao Cai",
        "Runnan Fang",
        "Zhengwei Tao",
        "Wenbiao Yin",
        "Chenxiong Qian",
        "Yong Jiang",
        "Pengjun Xie",
        "Fei Huang",
        "Jingren Zhou"
      ],
      "summary": "Large language models (LLMs) have evolved into agentic systems capable of\nautonomous tool use and multi-step reasoning for complex problem-solving.\nHowever, post-training approaches building upon general-purpose foundation\nmodels consistently underperform in agentic tasks, particularly in open-source\nimplementations. We identify the root cause: the absence of robust agentic\nfoundation models forces models during post-training to simultaneously learn\ndiverse agentic behaviors while aligning them to expert demonstrations, thereby\ncreating fundamental optimization tensions. To this end, we are the first to\npropose incorporating Agentic Continual Pre-training (Agentic CPT) into the\ndeep research agents training pipeline to build powerful agentic foundational\nmodels. Based on this approach, we develop a deep research agent model named\nAgentFounder. We evaluate our AgentFounder-30B on 10 benchmarks and achieve\nstate-of-the-art performance while retains strong tool-use ability, notably\n39.9% on BrowseComp-en, 43.3% on BrowseComp-zh, and 31.5% Pass@1 on HLE.",
      "fetch_date": "2025-09-17",
      "num_comments": 9,
      "ai_summary": "AgentFounder, a deep research agent model incorporating Agentic Continual Pre-training, achieves state-of-the-art performance in agentic tasks while maintaining strong tool-use ability.",
      "ai_keywords": [
        "Large language models",
        "agentic systems",
        "autonomous tool use",
        "multi-step reasoning",
        "post-training approaches",
        "general-purpose foundation models",
        "agentic foundation models",
        "Agentic Continual Pre-training",
        "deep research agents",
        "AgentFounder",
        "BrowseComp-en",
        "BrowseComp-zh",
        "HLE"
      ]
    }
  },
  {
    "id": "27945bd6f1634bfd914ab287d0fdaf8e",
    "source": "huggingface",
    "type": "paper",
    "title": "WebWeaver: Structuring Web-Scale Evidence with Dynamic Outlines for\n  Open-Ended Deep Research",
    "description": "This paper tackles open-ended deep research (OEDR), a complex challenge where\nAI agents must synthesize vast web-scale information into insightful reports.\nCurrent approaches are plagued by dual-fold ...<br/>Upvotes: 103<br/>GitHub Stars: 15711<br/>Authors: Zijian Li, Xin Guan, Bo Zhang<br/>ðŸ”— <a href=\"https://github.com/Alibaba-NLP/DeepResearch\">GitHub</a><br/>ðŸ”— <a href=\"https://tongyi-agent.github.io/blog/\">Project Page</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2509.13312\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2509.13312",
    "external_url": "https://github.com/Alibaba-NLP/DeepResearch",
    "published_date": "2025-09-16T13:57:21.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2509.13312",
      "upvotes": 103,
      "github_stars": 15711,
      "github_url": "https://github.com/Alibaba-NLP/DeepResearch",
      "project_url": "https://tongyi-agent.github.io/blog/",
      "authors": [
        "Zijian Li",
        "Xin Guan",
        "Bo Zhang",
        "Shen Huang",
        "Houquan Zhou",
        "Shaopeng Lai",
        "Ming Yan",
        "Yong Jiang",
        "Pengjun Xie",
        "Fei Huang",
        "Jun Zhang",
        "Jingren Zhou"
      ],
      "summary": "This paper tackles open-ended deep research (OEDR), a complex challenge where\nAI agents must synthesize vast web-scale information into insightful reports.\nCurrent approaches are plagued by dual-fold limitations: static research\npipelines that decouple planning from evidence acquisition and one-shot\ngeneration paradigms that easily suffer from long-context failure issues like\n\"loss in the middle\" and hallucinations. To address these challenges, we\nintroduce WebWeaver, a novel dual-agent framework that emulates the human\nresearch process. The planner operates in a dynamic cycle, iteratively\ninterleaving evidence acquisition with outline optimization to produce a\ncomprehensive, source-grounded outline linking to a memory bank of evidence.\nThe writer then executes a hierarchical retrieval and writing process,\ncomposing the report section by section. By performing targeted retrieval of\nonly the necessary evidence from the memory bank for each part, it effectively\nmitigates long-context issues. Our framework establishes a new state-of-the-art\nacross major OEDR benchmarks, including DeepResearch Bench, DeepConsult, and\nDeepResearchGym. These results validate our human-centric, iterative\nmethodology, demonstrating that adaptive planning and focused synthesis are\ncrucial for producing high-quality, reliable, and well-structured reports.",
      "fetch_date": "2025-09-17",
      "num_comments": 5,
      "ai_summary": "WebWeaver, a dual-agent framework, addresses open-ended deep research challenges by integrating adaptive planning and focused synthesis to produce high-quality, reliable reports.",
      "ai_keywords": [
        "open-ended deep research",
        "AI agents",
        "static research pipelines",
        "one-shot generation",
        "long-context failure",
        "loss in the middle",
        "hallucinations",
        "dual-agent framework",
        "human research process",
        "planner",
        "evidence acquisition",
        "outline optimization",
        "memory bank",
        "writer",
        "hierarchical retrieval",
        "writing process",
        "DeepResearch Bench",
        "DeepConsult",
        "DeepResearchGym"
      ]
    }
  },
  {
    "id": "d4b4f91354d2792a0826158fb9d00e0b",
    "source": "huggingface",
    "type": "paper",
    "title": "WebSailor-V2: Bridging the Chasm to Proprietary Agents via Synthetic\n  Data and Scalable Reinforcement Learning",
    "description": "Transcending human cognitive limitations represents a critical frontier in\nLLM training. Proprietary agentic systems like DeepResearch have demonstrated\nsuperhuman capabilities on extremely complex in...<br/>Upvotes: 86<br/>GitHub Stars: 15711<br/>Authors: Kuan Li, Zhongwang Zhang, Huifeng Yin<br/>ðŸ”— <a href=\"https://github.com/Alibaba-NLP/DeepResearch/\">GitHub</a><br/>ðŸ”— <a href=\"https://tongyi-agent.github.io/blog/\">Project Page</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2509.13305\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2509.13305",
    "external_url": "https://github.com/Alibaba-NLP/DeepResearch/",
    "published_date": "2025-09-16T13:57:03.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2509.13305",
      "upvotes": 86,
      "github_stars": 15711,
      "github_url": "https://github.com/Alibaba-NLP/DeepResearch/",
      "project_url": "https://tongyi-agent.github.io/blog/",
      "authors": [
        "Kuan Li",
        "Zhongwang Zhang",
        "Huifeng Yin",
        "Rui Ye",
        "Yida Zhao",
        "Liwen Zhang",
        "Litu Ou",
        "Dingchu Zhang",
        "Xixi Wu",
        "Jialong Wu",
        "Xinyu Wang",
        "Zile Qiao",
        "Zhen Zhang",
        "Yong Jiang",
        "Pengjun Xie",
        "Fei Huang",
        "Jingren Zhou"
      ],
      "summary": "Transcending human cognitive limitations represents a critical frontier in\nLLM training. Proprietary agentic systems like DeepResearch have demonstrated\nsuperhuman capabilities on extremely complex information-seeking benchmarks\nsuch as BrowseComp, a feat previously unattainable. We posit that their success\nhinges on a sophisticated reasoning pattern absent in open-source models: the\nability to systematically reduce extreme uncertainty when navigating vast\ninformation landscapes. Based on this insight, we introduce WebSailor, a\ncomplete post-training methodology designed to instill this crucial capability.\nOur approach involves generating novel, high-uncertainty tasks through\nstructured sampling and information obfuscation, RFT cold start, and an\nefficient agentic RL training algorithm, Duplicating Sampling Policy\nOptimization (DUPO). With this integrated pipeline, WebSailor significantly\noutperforms all open-source agents in complex information-seeking tasks,\nmatching proprietary agents' performance and closing the capability gap.",
      "fetch_date": "2025-09-17",
      "num_comments": 4,
      "ai_summary": "WebSailor, a post-training methodology, enhances open-source models with systematic uncertainty reduction, matching proprietary agents' performance in complex information-seeking tasks.",
      "ai_keywords": [
        "LLM training",
        "DeepResearch",
        "BrowseComp",
        "reasoning pattern",
        "high-uncertainty tasks",
        "structured sampling",
        "information obfuscation",
        "RFT cold start",
        "agentic RL training",
        "Duplicating Sampling Policy Optimization",
        "DUPO"
      ]
    }
  },
  {
    "id": "56ef9e3095cf3666002acddf23dee4ac",
    "source": "huggingface",
    "type": "paper",
    "title": "ReSum: Unlocking Long-Horizon Search Intelligence via Context\n  Summarization",
    "description": "Large Language Model (LLM)-based web agents demonstrate strong performance on\nknowledge-intensive tasks but are hindered by context window limitations in\nparadigms like ReAct. Complex queries involvin...<br/>Upvotes: 76<br/>GitHub Stars: 15711<br/>Authors: Xixi Wu, Kuan Li, Yida Zhao<br/>ðŸ”— <a href=\"https://github.com/Alibaba-NLP/DeepResearch//\">GitHub</a><br/>ðŸ”— <a href=\"https://tongyi-agent.github.io/blog/\">Project Page</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2509.13313\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2509.13313",
    "external_url": "https://github.com/Alibaba-NLP/DeepResearch//",
    "published_date": "2025-09-16T13:57:22.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2509.13313",
      "upvotes": 76,
      "github_stars": 15711,
      "github_url": "https://github.com/Alibaba-NLP/DeepResearch//",
      "project_url": "https://tongyi-agent.github.io/blog/",
      "authors": [
        "Xixi Wu",
        "Kuan Li",
        "Yida Zhao",
        "Liwen Zhang",
        "Litu Ou",
        "Huifeng Yin",
        "Zhongwang Zhang",
        "Yong Jiang",
        "Pengjun Xie",
        "Fei Huang",
        "Minhao Cheng",
        "Shuai Wang",
        "Hong Cheng",
        "Jingren Zhou"
      ],
      "summary": "Large Language Model (LLM)-based web agents demonstrate strong performance on\nknowledge-intensive tasks but are hindered by context window limitations in\nparadigms like ReAct. Complex queries involving multiple entities, intertwined\nrelationships, and high uncertainty demand extensive search cycles that rapidly\nexhaust context budgets before reaching complete solutions. To overcome this\nchallenge, we introduce ReSum, a novel paradigm that enables indefinite\nexploration through periodic context summarization. ReSum converts growing\ninteraction histories into compact reasoning states, maintaining awareness of\nprior discoveries while bypassing context constraints. For paradigm adaptation,\nwe propose ReSum-GRPO, integrating GRPO with segmented trajectory training and\nadvantage broadcasting to familiarize agents with summary-conditioned\nreasoning. Extensive experiments on web agents of varying scales across three\nbenchmarks demonstrate that ReSum delivers an average absolute improvement of\n4.5\\% over ReAct, with further gains of up to 8.2\\% following ReSum-GRPO\ntraining. Notably, with only 1K training samples, our WebResummer-30B (a\nReSum-GRPO-trained version of WebSailor-30B) achieves 33.3\\% Pass@1 on\nBrowseComp-zh and 18.3\\% on BrowseComp-en, surpassing existing open-source web\nagents.",
      "fetch_date": "2025-09-17",
      "num_comments": 5,
      "ai_summary": "ReSum, a novel paradigm with periodic context summarization, enhances web agents' performance on knowledge-intensive tasks by overcoming context window limitations, achieving significant improvements over ReAct.",
      "ai_keywords": [
        "Large Language Model",
        "LLM",
        "web agents",
        "knowledge-intensive tasks",
        "context window limitations",
        "ReAct",
        "ReSum",
        "context summarization",
        "reasoning states",
        "GRPO",
        "segmented trajectory training",
        "advantage broadcasting",
        "ReSum-GRPO",
        "WebResummer-30B",
        "WebSailor-30B",
        "BrowseComp-zh",
        "BrowseComp-en",
        "Pass@1"
      ]
    }
  }
]