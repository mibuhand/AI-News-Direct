[
  {
    "id": "7a9ae43171e964d5b9a58c9a76f8c373",
    "source": "huggingface",
    "type": "paper",
    "title": "The Dragon Hatchling: The Missing Link between the Transformer and\n  Models of the Brain",
    "description": "The relationship between computing systems and the brain has served as\nmotivation for pioneering theoreticians since John von Neumann and Alan Turing.\nUniform, scale-free biological networks, such as ...<br/>Upvotes: 462<br/>GitHub Stars: 3046<br/>Authors: Adrian Kosowski, PrzemysÅ‚aw UznaÅ„ski, Jan Chorowski<br/>ðŸ”— <a href=\"https://github.com/pathwaycom/bdh\">GitHub</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2509.26507\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2509.26507",
    "external_url": "https://github.com/pathwaycom/bdh",
    "published_date": "2025-09-30T12:49:01.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2509.26507",
      "upvotes": 462,
      "github_stars": 3046,
      "github_url": "https://github.com/pathwaycom/bdh",
      "project_url": "",
      "authors": [
        "Adrian Kosowski",
        "PrzemysÅ‚aw UznaÅ„ski",
        "Jan Chorowski",
        "Zuzanna Stamirowska",
        "MichaÅ‚ Bartoszkiewicz"
      ],
      "summary": "The relationship between computing systems and the brain has served as\nmotivation for pioneering theoreticians since John von Neumann and Alan Turing.\nUniform, scale-free biological networks, such as the brain, have powerful\nproperties, including generalizing over time, which is the main barrier for\nMachine Learning on the path to Universal Reasoning Models.\n  We introduce `Dragon Hatchling' (BDH), a new Large Language Model\narchitecture based on a scale-free biologically inspired network of \\n\nlocally-interacting neuron particles. BDH couples strong theoretical\nfoundations and inherent interpretability without sacrificing Transformer-like\nperformance.\n  BDH is a practical, performant state-of-the-art attention-based state space\nsequence learning architecture. In addition to being a graph model, BDH admits\na GPU-friendly formulation. It exhibits Transformer-like scaling laws:\nempirically BDH rivals GPT2 performance on language and translation tasks, at\nthe same number of parameters (10M to 1B), for the same training data.\n  BDH can be represented as a brain model. The working memory of BDH during\ninference entirely relies on synaptic plasticity with Hebbian learning using\nspiking neurons. We confirm empirically that specific, individual synapses\nstrengthen connection whenever BDH hears or reasons about a specific concept\nwhile processing language inputs. The neuron interaction network of BDH is a\ngraph of high modularity with heavy-tailed degree distribution. The BDH model\nis biologically plausible, explaining one possible mechanism which human\nneurons could use to achieve speech.\n  BDH is designed for interpretability. Activation vectors of BDH are sparse\nand positive. We demonstrate monosemanticity in BDH on language tasks.\nInterpretability of state, which goes beyond interpretability of neurons and\nmodel parameters, is an inherent feature of the BDH architecture.",
      "fetch_date": "2025-10-01",
      "num_comments": 14,
      "ai_summary": "BDH, a biologically inspired Large Language Model, combines scale-free network architecture with Hebbian learning to achieve Transformer-like performance while maintaining interpretability.",
      "ai_keywords": [
        "Large Language Model",
        "scale-free network",
        "Hebbian learning",
        "synaptic plasticity",
        "spiking neurons",
        "graph model",
        "GPU-friendly",
        "Transformer-like scaling laws",
        "monosemanticity",
        "interpretability"
      ]
    }
  },
  {
    "id": "3d55a02b14bdc7a04256ce32475eb075",
    "source": "huggingface",
    "type": "paper",
    "title": "Less is More: Recursive Reasoning with Tiny Networks",
    "description": "Hierarchical Reasoning Model (HRM) is a novel approach using two small neural\nnetworks recursing at different frequencies. This biologically inspired method\nbeats Large Language models (LLMs) on hard ...<br/>Upvotes: 359<br/>GitHub Stars: 4094<br/>Authors: Alexia Jolicoeur-Martineau<br/>ðŸ”— <a href=\"https://github.com/SamsungSAILMontreal/TinyRecursiveModels\">GitHub</a><br/>ðŸ”— <a href=\"https://alexiajm.github.io/2025/09/29/tiny_recursive_models.html#\">Project Page</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2510.04871\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2510.04871",
    "external_url": "https://github.com/SamsungSAILMontreal/TinyRecursiveModels",
    "published_date": "2025-10-06T10:58:08.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2510.04871",
      "upvotes": 359,
      "github_stars": 4094,
      "github_url": "https://github.com/SamsungSAILMontreal/TinyRecursiveModels",
      "project_url": "https://alexiajm.github.io/2025/09/29/tiny_recursive_models.html#",
      "authors": [
        "Alexia Jolicoeur-Martineau"
      ],
      "summary": "Hierarchical Reasoning Model (HRM) is a novel approach using two small neural\nnetworks recursing at different frequencies. This biologically inspired method\nbeats Large Language models (LLMs) on hard puzzle tasks such as Sudoku, Maze,\nand ARC-AGI while trained with small models (27M parameters) on small data\n(around 1000 examples). HRM holds great promise for solving hard problems with\nsmall networks, but it is not yet well understood and may be suboptimal. We\npropose Tiny Recursive Model (TRM), a much simpler recursive reasoning approach\nthat achieves significantly higher generalization than HRM, while using a\nsingle tiny network with only 2 layers. With only 7M parameters, TRM obtains\n45% test-accuracy on ARC-AGI-1 and 8% on ARC-AGI-2, higher than most LLMs\n(e.g., Deepseek R1, o3-mini, Gemini 2.5 Pro) with less than 0.01% of the\nparameters.",
      "fetch_date": "2025-10-08",
      "num_comments": 20,
      "ai_summary": "Tiny Recursive Model (TRM) achieves high generalization on complex puzzle tasks using a small, two-layer network with minimal parameters, outperforming larger language models.",
      "ai_keywords": [
        "Hierarchical Reasoning Model",
        "HRM",
        "Tiny Recursive Model",
        "TRM",
        "recursive reasoning",
        "neural networks",
        "ARC-AGI",
        "Deepseek R1",
        "o3-mini",
        "Gemini 2.5 Pro"
      ]
    }
  },
  {
    "id": "b5eadc2228eda785fe3e8da98ea25174",
    "source": "huggingface",
    "type": "paper",
    "title": "Agent Learning via Early Experience",
    "description": "A long-term goal of language agents is to learn and improve through their own\nexperience, ultimately outperforming humans in complex, real-world tasks.\nHowever, training agents from experience data wi...<br/>Upvotes: 192<br/>Authors: Kai Zhang, Xiangchao Chen, Bo Liu<br/>ðŸ”— <a href=\"https://huggingface.co/papers/2510.08558\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2510.08558",
    "external_url": "",
    "published_date": "2025-10-09T13:59:17.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2510.08558",
      "upvotes": 192,
      "github_stars": 0,
      "github_url": "",
      "project_url": "",
      "authors": [
        "Kai Zhang",
        "Xiangchao Chen",
        "Bo Liu",
        "Tianci Xue",
        "Zeyi Liao",
        "Zhihan Liu",
        "Xiyao Wang",
        "Yuting Ning",
        "Zhaorun Chen",
        "Xiaohan Fu",
        "Jian Xie",
        "Yuxuan Sun",
        "Boyu Gou",
        "Qi Qi",
        "Zihang Meng",
        "Jianwei Yang",
        "Ning Zhang",
        "Xian Li",
        "Ashish Shah",
        "Dat Huynh",
        "Hengduo Li",
        "Zi Yang",
        "Sara Cao",
        "Lawrence Jang",
        "Shuyan Zhou",
        "Jiacheng Zhu",
        "Huan Sun",
        "Jason Weston",
        "Yu Su",
        "Yifan Wu"
      ],
      "summary": "A long-term goal of language agents is to learn and improve through their own\nexperience, ultimately outperforming humans in complex, real-world tasks.\nHowever, training agents from experience data with reinforcement learning\nremains difficult in many environments, which either lack verifiable rewards\n(e.g., websites) or require inefficient long-horizon rollouts (e.g., multi-turn\ntool use). As a result, most current agents rely on supervised fine-tuning on\nexpert data, which is challenging to scale and generalizes poorly. This\nlimitation stems from the nature of expert demonstrations: they capture only a\nnarrow range of scenarios and expose the agent to limited environment\ndiversity. We address this limitation with a middle-ground paradigm we call\nearly experience: interaction data generated by the agent's own actions, where\nthe resulting future states serve as supervision without reward signals. Within\nthis paradigm we study two strategies of using such data: (1) Implicit world\nmodeling, which uses collected states to ground the policy in environment\ndynamics; and (2) Self-reflection, where the agent learns from its suboptimal\nactions to improve reasoning and decision-making. We evaluate across eight\ndiverse environments and multiple model families. Our approaches consistently\nimprove effectiveness and out-of-domain generalization, highlighting the value\nof early experience. Moreover, in environments with verifiable rewards, our\nresults provide promising signals that early experience offers a strong\nfoundation for subsequent reinforcement learning, positioning it as a practical\nbridge between imitation learning and fully experience-driven agents.",
      "fetch_date": "2025-10-10",
      "num_comments": 8,
      "ai_summary": "Early experience, using agent-generated interaction data without reward signals, improves policy effectiveness and generalization, serving as a bridge between imitation learning and reinforcement learning.",
      "ai_keywords": [
        "reinforcement learning",
        "early experience",
        "implicit world modeling",
        "self-reflection",
        "out-of-domain generalization"
      ]
    }
  },
  {
    "id": "4618188e5babf65ab96739c065ddfd61",
    "source": "huggingface",
    "type": "paper",
    "title": "LongLive: Real-time Interactive Long Video Generation",
    "description": "We present LongLive, a frame-level autoregressive (AR) framework for\nreal-time and interactive long video generation. Long video generation presents\nchallenges in both efficiency and quality. Diffusio...<br/>Upvotes: 174<br/>GitHub Stars: 675<br/>Authors: Shuai Yang, Wei Huang, Ruihang Chu<br/>ðŸ”— <a href=\"https://github.com/NVlabs/LongLive\">GitHub</a><br/>ðŸ”— <a href=\"https://nvlabs.github.io/LongLive/\">Project Page</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2509.22622\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2509.22622",
    "external_url": "https://github.com/NVlabs/LongLive",
    "published_date": "2025-09-26T13:48:24.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2509.22622",
      "upvotes": 174,
      "github_stars": 675,
      "github_url": "https://github.com/NVlabs/LongLive",
      "project_url": "https://nvlabs.github.io/LongLive/",
      "authors": [
        "Shuai Yang",
        "Wei Huang",
        "Ruihang Chu",
        "Yicheng Xiao",
        "Yuyang Zhao",
        "Xianbang Wang",
        "Muyang Li",
        "Enze Xie",
        "Yingcong Chen",
        "Yao Lu",
        "Song Han",
        "Yukang Chen"
      ],
      "summary": "We present LongLive, a frame-level autoregressive (AR) framework for\nreal-time and interactive long video generation. Long video generation presents\nchallenges in both efficiency and quality. Diffusion and Diffusion-Forcing\nmodels can produce high-quality videos but suffer from low efficiency due to\nbidirectional attention. Causal attention AR models support KV caching for\nfaster inference, but often degrade in quality on long videos due to memory\nchallenges during long-video training. In addition, beyond static prompt-based\ngeneration, interactive capabilities, such as streaming prompt inputs, are\ncritical for dynamic content creation, enabling users to guide narratives in\nreal time. This interactive requirement significantly increases complexity,\nespecially in ensuring visual consistency and semantic coherence during prompt\ntransitions. To address these challenges, LongLive adopts a causal, frame-level\nAR design that integrates a KV-recache mechanism that refreshes cached states\nwith new prompts for smooth, adherent switches; streaming long tuning to enable\nlong video training and to align training and inference (train-long-test-long);\nand short window attention paired with a frame-level attention sink, shorten as\nframe sink, preserving long-range consistency while enabling faster generation.\nWith these key designs, LongLive fine-tunes a 1.3B-parameter short-clip model\nto minute-long generation in just 32 GPU-days. At inference, LongLive sustains\n20.7 FPS on a single NVIDIA H100, achieves strong performance on VBench in both\nshort and long videos. LongLive supports up to 240-second videos on a single\nH100 GPU. LongLive further supports INT8-quantized inference with only marginal\nquality loss.",
      "fetch_date": "2025-09-29",
      "num_comments": 2,
      "ai_summary": "LongLive is a frame-level autoregressive framework for real-time and interactive long video generation, addressing efficiency and quality challenges through causal attention, KV-recache, streaming long tuning, and short window attention.",
      "ai_keywords": [
        "frame-level autoregressive",
        "diffusion models",
        "diffusion-forcing models",
        "bidirectional attention",
        "causal attention",
        "KV caching",
        "interactive capabilities",
        "streaming prompt inputs",
        "KV-recache mechanism",
        "streaming long tuning",
        "short window attention",
        "frame-level attention sink",
        "frame sink",
        "long-range consistency",
        "VBench",
        "INT8-quantized inference"
      ]
    }
  },
  {
    "id": "652276de74e8a80281a665d98165228d",
    "source": "huggingface",
    "type": "paper",
    "title": "MCPMark: A Benchmark for Stress-Testing Realistic and Comprehensive MCP\n  Use",
    "description": "MCP standardizes how LLMs interact with external systems, forming the\nfoundation for general agents. However, existing MCP benchmarks remain narrow\nin scope: they focus on read-heavy tasks or tasks wi...<br/>Upvotes: 160<br/>GitHub Stars: 257<br/>Authors: Zijian Wu, Xiangyan Liu, Xinyuan Zhang<br/>ðŸ”— <a href=\"https://github.com/eval-sys/mcpmark\">GitHub</a><br/>ðŸ”— <a href=\"https://mcpmark.ai/\">Project Page</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2509.24002\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2509.24002",
    "external_url": "https://github.com/eval-sys/mcpmark",
    "published_date": "2025-09-28T13:53:27.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2509.24002",
      "upvotes": 160,
      "github_stars": 257,
      "github_url": "https://github.com/eval-sys/mcpmark",
      "project_url": "https://mcpmark.ai/",
      "authors": [
        "Zijian Wu",
        "Xiangyan Liu",
        "Xinyuan Zhang",
        "Lingjun Chen",
        "Fanqing Meng",
        "Lingxiao Du",
        "Yiran Zhao",
        "Fanshi Zhang",
        "Yaoqi Ye",
        "Jiawei Wang",
        "Zirui Wang",
        "Jinjie Ni",
        "Yufan Yang",
        "Arvin Xu",
        "Michael Qizhe Shieh"
      ],
      "summary": "MCP standardizes how LLMs interact with external systems, forming the\nfoundation for general agents. However, existing MCP benchmarks remain narrow\nin scope: they focus on read-heavy tasks or tasks with limited interaction\ndepth, and fail to capture the complexity and realism of real-world workflows.\nTo address this gap, we propose MCPMark, a benchmark designed to evaluate MCP\nuse in a more realistic and comprehensive manner. It consists of 127\nhigh-quality tasks collaboratively created by domain experts and AI agents.\nEach task begins with a curated initial state and includes a programmatic\nscript for automatic verification. These tasks demand richer and more diverse\ninteractions with the environment, involving a broad range of create, read,\nupdate, and delete (CRUD) operations. We conduct a comprehensive evaluation of\ncutting-edge LLMs using a minimal agent framework that operates in a\ntool-calling loop. Empirical results show that the best-performing model,\ngpt-5-medium, reaches only 52.56\\% pass@1 and 33.86\\% pass^4, while other\nwidely regarded strong models, including claude-sonnet-4 and o3, fall below\n30\\% pass@1 and 15\\% pass^4. On average, LLMs require 16.2 execution\nturns and 17.4 tool calls per task, significantly surpassing those in\nprevious MCP benchmarks and highlighting the stress-testing nature of MCPMark.",
      "fetch_date": "2025-10-01",
      "num_comments": 7,
      "ai_summary": "MCPMark is a comprehensive benchmark for evaluating MCP use in real-world workflows, featuring diverse tasks that require richer interactions with the environment, and reveals that current LLMs perform poorly on these tasks.",
      "ai_keywords": [
        "MCP",
        "LLMs",
        "general agents",
        "MCP benchmarks",
        "MCPMark",
        "high-quality tasks",
        "domain experts",
        "AI agents",
        "initial state",
        "programmatic script",
        "automatic verification",
        "CRUD operations",
        "minimal agent framework",
        "tool-calling loop",
        "gpt-5-medium",
        "claude-sonnet-4",
        "o3",
        "pass@1",
        "pass^4",
        "execution turns",
        "tool calls"
      ]
    }
  },
  {
    "id": "be8daac86204946af4ee6890c05adb8e",
    "source": "huggingface",
    "type": "paper",
    "title": "Vision-Zero: Scalable VLM Self-Improvement via Strategic Gamified\n  Self-Play",
    "description": "Although reinforcement learning (RL) can effectively enhance the reasoning\ncapabilities of vision-language models (VLMs), current methods remain heavily\ndependent on labor-intensive datasets that requ...<br/>Upvotes: 131<br/>GitHub Stars: 62<br/>Authors: Qinsi Wang, Bo Liu, Tianyi Zhou<br/>ðŸ”— <a href=\"https://github.com/wangqinsi1/Vision-Zero\">GitHub</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2509.25541\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2509.25541",
    "external_url": "https://github.com/wangqinsi1/Vision-Zero",
    "published_date": "2025-09-29T17:55:55.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2509.25541",
      "upvotes": 131,
      "github_stars": 62,
      "github_url": "https://github.com/wangqinsi1/Vision-Zero",
      "project_url": "",
      "authors": [
        "Qinsi Wang",
        "Bo Liu",
        "Tianyi Zhou",
        "Jing Shi",
        "Yueqian Lin",
        "Yiran Chen",
        "Hai Helen Li",
        "Kun Wan",
        "Wentian Zhao"
      ],
      "summary": "Although reinforcement learning (RL) can effectively enhance the reasoning\ncapabilities of vision-language models (VLMs), current methods remain heavily\ndependent on labor-intensive datasets that require extensive manual\nconstruction and verification, leading to extremely high training costs and\nconsequently constraining the practical deployment of VLMs. To address this\nchallenge, we propose Vision-Zero, a domain-agnostic framework enabling VLM\nself-improvement through competitive visual games generated from arbitrary\nimage pairs. Specifically, Vision-Zero encompasses three main attributes: (1)\nStrategic Self-Play Framework: Vision-Zero trains VLMs in \"Who Is the\nSpy\"-style games, where the models engage in strategic reasoning and actions\nacross multiple roles. Through interactive gameplay, models autonomously\ngenerate their training data without human annotation. (2) Gameplay from\nArbitrary Images: Unlike existing gamified frameworks, Vision-Zero can generate\ngames from arbitrary images, thereby enhancing the model's reasoning ability\nacross diverse domains and showing strong generalization to different tasks. We\ndemonstrate this versatility using three distinct types of image datasets:\nCLEVR-based synthetic scenes, charts, and real-world images. (3) Sustainable\nPerformance Gain: We introduce Iterative Self-Play Policy Optimization\n(Iterative-SPO), a novel training algorithm that alternates between Self-Play\nand reinforcement learning with verifiable rewards (RLVR), mitigating the\nperformance plateau often seen in self-play-only training and achieving\nsustained long-term improvements. Despite using label-free data, Vision-Zero\nachieves state-of-the-art performance on reasoning, chart question answering,\nand vision-centric understanding tasks, surpassing other annotation-based\nmethods. Models and code has been released at\nhttps://github.com/wangqinsi1/Vision-Zero.",
      "fetch_date": "2025-10-01",
      "num_comments": 2,
      "ai_summary": "Vision-Zero is a domain-agnostic framework that enhances vision-language models through self-improvement in competitive visual games, using Iterative Self-Play Policy Optimization and achieving state-of-the-art performance without human annotation.",
      "ai_keywords": [
        "reinforcement learning",
        "vision-language models",
        "strategic self-play framework",
        "self-play",
        "reinforcement learning with verifiable rewards",
        "Iterative Self-Play Policy Optimization"
      ]
    }
  },
  {
    "id": "b1fe8132db01bc9650eda3e26023bc30",
    "source": "huggingface",
    "type": "paper",
    "title": "MinerU2.5: A Decoupled Vision-Language Model for Efficient\n  High-Resolution Document Parsing",
    "description": "We introduce MinerU2.5, a 1.2B-parameter document parsing vision-language\nmodel that achieves state-of-the-art recognition accuracy while maintaining\nexceptional computational efficiency. Our approach...<br/>Upvotes: 104<br/>GitHub Stars: 46179<br/>Authors: Junbo Niu, Zheng Liu, Zhuangcheng Gu<br/>ðŸ”— <a href=\"https://github.com/opendatalab/MinerU\">GitHub</a><br/>ðŸ”— <a href=\"https://opendatalab.github.io/MinerU/\">Project Page</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2509.22186\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2509.22186",
    "external_url": "https://github.com/opendatalab/MinerU",
    "published_date": "2025-09-26T06:45:48.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2509.22186",
      "upvotes": 104,
      "github_stars": 46179,
      "github_url": "https://github.com/opendatalab/MinerU",
      "project_url": "https://opendatalab.github.io/MinerU/",
      "authors": [
        "Junbo Niu",
        "Zheng Liu",
        "Zhuangcheng Gu",
        "Bin Wang",
        "Linke Ouyang",
        "Zhiyuan Zhao",
        "Tao Chu",
        "Tianyao He",
        "Fan Wu",
        "Qintong Zhang",
        "Zhenjiang Jin",
        "Guang Liang",
        "Rui Zhang",
        "Wenzheng Zhang",
        "Yuan Qu",
        "Zhifei Ren",
        "Yuefeng Sun",
        "Yuanhong Zheng",
        "Dongsheng Ma",
        "Zirui Tang",
        "Boyu Niu",
        "Ziyang Miao",
        "Hejun Dong",
        "Siyi Qian",
        "Junyuan Zhang",
        "Jingzhou Chen",
        "Fangdong Wang",
        "Xiaomeng Zhao",
        "Liqun Wei",
        "Wei Li",
        "Shasha Wang",
        "Ruiliang Xu",
        "Yuanyuan Cao",
        "Lu Chen",
        "Qianqian Wu",
        "Huaiyu Gu",
        "Lindong Lu",
        "Keming Wang",
        "Dechen Lin",
        "Guanlin Shen",
        "Xuanhe Zhou",
        "Linfeng Zhang",
        "Yuhang Zang",
        "Xiaoyi Dong",
        "Jiaqi Wang",
        "Bo Zhang",
        "Lei Bai",
        "Pei Chu",
        "Weijia Li",
        "Jiang Wu",
        "Lijun Wu",
        "Zhenxiang Li",
        "Guangyu Wang",
        "Zhongying Tu",
        "Chao Xu",
        "Kai Chen",
        "Yu Qiao",
        "Bowen Zhou",
        "Dahua Lin",
        "Wentao Zhang",
        "Conghui He"
      ],
      "summary": "We introduce MinerU2.5, a 1.2B-parameter document parsing vision-language\nmodel that achieves state-of-the-art recognition accuracy while maintaining\nexceptional computational efficiency. Our approach employs a coarse-to-fine,\ntwo-stage parsing strategy that decouples global layout analysis from local\ncontent recognition. In the first stage, the model performs efficient layout\nanalysis on downsampled images to identify structural elements, circumventing\nthe computational overhead of processing high-resolution inputs. In the second\nstage, guided by the global layout, it performs targeted content recognition on\nnative-resolution crops extracted from the original image, preserving\nfine-grained details in dense text, complex formulas, and tables. To support\nthis strategy, we developed a comprehensive data engine that generates diverse,\nlarge-scale training corpora for both pretraining and fine-tuning. Ultimately,\nMinerU2.5 demonstrates strong document parsing ability, achieving\nstate-of-the-art performance on multiple benchmarks, surpassing both\ngeneral-purpose and domain-specific models across various recognition tasks,\nwhile maintaining significantly lower computational overhead.",
      "fetch_date": "2025-09-29",
      "num_comments": 2,
      "ai_summary": "MinerU2.5, a 1.2B-parameter document parsing vision-language model, achieves state-of-the-art recognition accuracy with computational efficiency through a coarse-to-fine parsing strategy.",
      "ai_keywords": [
        "document parsing",
        "vision-language model",
        "coarse-to-fine",
        "two-stage parsing",
        "layout analysis",
        "content recognition",
        "downsampled images",
        "native-resolution crops",
        "data engine",
        "pretraining",
        "fine-tuning",
        "state-of-the-art performance",
        "computational overhead"
      ]
    }
  },
  {
    "id": "59f26db9f2ae0d3d43973c1ffbd40568",
    "source": "huggingface",
    "type": "paper",
    "title": "MiniCPM-V 4.5: Cooking Efficient MLLMs via Architecture, Data, and\n  Training Recipe",
    "description": "Multimodal Large Language Models (MLLMs) are undergoing rapid progress and\nrepresent the frontier of AI development. However, their training and inference\nefficiency have emerged as a core bottleneck ...<br/>Upvotes: 47<br/>GitHub Stars: 22071<br/>Authors: Tianyu Yu, Zefan Wang, Chongyi Wang<br/>ðŸ”— <a href=\"https://github.com/OpenBMB/MiniCPM-V\">GitHub</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2509.18154\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2509.18154",
    "external_url": "https://github.com/OpenBMB/MiniCPM-V",
    "published_date": "2025-09-16T15:41:48.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2509.18154",
      "upvotes": 47,
      "github_stars": 22071,
      "github_url": "https://github.com/OpenBMB/MiniCPM-V",
      "project_url": "",
      "authors": [
        "Tianyu Yu",
        "Zefan Wang",
        "Chongyi Wang",
        "Fuwei Huang",
        "Wenshuo Ma",
        "Zhihui He",
        "Tianchi Cai",
        "Weize Chen",
        "Yuxiang Huang",
        "Yuanqian Zhao",
        "Bokai Xu",
        "Junbo Cui",
        "Yingjing Xu",
        "Liqing Ruan",
        "Luoyuan Zhang",
        "Hanyu Liu",
        "Jingkun Tang",
        "Hongyuan Liu",
        "Qining Guo",
        "Wenhao Hu",
        "Bingxiang He",
        "Jie Zhou",
        "Jie Cai",
        "Ji Qi",
        "Zonghao Guo",
        "Chi Chen",
        "Guoyang Zeng",
        "Yuxuan Li",
        "Ganqu Cui",
        "Ning Ding",
        "Xu Han",
        "Yuan Yao",
        "Zhiyuan Liu",
        "Maosong Sun"
      ],
      "summary": "Multimodal Large Language Models (MLLMs) are undergoing rapid progress and\nrepresent the frontier of AI development. However, their training and inference\nefficiency have emerged as a core bottleneck in making MLLMs more accessible\nand scalable. To address the challenges, we present MiniCPM-V 4.5, an 8B\nparameter model designed for high efficiency and strong performance. We\nintroduce three core improvements in model architecture, data strategy and\ntraining method: a unified 3D-Resampler model architecture for highly compact\nencoding over images and videos, a unified learning paradigm for document\nknowledge and text recognition without heavy data engineering, and a hybrid\nreinforcement learning strategy for proficiency in both short and long\nreasoning modes. Comprehensive experimental results in OpenCompass evaluation\nshow that MiniCPM-V 4.5 surpasses widely used proprietary models such as\nGPT-4o-latest, and significantly larger open-source models such as Qwen2.5-VL\n72B. Notably, the strong performance is achieved with remarkable efficiency.\nFor example, on the widely adopted VideoMME benchmark, MiniCPM-V 4.5 achieves\nstate-of-the-art performance among models under 30B size, using just 46.7\\% GPU\nmemory cost and 8.7\\% inference time of Qwen2.5-VL 7B.",
      "fetch_date": "2025-09-24",
      "num_comments": 4,
      "ai_summary": "MiniCPM-V 4.5, a 8B parameter multimodal large language model, achieves high performance and efficiency through a unified 3D-Resampler architecture, a unified learning paradigm, and a hybrid reinforcement learning strategy.",
      "ai_keywords": [
        "3D-Resampler",
        "unified learning paradigm",
        "hybrid reinforcement learning strategy",
        "multimodal large language models",
        "OpenCompass evaluation",
        "VideoMME benchmark"
      ]
    }
  },
  {
    "id": "17d435d0d4a4864c8247d4e12399b781",
    "source": "huggingface",
    "type": "paper",
    "title": "Scaling Agents via Continual Pre-training",
    "description": "Large language models (LLMs) have evolved into agentic systems capable of\nautonomous tool use and multi-step reasoning for complex problem-solving.\nHowever, post-training approaches building upon gene...<br/>Upvotes: 110<br/>GitHub Stars: 15921<br/>Authors: Liangcai Su, Zhen Zhang, Guangyu Li<br/>ðŸ”— <a href=\"https://github.com/Alibaba-NLP/DeepResearch///\">GitHub</a><br/>ðŸ”— <a href=\"https://tongyi-agent.github.io/blog/\">Project Page</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2509.13310\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2509.13310",
    "external_url": "https://github.com/Alibaba-NLP/DeepResearch///",
    "published_date": "2025-09-16T13:57:19.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2509.13310",
      "upvotes": 110,
      "github_stars": 15921,
      "github_url": "https://github.com/Alibaba-NLP/DeepResearch///",
      "project_url": "https://tongyi-agent.github.io/blog/",
      "authors": [
        "Liangcai Su",
        "Zhen Zhang",
        "Guangyu Li",
        "Zhuo Chen",
        "Chenxi Wang",
        "Maojia Song",
        "Xinyu Wang",
        "Kuan Li",
        "Jialong Wu",
        "Xuanzhong Chen",
        "Zile Qiao",
        "Zhongwang Zhang",
        "Huifeng Yin",
        "Shihao Cai",
        "Runnan Fang",
        "Zhengwei Tao",
        "Wenbiao Yin",
        "Chenxiong Qian",
        "Yong Jiang",
        "Pengjun Xie",
        "Fei Huang",
        "Jingren Zhou"
      ],
      "summary": "Large language models (LLMs) have evolved into agentic systems capable of\nautonomous tool use and multi-step reasoning for complex problem-solving.\nHowever, post-training approaches building upon general-purpose foundation\nmodels consistently underperform in agentic tasks, particularly in open-source\nimplementations. We identify the root cause: the absence of robust agentic\nfoundation models forces models during post-training to simultaneously learn\ndiverse agentic behaviors while aligning them to expert demonstrations, thereby\ncreating fundamental optimization tensions. To this end, we are the first to\npropose incorporating Agentic Continual Pre-training (Agentic CPT) into the\ndeep research agents training pipeline to build powerful agentic foundational\nmodels. Based on this approach, we develop a deep research agent model named\nAgentFounder. We evaluate our AgentFounder-30B on 10 benchmarks and achieve\nstate-of-the-art performance while retains strong tool-use ability, notably\n39.9% on BrowseComp-en, 43.3% on BrowseComp-zh, and 31.5% Pass@1 on HLE.",
      "fetch_date": "2025-09-17",
      "num_comments": 9,
      "ai_summary": "AgentFounder, a deep research agent model incorporating Agentic Continual Pre-training, achieves state-of-the-art performance in agentic tasks while maintaining strong tool-use ability.",
      "ai_keywords": [
        "Large language models",
        "agentic systems",
        "autonomous tool use",
        "multi-step reasoning",
        "post-training approaches",
        "general-purpose foundation models",
        "agentic foundation models",
        "Agentic Continual Pre-training",
        "deep research agents",
        "AgentFounder",
        "BrowseComp-en",
        "BrowseComp-zh",
        "HLE"
      ]
    }
  },
  {
    "id": "27945bd6f1634bfd914ab287d0fdaf8e",
    "source": "huggingface",
    "type": "paper",
    "title": "WebWeaver: Structuring Web-Scale Evidence with Dynamic Outlines for\n  Open-Ended Deep Research",
    "description": "This paper tackles open-ended deep research (OEDR), a complex challenge where\nAI agents must synthesize vast web-scale information into insightful reports.\nCurrent approaches are plagued by dual-fold ...<br/>Upvotes: 103<br/>GitHub Stars: 15921<br/>Authors: Zijian Li, Xin Guan, Bo Zhang<br/>ðŸ”— <a href=\"https://github.com/Alibaba-NLP/DeepResearch\">GitHub</a><br/>ðŸ”— <a href=\"https://tongyi-agent.github.io/blog/\">Project Page</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2509.13312\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2509.13312",
    "external_url": "https://github.com/Alibaba-NLP/DeepResearch",
    "published_date": "2025-09-16T13:57:21.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2509.13312",
      "upvotes": 103,
      "github_stars": 15921,
      "github_url": "https://github.com/Alibaba-NLP/DeepResearch",
      "project_url": "https://tongyi-agent.github.io/blog/",
      "authors": [
        "Zijian Li",
        "Xin Guan",
        "Bo Zhang",
        "Shen Huang",
        "Houquan Zhou",
        "Shaopeng Lai",
        "Ming Yan",
        "Yong Jiang",
        "Pengjun Xie",
        "Fei Huang",
        "Jun Zhang",
        "Jingren Zhou"
      ],
      "summary": "This paper tackles open-ended deep research (OEDR), a complex challenge where\nAI agents must synthesize vast web-scale information into insightful reports.\nCurrent approaches are plagued by dual-fold limitations: static research\npipelines that decouple planning from evidence acquisition and one-shot\ngeneration paradigms that easily suffer from long-context failure issues like\n\"loss in the middle\" and hallucinations. To address these challenges, we\nintroduce WebWeaver, a novel dual-agent framework that emulates the human\nresearch process. The planner operates in a dynamic cycle, iteratively\ninterleaving evidence acquisition with outline optimization to produce a\ncomprehensive, source-grounded outline linking to a memory bank of evidence.\nThe writer then executes a hierarchical retrieval and writing process,\ncomposing the report section by section. By performing targeted retrieval of\nonly the necessary evidence from the memory bank for each part, it effectively\nmitigates long-context issues. Our framework establishes a new state-of-the-art\nacross major OEDR benchmarks, including DeepResearch Bench, DeepConsult, and\nDeepResearchGym. These results validate our human-centric, iterative\nmethodology, demonstrating that adaptive planning and focused synthesis are\ncrucial for producing high-quality, reliable, and well-structured reports.",
      "fetch_date": "2025-09-17",
      "num_comments": 5,
      "ai_summary": "WebWeaver, a dual-agent framework, addresses open-ended deep research challenges by integrating adaptive planning and focused synthesis to produce high-quality, reliable reports.",
      "ai_keywords": [
        "open-ended deep research",
        "AI agents",
        "static research pipelines",
        "one-shot generation",
        "long-context failure",
        "loss in the middle",
        "hallucinations",
        "dual-agent framework",
        "human research process",
        "planner",
        "evidence acquisition",
        "outline optimization",
        "memory bank",
        "writer",
        "hierarchical retrieval",
        "writing process",
        "DeepResearch Bench",
        "DeepConsult",
        "DeepResearchGym"
      ]
    }
  },
  {
    "id": "d4b4f91354d2792a0826158fb9d00e0b",
    "source": "huggingface",
    "type": "paper",
    "title": "WebSailor-V2: Bridging the Chasm to Proprietary Agents via Synthetic\n  Data and Scalable Reinforcement Learning",
    "description": "Transcending human cognitive limitations represents a critical frontier in\nLLM training. Proprietary agentic systems like DeepResearch have demonstrated\nsuperhuman capabilities on extremely complex in...<br/>Upvotes: 86<br/>GitHub Stars: 15921<br/>Authors: Kuan Li, Zhongwang Zhang, Huifeng Yin<br/>ðŸ”— <a href=\"https://github.com/Alibaba-NLP/DeepResearch/\">GitHub</a><br/>ðŸ”— <a href=\"https://tongyi-agent.github.io/blog/\">Project Page</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2509.13305\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2509.13305",
    "external_url": "https://github.com/Alibaba-NLP/DeepResearch/",
    "published_date": "2025-09-16T13:57:03.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2509.13305",
      "upvotes": 86,
      "github_stars": 15921,
      "github_url": "https://github.com/Alibaba-NLP/DeepResearch/",
      "project_url": "https://tongyi-agent.github.io/blog/",
      "authors": [
        "Kuan Li",
        "Zhongwang Zhang",
        "Huifeng Yin",
        "Rui Ye",
        "Yida Zhao",
        "Liwen Zhang",
        "Litu Ou",
        "Dingchu Zhang",
        "Xixi Wu",
        "Jialong Wu",
        "Xinyu Wang",
        "Zile Qiao",
        "Zhen Zhang",
        "Yong Jiang",
        "Pengjun Xie",
        "Fei Huang",
        "Jingren Zhou"
      ],
      "summary": "Transcending human cognitive limitations represents a critical frontier in\nLLM training. Proprietary agentic systems like DeepResearch have demonstrated\nsuperhuman capabilities on extremely complex information-seeking benchmarks\nsuch as BrowseComp, a feat previously unattainable. We posit that their success\nhinges on a sophisticated reasoning pattern absent in open-source models: the\nability to systematically reduce extreme uncertainty when navigating vast\ninformation landscapes. Based on this insight, we introduce WebSailor, a\ncomplete post-training methodology designed to instill this crucial capability.\nOur approach involves generating novel, high-uncertainty tasks through\nstructured sampling and information obfuscation, RFT cold start, and an\nefficient agentic RL training algorithm, Duplicating Sampling Policy\nOptimization (DUPO). With this integrated pipeline, WebSailor significantly\noutperforms all open-source agents in complex information-seeking tasks,\nmatching proprietary agents' performance and closing the capability gap.",
      "fetch_date": "2025-09-17",
      "num_comments": 4,
      "ai_summary": "WebSailor, a post-training methodology, enhances open-source models with systematic uncertainty reduction, matching proprietary agents' performance in complex information-seeking tasks.",
      "ai_keywords": [
        "LLM training",
        "DeepResearch",
        "BrowseComp",
        "reasoning pattern",
        "high-uncertainty tasks",
        "structured sampling",
        "information obfuscation",
        "RFT cold start",
        "agentic RL training",
        "Duplicating Sampling Policy Optimization",
        "DUPO"
      ]
    }
  },
  {
    "id": "56ef9e3095cf3666002acddf23dee4ac",
    "source": "huggingface",
    "type": "paper",
    "title": "ReSum: Unlocking Long-Horizon Search Intelligence via Context\n  Summarization",
    "description": "Large Language Model (LLM)-based web agents demonstrate strong performance on\nknowledge-intensive tasks but are hindered by context window limitations in\nparadigms like ReAct. Complex queries involvin...<br/>Upvotes: 77<br/>GitHub Stars: 15921<br/>Authors: Xixi Wu, Kuan Li, Yida Zhao<br/>ðŸ”— <a href=\"https://github.com/Alibaba-NLP/DeepResearch//\">GitHub</a><br/>ðŸ”— <a href=\"https://tongyi-agent.github.io/blog/\">Project Page</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2509.13313\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2509.13313",
    "external_url": "https://github.com/Alibaba-NLP/DeepResearch//",
    "published_date": "2025-09-16T13:57:22.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2509.13313",
      "upvotes": 77,
      "github_stars": 15921,
      "github_url": "https://github.com/Alibaba-NLP/DeepResearch//",
      "project_url": "https://tongyi-agent.github.io/blog/",
      "authors": [
        "Xixi Wu",
        "Kuan Li",
        "Yida Zhao",
        "Liwen Zhang",
        "Litu Ou",
        "Huifeng Yin",
        "Zhongwang Zhang",
        "Yong Jiang",
        "Pengjun Xie",
        "Fei Huang",
        "Minhao Cheng",
        "Shuai Wang",
        "Hong Cheng",
        "Jingren Zhou"
      ],
      "summary": "Large Language Model (LLM)-based web agents demonstrate strong performance on\nknowledge-intensive tasks but are hindered by context window limitations in\nparadigms like ReAct. Complex queries involving multiple entities, intertwined\nrelationships, and high uncertainty demand extensive search cycles that rapidly\nexhaust context budgets before reaching complete solutions. To overcome this\nchallenge, we introduce ReSum, a novel paradigm that enables indefinite\nexploration through periodic context summarization. ReSum converts growing\ninteraction histories into compact reasoning states, maintaining awareness of\nprior discoveries while bypassing context constraints. For paradigm adaptation,\nwe propose ReSum-GRPO, integrating GRPO with segmented trajectory training and\nadvantage broadcasting to familiarize agents with summary-conditioned\nreasoning. Extensive experiments on web agents of varying scales across three\nbenchmarks demonstrate that ReSum delivers an average absolute improvement of\n4.5\\% over ReAct, with further gains of up to 8.2\\% following ReSum-GRPO\ntraining. Notably, with only 1K training samples, our WebResummer-30B (a\nReSum-GRPO-trained version of WebSailor-30B) achieves 33.3\\% Pass@1 on\nBrowseComp-zh and 18.3\\% on BrowseComp-en, surpassing existing open-source web\nagents.",
      "fetch_date": "2025-09-17",
      "num_comments": 5,
      "ai_summary": "ReSum, a novel paradigm with periodic context summarization, enhances web agents' performance on knowledge-intensive tasks by overcoming context window limitations, achieving significant improvements over ReAct.",
      "ai_keywords": [
        "Large Language Model",
        "LLM",
        "web agents",
        "knowledge-intensive tasks",
        "context window limitations",
        "ReAct",
        "ReSum",
        "context summarization",
        "reasoning states",
        "GRPO",
        "segmented trajectory training",
        "advantage broadcasting",
        "ReSum-GRPO",
        "WebResummer-30B",
        "WebSailor-30B",
        "BrowseComp-zh",
        "BrowseComp-en",
        "Pass@1"
      ]
    }
  }
]