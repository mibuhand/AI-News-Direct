[
  {
    "id": "7a9ae43171e964d5b9a58c9a76f8c373",
    "source": "huggingface",
    "type": "paper",
    "title": "The Dragon Hatchling: The Missing Link between the Transformer and\n  Models of the Brain",
    "description": "The relationship between computing systems and the brain has served as\nmotivation for pioneering theoreticians since John von Neumann and Alan Turing.\nUniform, scale-free biological networks, such as ...<br/>Upvotes: 518<br/>GitHub Stars: 3256<br/>Authors: Adrian Kosowski, PrzemysÅ‚aw UznaÅ„ski, Jan Chorowski<br/>ðŸ”— <a href=\"https://github.com/pathwaycom/bdh\">GitHub</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2509.26507\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2509.26507",
    "external_url": "https://github.com/pathwaycom/bdh",
    "published_date": "2025-09-30T12:49:01.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2509.26507",
      "upvotes": 518,
      "github_stars": 3256,
      "github_url": "https://github.com/pathwaycom/bdh",
      "project_url": "",
      "authors": [
        "Adrian Kosowski",
        "PrzemysÅ‚aw UznaÅ„ski",
        "Jan Chorowski",
        "Zuzanna Stamirowska",
        "MichaÅ‚ Bartoszkiewicz"
      ],
      "summary": "The relationship between computing systems and the brain has served as\nmotivation for pioneering theoreticians since John von Neumann and Alan Turing.\nUniform, scale-free biological networks, such as the brain, have powerful\nproperties, including generalizing over time, which is the main barrier for\nMachine Learning on the path to Universal Reasoning Models.\n  We introduce `Dragon Hatchling' (BDH), a new Large Language Model\narchitecture based on a scale-free biologically inspired network of \\n\nlocally-interacting neuron particles. BDH couples strong theoretical\nfoundations and inherent interpretability without sacrificing Transformer-like\nperformance.\n  BDH is a practical, performant state-of-the-art attention-based state space\nsequence learning architecture. In addition to being a graph model, BDH admits\na GPU-friendly formulation. It exhibits Transformer-like scaling laws:\nempirically BDH rivals GPT2 performance on language and translation tasks, at\nthe same number of parameters (10M to 1B), for the same training data.\n  BDH can be represented as a brain model. The working memory of BDH during\ninference entirely relies on synaptic plasticity with Hebbian learning using\nspiking neurons. We confirm empirically that specific, individual synapses\nstrengthen connection whenever BDH hears or reasons about a specific concept\nwhile processing language inputs. The neuron interaction network of BDH is a\ngraph of high modularity with heavy-tailed degree distribution. The BDH model\nis biologically plausible, explaining one possible mechanism which human\nneurons could use to achieve speech.\n  BDH is designed for interpretability. Activation vectors of BDH are sparse\nand positive. We demonstrate monosemanticity in BDH on language tasks.\nInterpretability of state, which goes beyond interpretability of neurons and\nmodel parameters, is an inherent feature of the BDH architecture.",
      "fetch_date": "2025-10-01",
      "num_comments": 21,
      "ai_summary": "BDH, a biologically inspired Large Language Model, combines scale-free network architecture with Hebbian learning to achieve Transformer-like performance while maintaining interpretability.",
      "ai_keywords": [
        "Large Language Model",
        "scale-free network",
        "Hebbian learning",
        "synaptic plasticity",
        "spiking neurons",
        "graph model",
        "GPU-friendly",
        "Transformer-like scaling laws",
        "monosemanticity",
        "interpretability"
      ]
    }
  },
  {
    "id": "3d55a02b14bdc7a04256ce32475eb075",
    "source": "huggingface",
    "type": "paper",
    "title": "Less is More: Recursive Reasoning with Tiny Networks",
    "description": "Hierarchical Reasoning Model (HRM) is a novel approach using two small neural\nnetworks recursing at different frequencies. This biologically inspired method\nbeats Large Language models (LLMs) on hard ...<br/>Upvotes: 457<br/>GitHub Stars: 5307<br/>Authors: Alexia Jolicoeur-Martineau<br/>ðŸ”— <a href=\"https://github.com/SamsungSAILMontreal/TinyRecursiveModels\">GitHub</a><br/>ðŸ”— <a href=\"https://alexiajm.github.io/2025/09/29/tiny_recursive_models.html#\">Project Page</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2510.04871\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2510.04871",
    "external_url": "https://github.com/SamsungSAILMontreal/TinyRecursiveModels",
    "published_date": "2025-10-06T10:58:08.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2510.04871",
      "upvotes": 457,
      "github_stars": 5307,
      "github_url": "https://github.com/SamsungSAILMontreal/TinyRecursiveModels",
      "project_url": "https://alexiajm.github.io/2025/09/29/tiny_recursive_models.html#",
      "authors": [
        "Alexia Jolicoeur-Martineau"
      ],
      "summary": "Hierarchical Reasoning Model (HRM) is a novel approach using two small neural\nnetworks recursing at different frequencies. This biologically inspired method\nbeats Large Language models (LLMs) on hard puzzle tasks such as Sudoku, Maze,\nand ARC-AGI while trained with small models (27M parameters) on small data\n(around 1000 examples). HRM holds great promise for solving hard problems with\nsmall networks, but it is not yet well understood and may be suboptimal. We\npropose Tiny Recursive Model (TRM), a much simpler recursive reasoning approach\nthat achieves significantly higher generalization than HRM, while using a\nsingle tiny network with only 2 layers. With only 7M parameters, TRM obtains\n45% test-accuracy on ARC-AGI-1 and 8% on ARC-AGI-2, higher than most LLMs\n(e.g., Deepseek R1, o3-mini, Gemini 2.5 Pro) with less than 0.01% of the\nparameters.",
      "fetch_date": "2025-10-08",
      "num_comments": 41,
      "ai_summary": "Tiny Recursive Model (TRM) achieves high generalization on complex puzzle tasks using a small, two-layer network with minimal parameters, outperforming larger language models.",
      "ai_keywords": [
        "Hierarchical Reasoning Model",
        "HRM",
        "Tiny Recursive Model",
        "TRM",
        "recursive reasoning",
        "neural networks",
        "ARC-AGI",
        "Deepseek R1",
        "o3-mini",
        "Gemini 2.5 Pro"
      ]
    }
  },
  {
    "id": "b5eadc2228eda785fe3e8da98ea25174",
    "source": "huggingface",
    "type": "paper",
    "title": "Agent Learning via Early Experience",
    "description": "A long-term goal of language agents is to learn and improve through their own\nexperience, ultimately outperforming humans in complex, real-world tasks.\nHowever, training agents from experience data wi...<br/>Upvotes: 254<br/>Authors: Kai Zhang, Xiangchao Chen, Bo Liu<br/>ðŸ”— <a href=\"https://huggingface.co/papers/2510.08558\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2510.08558",
    "external_url": "",
    "published_date": "2025-10-09T13:59:17.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2510.08558",
      "upvotes": 254,
      "github_stars": 0,
      "github_url": "",
      "project_url": "",
      "authors": [
        "Kai Zhang",
        "Xiangchao Chen",
        "Bo Liu",
        "Tianci Xue",
        "Zeyi Liao",
        "Zhihan Liu",
        "Xiyao Wang",
        "Yuting Ning",
        "Zhaorun Chen",
        "Xiaohan Fu",
        "Jian Xie",
        "Yuxuan Sun",
        "Boyu Gou",
        "Qi Qi",
        "Zihang Meng",
        "Jianwei Yang",
        "Ning Zhang",
        "Xian Li",
        "Ashish Shah",
        "Dat Huynh",
        "Hengduo Li",
        "Zi Yang",
        "Sara Cao",
        "Lawrence Jang",
        "Shuyan Zhou",
        "Jiacheng Zhu",
        "Huan Sun",
        "Jason Weston",
        "Yu Su",
        "Yifan Wu"
      ],
      "summary": "A long-term goal of language agents is to learn and improve through their own\nexperience, ultimately outperforming humans in complex, real-world tasks.\nHowever, training agents from experience data with reinforcement learning\nremains difficult in many environments, which either lack verifiable rewards\n(e.g., websites) or require inefficient long-horizon rollouts (e.g., multi-turn\ntool use). As a result, most current agents rely on supervised fine-tuning on\nexpert data, which is challenging to scale and generalizes poorly. This\nlimitation stems from the nature of expert demonstrations: they capture only a\nnarrow range of scenarios and expose the agent to limited environment\ndiversity. We address this limitation with a middle-ground paradigm we call\nearly experience: interaction data generated by the agent's own actions, where\nthe resulting future states serve as supervision without reward signals. Within\nthis paradigm we study two strategies of using such data: (1) Implicit world\nmodeling, which uses collected states to ground the policy in environment\ndynamics; and (2) Self-reflection, where the agent learns from its suboptimal\nactions to improve reasoning and decision-making. We evaluate across eight\ndiverse environments and multiple model families. Our approaches consistently\nimprove effectiveness and out-of-domain generalization, highlighting the value\nof early experience. Moreover, in environments with verifiable rewards, our\nresults provide promising signals that early experience offers a strong\nfoundation for subsequent reinforcement learning, positioning it as a practical\nbridge between imitation learning and fully experience-driven agents.",
      "fetch_date": "2025-10-10",
      "num_comments": 10,
      "ai_summary": "Early experience, using agent-generated interaction data without reward signals, improves policy effectiveness and generalization, serving as a bridge between imitation learning and reinforcement learning.",
      "ai_keywords": [
        "reinforcement learning",
        "early experience",
        "implicit world modeling",
        "self-reflection",
        "out-of-domain generalization"
      ]
    }
  },
  {
    "id": "652276de74e8a80281a665d98165228d",
    "source": "huggingface",
    "type": "paper",
    "title": "MCPMark: A Benchmark for Stress-Testing Realistic and Comprehensive MCP\n  Use",
    "description": "MCP standardizes how LLMs interact with external systems, forming the\nfoundation for general agents. However, existing MCP benchmarks remain narrow\nin scope: they focus on read-heavy tasks or tasks wi...<br/>Upvotes: 170<br/>GitHub Stars: 289<br/>Authors: Zijian Wu, Xiangyan Liu, Xinyuan Zhang<br/>ðŸ”— <a href=\"https://github.com/eval-sys/mcpmark\">GitHub</a><br/>ðŸ”— <a href=\"https://mcpmark.ai/\">Project Page</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2509.24002\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2509.24002",
    "external_url": "https://github.com/eval-sys/mcpmark",
    "published_date": "2025-09-28T13:53:27.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2509.24002",
      "upvotes": 170,
      "github_stars": 289,
      "github_url": "https://github.com/eval-sys/mcpmark",
      "project_url": "https://mcpmark.ai/",
      "authors": [
        "Zijian Wu",
        "Xiangyan Liu",
        "Xinyuan Zhang",
        "Lingjun Chen",
        "Fanqing Meng",
        "Lingxiao Du",
        "Yiran Zhao",
        "Fanshi Zhang",
        "Yaoqi Ye",
        "Jiawei Wang",
        "Zirui Wang",
        "Jinjie Ni",
        "Yufan Yang",
        "Arvin Xu",
        "Michael Qizhe Shieh"
      ],
      "summary": "MCP standardizes how LLMs interact with external systems, forming the\nfoundation for general agents. However, existing MCP benchmarks remain narrow\nin scope: they focus on read-heavy tasks or tasks with limited interaction\ndepth, and fail to capture the complexity and realism of real-world workflows.\nTo address this gap, we propose MCPMark, a benchmark designed to evaluate MCP\nuse in a more realistic and comprehensive manner. It consists of 127\nhigh-quality tasks collaboratively created by domain experts and AI agents.\nEach task begins with a curated initial state and includes a programmatic\nscript for automatic verification. These tasks demand richer and more diverse\ninteractions with the environment, involving a broad range of create, read,\nupdate, and delete (CRUD) operations. We conduct a comprehensive evaluation of\ncutting-edge LLMs using a minimal agent framework that operates in a\ntool-calling loop. Empirical results show that the best-performing model,\ngpt-5-medium, reaches only 52.56\\% pass@1 and 33.86\\% pass^4, while other\nwidely regarded strong models, including claude-sonnet-4 and o3, fall below\n30\\% pass@1 and 15\\% pass^4. On average, LLMs require 16.2 execution\nturns and 17.4 tool calls per task, significantly surpassing those in\nprevious MCP benchmarks and highlighting the stress-testing nature of MCPMark.",
      "fetch_date": "2025-10-01",
      "num_comments": 8,
      "ai_summary": "MCPMark is a comprehensive benchmark for evaluating MCP use in real-world workflows, featuring diverse tasks that require richer interactions with the environment, and reveals that current LLMs perform poorly on these tasks.",
      "ai_keywords": [
        "MCP",
        "LLMs",
        "general agents",
        "MCP benchmarks",
        "MCPMark",
        "high-quality tasks",
        "domain experts",
        "AI agents",
        "initial state",
        "programmatic script",
        "automatic verification",
        "CRUD operations",
        "minimal agent framework",
        "tool-calling loop",
        "gpt-5-medium",
        "claude-sonnet-4",
        "o3",
        "pass@1",
        "pass^4",
        "execution turns",
        "tool calls"
      ]
    }
  },
  {
    "id": "f5ecd82d2d6a90e1b4eb7c0d2afe9c3e",
    "source": "huggingface",
    "type": "paper",
    "title": "QeRL: Beyond Efficiency -- Quantization-enhanced Reinforcement Learning\n  for LLMs",
    "description": "We propose QeRL, a Quantization-enhanced Reinforcement Learning framework for\nlarge language models (LLMs). While RL is essential for LLMs' reasoning\ncapabilities, it is resource-intensive, requiring ...<br/>Upvotes: 168<br/>GitHub Stars: 382<br/>Authors: Wei Huang, Yi Ge, Shuai Yang<br/>ðŸ”— <a href=\"https://github.com/NVlabs/QeRL\">GitHub</a><br/>ðŸ”— <a href=\"https://github.com/NVlabs/QeRL\">Project Page</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2510.11696\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2510.11696",
    "external_url": "https://github.com/NVlabs/QeRL",
    "published_date": "2025-10-13T13:55:09.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2510.11696",
      "upvotes": 168,
      "github_stars": 382,
      "github_url": "https://github.com/NVlabs/QeRL",
      "project_url": "https://github.com/NVlabs/QeRL",
      "authors": [
        "Wei Huang",
        "Yi Ge",
        "Shuai Yang",
        "Yicheng Xiao",
        "Huizi Mao",
        "Yujun Lin",
        "Hanrong Ye",
        "Sifei Liu",
        "Ka Chun Cheung",
        "Hongxu Yin",
        "Yao Lu",
        "Xiaojuan Qi",
        "Song Han",
        "Yukang Chen"
      ],
      "summary": "We propose QeRL, a Quantization-enhanced Reinforcement Learning framework for\nlarge language models (LLMs). While RL is essential for LLMs' reasoning\ncapabilities, it is resource-intensive, requiring substantial GPU memory and\nlong rollout durations. QeRL addresses these issues by combining NVFP4\nquantization with Low-Rank Adaptation (LoRA), accelerating rollout phase of RL\nwhile reducing memory overhead. Beyond efficiency, our findings show that\nquantization noise increases policy entropy, enhancing exploration, and\nenabling the discovery of better strategies during RL. To further optimize\nexploration, QeRL introduces an Adaptive Quantization Noise (AQN) mechanism,\nwhich dynamically adjusts noise during training. Experiments demonstrate that\nQeRL delivers over 1.5 times speedup in the rollout phase. Moreover, this is\nthe first framework to enable RL training of a 32B LLM on a single H100 80GB\nGPU, while delivering overall speedups for RL training. It also achieves faster\nreward growth and higher final accuracy than 16-bit LoRA and QLoRA, while\nmatching the performance of full-parameter fine-tuning on mathematical\nbenchmarks such as GSM8K (90.8%) and MATH 500 (77.4%) in the 7B model. These\nresults establish QeRL as an efficient and effective framework for RL training\nin LLMs.",
      "fetch_date": "2025-10-14",
      "num_comments": 4,
      "ai_summary": "QeRL, a quantization-enhanced reinforcement learning framework, accelerates RL training for large language models by combining NVFP4 quantization with Low-Rank Adaptation and an Adaptive Quantization Noise mechanism, achieving significant speedups and improved performance.",
      "ai_keywords": [
        "NVFP4 quantization",
        "Low-Rank Adaptation (LoRA)",
        "Adaptive Quantization Noise (AQN)",
        "reinforcement learning",
        "large language models (LLMs)",
        "rollout phase",
        "policy entropy",
        "exploration",
        "reward growth",
        "GSM8K",
        "MATH 500"
      ]
    }
  },
  {
    "id": "9f97533076b36bd588d78f78c4352369",
    "source": "huggingface",
    "type": "paper",
    "title": "Concerto: Joint 2D-3D Self-Supervised Learning Emerges Spatial\n  Representations",
    "description": "Humans learn abstract concepts through multisensory synergy, and once formed,\nsuch representations can often be recalled from a single modality. Inspired by\nthis principle, we introduce Concerto, a mi...<br/>Upvotes: 164<br/>GitHub Stars: 2588<br/>Authors: Yujia Zhang, Xiaoyang Wu, Yixing Lao<br/>ðŸ”— <a href=\"https://github.com/Pointcept/Pointcept\">GitHub</a><br/>ðŸ”— <a href=\"https://pointcept.github.io/Concerto/\">Project Page</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2510.23607\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2510.23607",
    "external_url": "https://github.com/Pointcept/Pointcept",
    "published_date": "2025-10-27T13:59:59.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2510.23607",
      "upvotes": 164,
      "github_stars": 2588,
      "github_url": "https://github.com/Pointcept/Pointcept",
      "project_url": "https://pointcept.github.io/Concerto/",
      "authors": [
        "Yujia Zhang",
        "Xiaoyang Wu",
        "Yixing Lao",
        "Chengyao Wang",
        "Zhuotao Tian",
        "Naiyan Wang",
        "Hengshuang Zhao"
      ],
      "summary": "Humans learn abstract concepts through multisensory synergy, and once formed,\nsuch representations can often be recalled from a single modality. Inspired by\nthis principle, we introduce Concerto, a minimalist simulation of human concept\nlearning for spatial cognition, combining 3D intra-modal self-distillation with\n2D-3D cross-modal joint embedding. Despite its simplicity, Concerto learns more\ncoherent and informative spatial features, as demonstrated by zero-shot\nvisualizations. It outperforms both standalone SOTA 2D and 3D self-supervised\nmodels by 14.2% and 4.8%, respectively, as well as their feature concatenation,\nin linear probing for 3D scene perception. With full fine-tuning, Concerto sets\nnew SOTA results across multiple scene understanding benchmarks (e.g., 80.7%\nmIoU on ScanNet). We further present a variant of Concerto tailored for\nvideo-lifted point cloud spatial understanding, and a translator that linearly\nprojects Concerto representations into CLIP's language space, enabling\nopen-world perception. These results highlight that Concerto emerges spatial\nrepresentations with superior fine-grained geometric and semantic consistency.",
      "fetch_date": "2025-10-28",
      "num_comments": 4,
      "ai_summary": "Concerto, a minimalist model combining 3D self-distillation and 2D-3D joint embedding, achieves superior spatial feature learning and outperforms existing models in scene understanding and open-world perception.",
      "ai_keywords": [
        "3D intra-modal self-distillation",
        "2D-3D cross-modal joint embedding",
        "zero-shot visualizations",
        "linear probing",
        "3D scene perception",
        "ScanNet",
        "mIoU",
        "video-lifted point cloud",
        "CLIP's language space",
        "open-world perception",
        "fine-grained geometric and semantic consistency"
      ]
    }
  },
  {
    "id": "d98bf11f4930fd1159bb5f90e3f76afd",
    "source": "huggingface",
    "type": "paper",
    "title": "PaddleOCR-VL: Boosting Multilingual Document Parsing via a 0.9B\n  Ultra-Compact Vision-Language Model",
    "description": "In this report, we propose PaddleOCR-VL, a SOTA and resource-efficient model\ntailored for document parsing. Its core component is PaddleOCR-VL-0.9B, a\ncompact yet powerful vision-language model (VLM) ...<br/>Upvotes: 78<br/>GitHub Stars: 62082<br/>Authors: Cheng Cui, Ting Sun, Suyin Liang<br/>ðŸ”— <a href=\"https://github.com/PaddlePaddle/PaddleOCR\">GitHub</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2510.14528\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2510.14528",
    "external_url": "https://github.com/PaddlePaddle/PaddleOCR",
    "published_date": "2025-10-16T06:18:48.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2510.14528",
      "upvotes": 78,
      "github_stars": 62082,
      "github_url": "https://github.com/PaddlePaddle/PaddleOCR",
      "project_url": "",
      "authors": [
        "Cheng Cui",
        "Ting Sun",
        "Suyin Liang",
        "Tingquan Gao",
        "Zelun Zhang",
        "Jiaxuan Liu",
        "Xueqing Wang",
        "Changda Zhou",
        "Hongen Liu",
        "Manhui Lin",
        "Yue Zhang",
        "Yubo Zhang",
        "Handong Zheng",
        "Jing Zhang",
        "Jun Zhang",
        "Yi Liu",
        "Dianhai Yu",
        "Yanjun Ma"
      ],
      "summary": "In this report, we propose PaddleOCR-VL, a SOTA and resource-efficient model\ntailored for document parsing. Its core component is PaddleOCR-VL-0.9B, a\ncompact yet powerful vision-language model (VLM) that integrates a NaViT-style\ndynamic resolution visual encoder with the ERNIE-4.5-0.3B language model to\nenable accurate element recognition. This innovative model efficiently supports\n109 languages and excels in recognizing complex elements (e.g., text, tables,\nformulas, and charts), while maintaining minimal resource consumption. Through\ncomprehensive evaluations on widely used public benchmarks and in-house\nbenchmarks, PaddleOCR-VL achieves SOTA performance in both page-level document\nparsing and element-level recognition. It significantly outperforms existing\nsolutions, exhibits strong competitiveness against top-tier VLMs, and delivers\nfast inference speeds. These strengths make it highly suitable for practical\ndeployment in real-world scenarios.",
      "fetch_date": "2025-10-17",
      "num_comments": 5,
      "ai_summary": "PaddleOCR-VL, a vision-language model combining NaViT-style visual encoder and ERNIE-4.5 language model, achieves state-of-the-art performance in document parsing with minimal resource consumption.",
      "ai_keywords": [
        "vision-language model",
        "NaViT-style",
        "dynamic resolution visual encoder",
        "ERNIE-4.5",
        "element recognition",
        "page-level document parsing",
        "element-level recognition",
        "inference speeds"
      ]
    }
  },
  {
    "id": "4477d6ceb0f6af4c535f87fb4c3e55f5",
    "source": "huggingface",
    "type": "paper",
    "title": "BitNet Distillation",
    "description": "In this paper, we present BitNet Distillation (BitDistill), a lightweight\npipeline that fine-tunes off-the-shelf full-precision LLMs (e.g., Qwen) into\n1.58-bit precision (i.e., ternary weights {-1, 0,...<br/>Upvotes: 51<br/>GitHub Stars: 24321<br/>Authors: Xun Wu, Shaohan Huang, Wenhui Wang<br/>ðŸ”— <a href=\"https://github.com/microsoft/BitNet\">GitHub</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2510.13998\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2510.13998",
    "external_url": "https://github.com/microsoft/BitNet",
    "published_date": "2025-10-15T14:28:12.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2510.13998",
      "upvotes": 51,
      "github_stars": 24321,
      "github_url": "https://github.com/microsoft/BitNet",
      "project_url": "",
      "authors": [
        "Xun Wu",
        "Shaohan Huang",
        "Wenhui Wang",
        "Ting Song",
        "Li Dong",
        "Yan Xia",
        "Furu Wei"
      ],
      "summary": "In this paper, we present BitNet Distillation (BitDistill), a lightweight\npipeline that fine-tunes off-the-shelf full-precision LLMs (e.g., Qwen) into\n1.58-bit precision (i.e., ternary weights {-1, 0, 1}) for specific downstream\ntasks, achieving strong task-specific performance with minimal computational\ncost. Specifically, BitDistill incorporates three key techniques: the SubLN\nmodule, as introduced in BitNet; multi-head attention distillation, based on\nMiniLM; and continual pre-training, which serves as a crucial warm-up step to\nmitigate the scalability issue of the performance gap between finetuned\nfull-precision and 1.58-bit LLMs on specific tasks. Experimental results show\nthat BitDistill achieves performance comparable to the full-precision\ncounterpart models across model size, while enabling up to 10x memory savings\nand 2.65x faster inference on CPUs. Code is available at\nhttps://github.com/microsoft/BitNet.",
      "fetch_date": "2025-10-17",
      "num_comments": 4,
      "ai_summary": "BitNet Distillation fine-tunes large language models to 1.58-bit precision using SubLN, multi-head attention distillation, and continual pre-training, achieving comparable performance with significant memory and inference speed improvements.",
      "ai_keywords": [
        "BitNet Distillation",
        "BitDistill",
        "SubLN",
        "multi-head attention distillation",
        "continual pre-training",
        "LLMs",
        "Qwen",
        "ternary weights",
        "memory savings",
        "inference speed"
      ]
    }
  },
  {
    "id": "bf88f955951ceb1c5ba0121481fe4bf5",
    "source": "huggingface",
    "type": "paper",
    "title": "FAPO: Flawed-Aware Policy Optimization for Efficient and Reliable\n  Reasoning",
    "description": "Reinforcement learning with verifiable rewards (RLVR) has emerged as a\npromising paradigm for enhancing the reasoning capabilities of large language\nmodels (LLMs). In this context, models explore reas...<br/>Upvotes: 4<br/>GitHub Stars: 14956<br/>Authors: Yuyang Ding, Chi Zhang, Juntao Li<br/>ðŸ”— <a href=\"https://github.com/volcengine/verl/tree/main/recipe/fapo\">GitHub</a><br/>ðŸ”— <a href=\"https://fapo-rl.github.io/\">Project Page</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2510.22543\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2510.22543",
    "external_url": "https://github.com/volcengine/verl/tree/main/recipe/fapo",
    "published_date": "2025-10-26T01:49:38.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2510.22543",
      "upvotes": 4,
      "github_stars": 14956,
      "github_url": "https://github.com/volcengine/verl/tree/main/recipe/fapo",
      "project_url": "https://fapo-rl.github.io/",
      "authors": [
        "Yuyang Ding",
        "Chi Zhang",
        "Juntao Li",
        "Haibin Lin",
        "Xin Liu",
        "Min Zhang"
      ],
      "summary": "Reinforcement learning with verifiable rewards (RLVR) has emerged as a\npromising paradigm for enhancing the reasoning capabilities of large language\nmodels (LLMs). In this context, models explore reasoning trajectories and\nexploit rollouts with correct answers as positive signals for policy\noptimization. However, these rollouts might involve flawed patterns such as\nanswer-guessing and jump-in-reasoning. Such flawed-positive rollouts are\nrewarded identically to fully correct ones, causing policy models to\ninternalize these unreliable reasoning patterns. In this work, we first conduct\na systematic study of flawed-positive rollouts in RL and find that they enable\nrapid capability gains during the early optimization stage, while constraining\nreasoning capability later by reinforcing unreliable patterns. Building on\nthese insights, we propose Flawed-Aware Policy Optimization (FAPO), which\npresents a parameter-free reward penalty for flawed-positive rollouts, enabling\nthe policy to leverage them as useful shortcuts in the warm-up stage, securing\nstable early gains, while gradually shifting optimization toward reliable\nreasoning in the later refinement stage. To accurately and comprehensively\ndetect flawed-positive rollouts, we introduce a generative reward model (GenRM)\nwith a process-level reward that precisely localizes reasoning errors.\nExperiments show that FAPO is effective in broad domains, improving outcome\ncorrectness, process reliability, and training stability without increasing the\ntoken budget.",
      "fetch_date": "2025-10-30",
      "num_comments": 1,
      "ai_summary": "Flawed-Aware Policy Optimization (FAPO) improves reinforcement learning with verifiable rewards by penalizing flawed-positive rollouts, enhancing reasoning capability and training stability without increasing computational cost.",
      "ai_keywords": [
        "reinforcement learning",
        "verifiable rewards",
        "large language models",
        "reasoning trajectories",
        "policy optimization",
        "flawed-positive rollouts",
        "parameter-free reward penalty",
        "generative reward model",
        "process-level reward",
        "reasoning errors",
        "outcome correctness",
        "process reliability",
        "training stability"
      ]
    }
  },
  {
    "id": "2fbd109d587f03077296ef20d0d7459e",
    "source": "huggingface",
    "type": "paper",
    "title": "JoyAgent-JDGenie: Technical Report on the GAIA",
    "description": "Large Language Models are increasingly deployed as autonomous agents for\ncomplex real-world tasks, yet existing systems often focus on isolated\nimprovements without a unifying design for robustness an...<br/>Upvotes: 3<br/>GitHub Stars: 10597<br/>Authors: Jiarun Liu, Shiyue Xu, Shangkun Liu<br/>ðŸ”— <a href=\"https://github.com/jd-opensource/joyagent-jdgenie\">GitHub</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2510.00510\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2510.00510",
    "external_url": "https://github.com/jd-opensource/joyagent-jdgenie",
    "published_date": "2025-10-01T00:41:58.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2510.00510",
      "upvotes": 3,
      "github_stars": 10597,
      "github_url": "https://github.com/jd-opensource/joyagent-jdgenie",
      "project_url": "",
      "authors": [
        "Jiarun Liu",
        "Shiyue Xu",
        "Shangkun Liu",
        "Yang Li",
        "Wen Liu",
        "Min Liu",
        "Xiaoqing Zhou",
        "Hanmin Wang",
        "Shilin Jia",
        "zhen Wang",
        "Shaohua Tian",
        "Hanhao Li",
        "Junbo Zhang",
        "Yongli Yu",
        "Peng Cao",
        "Haofen Wang"
      ],
      "summary": "Large Language Models are increasingly deployed as autonomous agents for\ncomplex real-world tasks, yet existing systems often focus on isolated\nimprovements without a unifying design for robustness and adaptability. We\npropose a generalist agent architecture that integrates three core components:\na collective multi-agent framework combining planning and execution agents with\ncritic model voting, a hierarchical memory system spanning working, semantic,\nand procedural layers, and a refined tool suite for search, code execution, and\nmultimodal parsing. Evaluated on a comprehensive benchmark, our framework\nconsistently outperforms open-source baselines and approaches the performance\nof proprietary systems. These results demonstrate the importance of\nsystem-level integration and highlight a path toward scalable, resilient, and\nadaptive AI assistants capable of operating across diverse domains and tasks.",
      "fetch_date": "2025-10-02",
      "num_comments": 2,
      "ai_summary": "A generalist agent architecture combining multi-agent planning, hierarchical memory, and a refined tool suite outperforms existing systems in diverse tasks.",
      "ai_keywords": [
        "multi-agent framework",
        "planning agents",
        "execution agents",
        "critic model voting",
        "hierarchical memory system",
        "working memory",
        "semantic memory",
        "procedural memory",
        "tool suite",
        "search",
        "code execution",
        "multimodal parsing"
      ]
    }
  },
  {
    "id": "2431e39c5ab567b865fe3f25b69b4d35",
    "source": "huggingface",
    "type": "paper",
    "title": "RAG-Anything: All-in-One RAG Framework",
    "description": "Retrieval-Augmented Generation (RAG) has emerged as a fundamental paradigm\nfor expanding Large Language Models beyond their static training limitations.\nHowever, a critical misalignment exists between...<br/>Upvotes: 42<br/>GitHub Stars: 9793<br/>Authors: Zirui Guo, Xubin Ren, Lingrui Xu<br/>ðŸ”— <a href=\"https://github.com/HKUDS/RAG-Anything\">GitHub</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2510.12323\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2510.12323",
    "external_url": "https://github.com/HKUDS/RAG-Anything",
    "published_date": "2025-10-14T05:25:35.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2510.12323",
      "upvotes": 42,
      "github_stars": 9793,
      "github_url": "https://github.com/HKUDS/RAG-Anything",
      "project_url": "",
      "authors": [
        "Zirui Guo",
        "Xubin Ren",
        "Lingrui Xu",
        "Jiahao Zhang",
        "Chao Huang"
      ],
      "summary": "Retrieval-Augmented Generation (RAG) has emerged as a fundamental paradigm\nfor expanding Large Language Models beyond their static training limitations.\nHowever, a critical misalignment exists between current RAG capabilities and\nreal-world information environments. Modern knowledge repositories are\ninherently multimodal, containing rich combinations of textual content, visual\nelements, structured tables, and mathematical expressions. Yet existing RAG\nframeworks are limited to textual content, creating fundamental gaps when\nprocessing multimodal documents. We present RAG-Anything, a unified framework\nthat enables comprehensive knowledge retrieval across all modalities. Our\napproach reconceptualizes multimodal content as interconnected knowledge\nentities rather than isolated data types. The framework introduces dual-graph\nconstruction to capture both cross-modal relationships and textual semantics\nwithin a unified representation. We develop cross-modal hybrid retrieval that\ncombines structural knowledge navigation with semantic matching. This enables\neffective reasoning over heterogeneous content where relevant evidence spans\nmultiple modalities. RAG-Anything demonstrates superior performance on\nchallenging multimodal benchmarks, achieving significant improvements over\nstate-of-the-art methods. Performance gains become particularly pronounced on\nlong documents where traditional approaches fail. Our framework establishes a\nnew paradigm for multimodal knowledge access, eliminating the architectural\nfragmentation that constrains current systems. Our framework is open-sourced\nat: https://github.com/HKUDS/RAG-Anything.",
      "fetch_date": "2025-10-15",
      "num_comments": 5,
      "ai_summary": "RAG-Anything is a unified framework that enhances multimodal knowledge retrieval by integrating cross-modal relationships and semantic matching, outperforming existing methods on complex benchmarks.",
      "ai_keywords": [
        "Retrieval-Augmented Generation",
        "RAG",
        "Large Language Models",
        "multimodal",
        "textual content",
        "visual elements",
        "structured tables",
        "mathematical expressions",
        "dual-graph construction",
        "cross-modal hybrid retrieval",
        "structural knowledge navigation",
        "semantic matching",
        "multimodal benchmarks",
        "long documents"
      ]
    }
  },
  {
    "id": "5c99dbab179702139c4bd03a805804f8",
    "source": "huggingface",
    "type": "paper",
    "title": "The Unreasonable Effectiveness of Scaling Agents for Computer Use",
    "description": "Computer-use agents (CUAs) hold promise for automating everyday digital\ntasks, but their unreliability and high variance hinder their application to\nlong-horizon, complex tasks. We introduce Behavior ...<br/>Upvotes: 23<br/>GitHub Stars: 7752<br/>Authors: Gonzalo Gonzalez-Pumariega, Vincent Tu, Chih-Lun Lee<br/>ðŸ”— <a href=\"https://github.com/simular-ai/Agent-S/\">GitHub</a><br/>ðŸ”— <a href=\"https://www.simular.ai/articles/agent-s3\">Project Page</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2510.02250\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2510.02250",
    "external_url": "https://github.com/simular-ai/Agent-S/",
    "published_date": "2025-10-02T13:37:08.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2510.02250",
      "upvotes": 23,
      "github_stars": 7752,
      "github_url": "https://github.com/simular-ai/Agent-S/",
      "project_url": "https://www.simular.ai/articles/agent-s3",
      "authors": [
        "Gonzalo Gonzalez-Pumariega",
        "Vincent Tu",
        "Chih-Lun Lee",
        "Jiachen Yang",
        "Ang Li",
        "Xin Eric Wang"
      ],
      "summary": "Computer-use agents (CUAs) hold promise for automating everyday digital\ntasks, but their unreliability and high variance hinder their application to\nlong-horizon, complex tasks. We introduce Behavior Best-of-N (bBoN), a method\nthat scales over agents by generating multiple rollouts and selecting among\nthem using behavior narratives that describe the agents' rollouts. It enables\nboth wide exploration and principled trajectory selection, substantially\nimproving robustness and success rates. On OSWorld, our bBoN scaling method\nestablishes a new state of the art (SoTA) at 69.9%, significantly outperforming\nprior methods and approaching human-level performance at 72%, with\ncomprehensive ablations validating key design choices. We further demonstrate\nstrong generalization results to different operating systems on\nWindowsAgentArena and AndroidWorld. Crucially, our results highlight the\nunreasonable effectiveness of scaling CUAs, when you do it right: effective\nscaling requires structured trajectory understanding and selection, and bBoN\nprovides a practical framework to achieve this.",
      "fetch_date": "2025-10-03",
      "num_comments": 2,
      "ai_summary": "Behavior Best-of-N (bBoN) improves the reliability and success rates of computer-use agents by generating and selecting among multiple rollouts using behavior narratives, achieving state-of-the-art performance on OSWorld and strong generalization to different operating systems.",
      "ai_keywords": [
        "Behavior Best-of-N",
        "bBoN",
        "rollouts",
        "behavior narratives",
        "trajectory selection",
        "OSWorld",
        "WindowsAgentArena",
        "AndroidWorld"
      ]
    }
  }
]