[
  {
    "id": "8c7bb673a7c23605ce494554bc937b12",
    "source": "huggingface",
    "type": "paper",
    "title": "Scaling Latent Reasoning via Looped Language Models",
    "description": "Modern LLMs are trained to \"think\" primarily via explicit text generation,\nsuch as chain-of-thought (CoT), which defers reasoning to post-training and\nunder-leverages pre-training data. We present and...<br/>Upvotes: 211<br/>Authors: Rui-Jie Zhu, Zixuan Wang, Kai Hua<br/>ðŸ”— <a href=\"https://ouro-llm.github.io/\">Project Page</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2510.25741\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2510.25741",
    "external_url": "",
    "published_date": "2025-10-29T13:45:42.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2510.25741",
      "upvotes": 211,
      "github_stars": 0,
      "github_url": "",
      "project_url": "https://ouro-llm.github.io/",
      "authors": [
        "Rui-Jie Zhu",
        "Zixuan Wang",
        "Kai Hua",
        "Tianyu Zhang",
        "Ziniu Li",
        "Haoran Que",
        "Boyi Wei",
        "Zixin Wen",
        "Fan Yin",
        "He Xing",
        "Lu Li",
        "Jiajun Shi",
        "Kaijing Ma",
        "Shanda Li",
        "Taylor Kergan",
        "Andrew Smith",
        "Xingwei Qu",
        "Mude Hui",
        "Bohong Wu",
        "Qiyang Min",
        "Hongzhi Huang",
        "Xun Zhou",
        "Wei Ye",
        "Jiaheng Liu",
        "Jian Yang",
        "Yunfeng Shi",
        "Chenghua Lin",
        "Enduo Zhao",
        "Tianle Cai",
        "Ge Zhang",
        "Wenhao Huang",
        "Yoshua Bengio",
        "Jason Eshraghian"
      ],
      "summary": "Modern LLMs are trained to \"think\" primarily via explicit text generation,\nsuch as chain-of-thought (CoT), which defers reasoning to post-training and\nunder-leverages pre-training data. We present and open-source Ouro, named after\nthe recursive Ouroboros, a family of pre-trained Looped Language Models\n(LoopLM) that instead build reasoning into the pre-training phase through (i)\niterative computation in latent space, (ii) an entropy-regularized objective\nfor learned depth allocation, and (iii) scaling to 7.7T tokens. Ouro 1.4B and\n2.6B models enjoy superior performance that match the results of up to 12B SOTA\nLLMs across a wide range of benchmarks. Through controlled experiments, we show\nthis advantage stems not from increased knowledge capacity, but from superior\nknowledge manipulation capabilities. We also show that LoopLM yields reasoning\ntraces more aligned with final outputs than explicit CoT. We hope our results\nshow the potential of LoopLM as a novel scaling direction in the reasoning era.\nOur model could be found in: http://ouro-llm.github.io.",
      "fetch_date": "2025-10-30",
      "num_comments": 4,
      "ai_summary": "LoopLM, a family of pre-trained Looped Language Models, enhances reasoning by integrating iterative computation and entropy regularization during pre-training, achieving superior performance with better knowledge manipulation.",
      "ai_keywords": [
        "Looped Language Models",
        "LoopLM",
        "iterative computation",
        "latent space",
        "entropy-regularized objective",
        "learned depth allocation",
        "chain-of-thought",
        "knowledge manipulation",
        "reasoning traces"
      ]
    }
  },
  {
    "id": "b81e62a9e2bd28a9fe78c760c27308b6",
    "source": "huggingface",
    "type": "paper",
    "title": "Thinking with Video: Video Generation as a Promising Multimodal\n  Reasoning Paradigm",
    "description": "\"Thinking with Text\" and \"Thinking with Images\" paradigm significantly\nimprove the reasoning ability of large language models (LLMs) and Vision\nLanguage Models (VLMs). However, these paradigms have in...<br/>Upvotes: 189<br/>GitHub Stars: 187<br/>Authors: Jingqi Tong, Yurong Mou, Hangcheng Li<br/>ðŸ”— <a href=\"https://github.com/tongjingqi/Thinking-with-Video\">GitHub</a><br/>ðŸ”— <a href=\"https://thinking-with-video.github.io/\">Project Page</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2511.04570\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2511.04570",
    "external_url": "https://github.com/tongjingqi/Thinking-with-Video",
    "published_date": "2025-11-06T12:25:23.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2511.04570",
      "upvotes": 189,
      "github_stars": 187,
      "github_url": "https://github.com/tongjingqi/Thinking-with-Video",
      "project_url": "https://thinking-with-video.github.io/",
      "authors": [
        "Jingqi Tong",
        "Yurong Mou",
        "Hangcheng Li",
        "Mingzhe Li",
        "Yongzhuo Yang",
        "Ming Zhang",
        "Qiguang Chen",
        "Tianyi Liang",
        "Xiaomeng Hu",
        "Yining Zheng",
        "Xinchi Chen",
        "Jun Zhao",
        "Xuanjing Huang",
        "Xipeng Qiu"
      ],
      "summary": "\"Thinking with Text\" and \"Thinking with Images\" paradigm significantly\nimprove the reasoning ability of large language models (LLMs) and Vision\nLanguage Models (VLMs). However, these paradigms have inherent limitations. (1)\nImages capture only single moments and fail to represent dynamic processes or\ncontinuous changes, and (2) The separation of text and vision as distinct\nmodalities, hindering unified multimodal understanding and generation. To\novercome these limitations, we introduce \"Thinking with Video\", a new paradigm\nthat leverages video generation models, such as Sora-2, to bridge visual and\ntextual reasoning in a unified temporal framework. To support this exploration,\nwe developed the Video Thinking Benchmark (VideoThinkBench). VideoThinkBench\nencompasses two task categories: (1) vision-centric tasks (e.g., Eyeballing\nPuzzles), and (2) text-centric tasks (e.g., subsets of GSM8K, MMMU). Our\nevaluation establishes Sora-2 as a capable reasoner. On vision-centric tasks,\nSora-2 is generally comparable to state-of-the-art (SOTA) VLMs, and even\nsurpasses VLMs on several tasks, such as Eyeballing Games. On text-centric\ntasks, Sora-2 achieves 92% accuracy on MATH, and 75.53% accuracy on MMMU.\nFurthermore, we systematically analyse the source of these abilities. We also\nfind that self-consistency and in-context learning can improve Sora-2's\nperformance. In summary, our findings demonstrate that the video generation\nmodel is the potential unified multimodal understanding and generation model,\npositions \"thinking with video\" as a unified multimodal reasoning paradigm.",
      "fetch_date": "2025-11-07",
      "num_comments": 4,
      "ai_summary": "The \"Thinking with Video\" paradigm enhances multimodal reasoning by integrating video generation models, demonstrated through the Video Thinking Benchmark and improved performance on both vision and text tasks.",
      "ai_keywords": [
        "Thinking with Text",
        "Thinking with Images",
        "large language models",
        "Vision Language Models",
        "Thinking with Video",
        "video generation models",
        "Video Thinking Benchmark",
        "vision-centric tasks",
        "text-centric tasks",
        "Eyeballing Puzzles",
        "GSM8K",
        "MMMU",
        "self-consistency",
        "in-context learning"
      ]
    }
  },
  {
    "id": "9f97533076b36bd588d78f78c4352369",
    "source": "huggingface",
    "type": "paper",
    "title": "Concerto: Joint 2D-3D Self-Supervised Learning Emerges Spatial\n  Representations",
    "description": "Humans learn abstract concepts through multisensory synergy, and once formed,\nsuch representations can often be recalled from a single modality. Inspired by\nthis principle, we introduce Concerto, a mi...<br/>Upvotes: 172<br/>GitHub Stars: 417<br/>Authors: Yujia Zhang, Xiaoyang Wu, Yixing Lao<br/>ðŸ”— <a href=\"https://github.com/Pointcept/Concerto\">GitHub</a><br/>ðŸ”— <a href=\"https://pointcept.github.io/Concerto/\">Project Page</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2510.23607\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2510.23607",
    "external_url": "https://github.com/Pointcept/Concerto",
    "published_date": "2025-10-27T13:59:59.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2510.23607",
      "upvotes": 172,
      "github_stars": 417,
      "github_url": "https://github.com/Pointcept/Concerto",
      "project_url": "https://pointcept.github.io/Concerto/",
      "authors": [
        "Yujia Zhang",
        "Xiaoyang Wu",
        "Yixing Lao",
        "Chengyao Wang",
        "Zhuotao Tian",
        "Naiyan Wang",
        "Hengshuang Zhao"
      ],
      "summary": "Humans learn abstract concepts through multisensory synergy, and once formed,\nsuch representations can often be recalled from a single modality. Inspired by\nthis principle, we introduce Concerto, a minimalist simulation of human concept\nlearning for spatial cognition, combining 3D intra-modal self-distillation with\n2D-3D cross-modal joint embedding. Despite its simplicity, Concerto learns more\ncoherent and informative spatial features, as demonstrated by zero-shot\nvisualizations. It outperforms both standalone SOTA 2D and 3D self-supervised\nmodels by 14.2% and 4.8%, respectively, as well as their feature concatenation,\nin linear probing for 3D scene perception. With full fine-tuning, Concerto sets\nnew SOTA results across multiple scene understanding benchmarks (e.g., 80.7%\nmIoU on ScanNet). We further present a variant of Concerto tailored for\nvideo-lifted point cloud spatial understanding, and a translator that linearly\nprojects Concerto representations into CLIP's language space, enabling\nopen-world perception. These results highlight that Concerto emerges spatial\nrepresentations with superior fine-grained geometric and semantic consistency.",
      "fetch_date": "2025-10-28",
      "num_comments": 4,
      "ai_summary": "Concerto, a minimalist model combining 3D self-distillation and 2D-3D joint embedding, achieves superior spatial feature learning and outperforms existing models in scene understanding and open-world perception.",
      "ai_keywords": [
        "3D intra-modal self-distillation",
        "2D-3D cross-modal joint embedding",
        "zero-shot visualizations",
        "linear probing",
        "3D scene perception",
        "ScanNet",
        "mIoU",
        "video-lifted point cloud",
        "CLIP's language space",
        "open-world perception",
        "fine-grained geometric and semantic consistency"
      ]
    }
  },
  {
    "id": "4622a47084403f1652a1baac4335b4fa",
    "source": "huggingface",
    "type": "paper",
    "title": "Lumine: An Open Recipe for Building Generalist Agents in 3D Open Worlds",
    "description": "We introduce Lumine, the first open recipe for developing generalist agents capable of completing hours-long complex missions in real time within challenging 3D open-world environments. Lumine adopts ...<br/>Upvotes: 157<br/>Authors: Weihao Tan, Xiangyang Li, Yunhao Fang<br/>ðŸ”— <a href=\"https://www.lumine-ai.org/\">Project Page</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2511.08892\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2511.08892",
    "external_url": "",
    "published_date": "2025-11-11T21:01:26.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2511.08892",
      "upvotes": 157,
      "github_stars": 0,
      "github_url": "",
      "project_url": "https://www.lumine-ai.org/",
      "authors": [
        "Weihao Tan",
        "Xiangyang Li",
        "Yunhao Fang",
        "Heyuan Yao",
        "Shi Yan",
        "Hao Luo",
        "Tenglong Ao",
        "Huihui Li",
        "Hongbin Ren",
        "Bairen Yi",
        "Yujia Qin",
        "Bo An",
        "Libin Liu",
        "Guang Shi"
      ],
      "summary": "We introduce Lumine, the first open recipe for developing generalist agents capable of completing hours-long complex missions in real time within challenging 3D open-world environments. Lumine adopts a human-like interaction paradigm that unifies perception, reasoning, and action in an end-to-end manner, powered by a vision-language model. It processes raw pixels at 5 Hz to produce precise 30 Hz keyboard-mouse actions and adaptively invokes reasoning only when necessary. Trained in Genshin Impact, Lumine successfully completes the entire five-hour Mondstadt main storyline on par with human-level efficiency and follows natural language instructions to perform a broad spectrum of tasks in both 3D open-world exploration and 2D GUI manipulation across collection, combat, puzzle-solving, and NPC interaction. In addition to its in-domain performance, Lumine demonstrates strong zero-shot cross-game generalization. Without any fine-tuning, it accomplishes 100-minute missions in Wuthering Waves and the full five-hour first chapter of Honkai: Star Rail. These promising results highlight Lumine's effectiveness across distinct worlds and interaction dynamics, marking a concrete step toward generalist agents in open-ended environments.",
      "fetch_date": "2025-11-13",
      "num_comments": 11,
      "ai_summary": "Lumine, a vision-language model-based agent, completes complex missions in real-time across different 3D open-world environments with human-like efficiency and zero-shot cross-game generalization.",
      "ai_keywords": [
        "vision-language model",
        "end-to-end",
        "3D open-world environments",
        "human-like interaction",
        "real-time",
        "zero-shot cross-game generalization"
      ]
    }
  },
  {
    "id": "fa71d4f57dc7d25049e28fe9f9644922",
    "source": "huggingface",
    "type": "paper",
    "title": "A Theoretical Study on Bridging Internal Probability and\n  Self-Consistency for LLM Reasoning",
    "description": "Test-time scaling seeks to improve the reasoning performance of large\nlanguage models (LLMs) by adding computational resources. A prevalent approach\nwithin the field is sampling-based test-time scalin...<br/>Upvotes: 145<br/>GitHub Stars: 13<br/>Authors: Zhi Zhou, Yuhao Tan, Zenan Li<br/>ðŸ”— <a href=\"https://github.com/WNJXYK/RPC\">GitHub</a><br/>ðŸ”— <a href=\"https://wnjxyk.github.io/RPC\">Project Page</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2510.15444\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2510.15444",
    "external_url": "https://github.com/WNJXYK/RPC",
    "published_date": "2025-10-17T04:59:30.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2510.15444",
      "upvotes": 145,
      "github_stars": 13,
      "github_url": "https://github.com/WNJXYK/RPC",
      "project_url": "https://wnjxyk.github.io/RPC",
      "authors": [
        "Zhi Zhou",
        "Yuhao Tan",
        "Zenan Li",
        "Yuan Yao",
        "Lan-Zhe Guo",
        "Yu-Feng Li",
        "Xiaoxing Ma"
      ],
      "summary": "Test-time scaling seeks to improve the reasoning performance of large\nlanguage models (LLMs) by adding computational resources. A prevalent approach\nwithin the field is sampling-based test-time scaling methods, which enhance\nreasoning by generating multiple reasoning paths for a given input during\ninference. However, despite its practical success, the theoretical foundations\nremain underexplored. In this paper, we provide the first theoretical framework\nfor analyzing sampling-based test-time scaling methods, grounded in the\nperspective of confidence estimation. Based on the framework, we analyze two\ndominant paradigms: self-consistency and perplexity, and reveal key\nlimitations: self-consistency suffers from high estimation error while\nperplexity exhibits substantial modeling error and possible degradation of the\nestimation error convergence. To address these limitations, we introduce RPC, a\nhybrid method that leverages our theoretical insights through two key\ncomponents: Perplexity Consistency and Reasoning Pruning. Perplexity\nConsistency combines the strengths of self-consistency and perplexity, boosting\nthe convergence rate of estimation error from linear to exponential while\npreserving model error. Reasoning Pruning prevents degradation by eliminating\nlow-probability reasoning paths. Both theoretical analysis and empirical\nresults across seven benchmark datasets demonstrate that RPC has a strong\npotential for reducing reasoning error. Notably, RPC achieves reasoning\nperformance comparable to self-consistency while not only enhancing confidence\nreliability but also reducing sampling costs by 50%. The code and resources are\navailable at https://wnjxyk.github.io/RPC.",
      "fetch_date": "2025-10-20",
      "num_comments": 6,
      "ai_summary": "A theoretical framework for sampling-based test-time scaling in large language models reveals limitations in self-consistency and perplexity, and introduces RPC to improve reasoning performance and reduce sampling costs.",
      "ai_keywords": [
        "sampling-based test-time scaling",
        "large language models",
        "self-consistency",
        "perplexity",
        "Perplexity Consistency",
        "Reasoning Pruning",
        "confidence estimation",
        "reasoning error",
        "benchmark datasets"
      ]
    }
  },
  {
    "id": "cb1e895dc25b82e9e2f05366ceb1adbe",
    "source": "huggingface",
    "type": "paper",
    "title": "ReCode: Unify Plan and Action for Universal Granularity Control",
    "description": "Real-world tasks require decisions at varying granularities, and humans excel\nat this by leveraging a unified cognitive representation where planning is\nfundamentally understood as a high-level form o...<br/>Upvotes: 119<br/>GitHub Stars: 423<br/>Authors: Zhaoyang Yu, Jiayi Zhang, Huixue Su<br/>ðŸ”— <a href=\"https://github.com/FoundationAgents/ReCode\">GitHub</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2510.23564\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2510.23564",
    "external_url": "https://github.com/FoundationAgents/ReCode",
    "published_date": "2025-10-27T13:35:15.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2510.23564",
      "upvotes": 119,
      "github_stars": 423,
      "github_url": "https://github.com/FoundationAgents/ReCode",
      "project_url": "",
      "authors": [
        "Zhaoyang Yu",
        "Jiayi Zhang",
        "Huixue Su",
        "Yufan Zhao",
        "Yifan Wu",
        "Mingyi Deng",
        "Jinyu Xiang",
        "Yizhang Lin",
        "Lingxiao Tang",
        "Yingchao Li",
        "Yuyu Luo",
        "Bang Liu",
        "Chenglin Wu"
      ],
      "summary": "Real-world tasks require decisions at varying granularities, and humans excel\nat this by leveraging a unified cognitive representation where planning is\nfundamentally understood as a high-level form of action. However, current Large\nLanguage Model (LLM)-based agents lack this crucial capability to operate\nfluidly across decision granularities. This limitation stems from existing\nparadigms that enforce a rigid separation between high-level planning and\nlow-level action, which impairs dynamic adaptability and limits generalization.\nWe propose ReCode (Recursive Code Generation), a novel paradigm that addresses\nthis limitation by unifying planning and action within a single code\nrepresentation. In this representation, ReCode treats high-level plans as\nabstract placeholder functions, which the agent then recursively decomposes\ninto finer-grained sub-functions until reaching primitive actions. This\nrecursive approach dissolves the rigid boundary between plan and action,\nenabling the agent to dynamically control its decision granularity.\nFurthermore, the recursive structure inherently generates rich,\nmulti-granularity training data, enabling models to learn hierarchical\ndecision-making processes. Extensive experiments show ReCode significantly\nsurpasses advanced baselines in inference performance and demonstrates\nexceptional data efficiency in training, validating our core insight that\nunifying planning and action through recursive code generation is a powerful\nand effective approach to achieving universal granularity control. The code is\navailable at https://github.com/FoundationAgents/ReCode.",
      "fetch_date": "2025-10-28",
      "num_comments": 1,
      "ai_summary": "ReCode, a recursive code generation paradigm, unifies high-level planning and low-level action in a single representation, enhancing decision granularity and data efficiency in LLM-based agents.",
      "ai_keywords": [
        "Large Language Model",
        "ReCode",
        "Recursive Code Generation",
        "high-level planning",
        "low-level action",
        "decision granularity",
        "abstract placeholder functions",
        "primitive actions",
        "hierarchical decision-making processes",
        "inference performance",
        "data efficiency"
      ]
    }
  },
  {
    "id": "bf88f955951ceb1c5ba0121481fe4bf5",
    "source": "huggingface",
    "type": "paper",
    "title": "FAPO: Flawed-Aware Policy Optimization for Efficient and Reliable\n  Reasoning",
    "description": "Reinforcement learning with verifiable rewards (RLVR) has emerged as a\npromising paradigm for enhancing the reasoning capabilities of large language\nmodels (LLMs). In this context, models explore reas...<br/>Upvotes: 7<br/>GitHub Stars: 15963<br/>Authors: Yuyang Ding, Chi Zhang, Juntao Li<br/>ðŸ”— <a href=\"https://github.com/volcengine/verl/tree/main/recipe/fapo\">GitHub</a><br/>ðŸ”— <a href=\"https://fapo-rl.github.io/\">Project Page</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2510.22543\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2510.22543",
    "external_url": "https://github.com/volcengine/verl/tree/main/recipe/fapo",
    "published_date": "2025-10-26T01:49:38.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2510.22543",
      "upvotes": 7,
      "github_stars": 15963,
      "github_url": "https://github.com/volcengine/verl/tree/main/recipe/fapo",
      "project_url": "https://fapo-rl.github.io/",
      "authors": [
        "Yuyang Ding",
        "Chi Zhang",
        "Juntao Li",
        "Haibin Lin",
        "Xin Liu",
        "Min Zhang"
      ],
      "summary": "Reinforcement learning with verifiable rewards (RLVR) has emerged as a\npromising paradigm for enhancing the reasoning capabilities of large language\nmodels (LLMs). In this context, models explore reasoning trajectories and\nexploit rollouts with correct answers as positive signals for policy\noptimization. However, these rollouts might involve flawed patterns such as\nanswer-guessing and jump-in-reasoning. Such flawed-positive rollouts are\nrewarded identically to fully correct ones, causing policy models to\ninternalize these unreliable reasoning patterns. In this work, we first conduct\na systematic study of flawed-positive rollouts in RL and find that they enable\nrapid capability gains during the early optimization stage, while constraining\nreasoning capability later by reinforcing unreliable patterns. Building on\nthese insights, we propose Flawed-Aware Policy Optimization (FAPO), which\npresents a parameter-free reward penalty for flawed-positive rollouts, enabling\nthe policy to leverage them as useful shortcuts in the warm-up stage, securing\nstable early gains, while gradually shifting optimization toward reliable\nreasoning in the later refinement stage. To accurately and comprehensively\ndetect flawed-positive rollouts, we introduce a generative reward model (GenRM)\nwith a process-level reward that precisely localizes reasoning errors.\nExperiments show that FAPO is effective in broad domains, improving outcome\ncorrectness, process reliability, and training stability without increasing the\ntoken budget.",
      "fetch_date": "2025-10-30",
      "num_comments": 1,
      "ai_summary": "Flawed-Aware Policy Optimization (FAPO) enhances reinforcement learning with verifiable rewards by penalizing flawed-positive rollouts, improving reasoning capability and training stability in large language models.",
      "ai_keywords": [
        "reinforcement learning",
        "verifiable rewards",
        "large language models",
        "reasoning trajectories",
        "policy optimization",
        "flawed-positive rollouts",
        "parameter-free reward penalty",
        "generative reward model",
        "process-level reward",
        "reasoning errors"
      ]
    }
  },
  {
    "id": "32811c5aee11a368e90161a3c41bd70b",
    "source": "huggingface",
    "type": "paper",
    "title": "Chronos-2: From Univariate to Universal Forecasting",
    "description": "Pretrained time series models have enabled inference-only forecasting systems\nthat produce accurate predictions without task-specific training. However,\nexisting approaches largely focus on univariate...<br/>Upvotes: 19<br/>GitHub Stars: 4325<br/>Authors: Abdul Fatir Ansari, Oleksandr Shchur, Jaris KÃ¼ken<br/>ðŸ”— <a href=\"https://github.com/amazon-science/chronos-forecasting\">GitHub</a><br/>ðŸ”— <a href=\"https://huggingface.co/amazon/chronos-2\">Project Page</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2510.15821\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2510.15821",
    "external_url": "https://github.com/amazon-science/chronos-forecasting",
    "published_date": "2025-10-17T13:00:53.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2510.15821",
      "upvotes": 19,
      "github_stars": 4325,
      "github_url": "https://github.com/amazon-science/chronos-forecasting",
      "project_url": "https://huggingface.co/amazon/chronos-2",
      "authors": [
        "Abdul Fatir Ansari",
        "Oleksandr Shchur",
        "Jaris KÃ¼ken",
        "Andreas Auer",
        "Boran Han",
        "Pedro Mercado",
        "Syama Sundar Rangapuram",
        "Huibin Shen",
        "Lorenzo Stella",
        "Xiyuan Zhang",
        "Mononito Goswami",
        "Shubham Kapoor",
        "Danielle C. Maddix",
        "Pablo Guerron",
        "Tony Hu",
        "Junming Yin",
        "Nick Erickson",
        "Prateek Mutalik Desai",
        "Hao Wang",
        "Huzefa Rangwala",
        "George Karypis",
        "Yuyang Wang",
        "Michael Bohlke-Schneider"
      ],
      "summary": "Pretrained time series models have enabled inference-only forecasting systems\nthat produce accurate predictions without task-specific training. However,\nexisting approaches largely focus on univariate forecasting, limiting their\napplicability in real-world scenarios where multivariate data and covariates\nplay a crucial role. We present Chronos-2, a pretrained model capable of\nhandling univariate, multivariate, and covariate-informed forecasting tasks in\na zero-shot manner. Chronos-2 employs a group attention mechanism that\nfacilitates in-context learning (ICL) through efficient information sharing\nacross multiple time series within a group, which may represent sets of related\nseries, variates of a multivariate series, or targets and covariates in a\nforecasting task. These general capabilities are achieved through training on\nsynthetic datasets that impose diverse multivariate structures on univariate\nseries. Chronos-2 delivers state-of-the-art performance across three\ncomprehensive benchmarks: fev-bench, GIFT-Eval, and Chronos Benchmark II. On\nfev-bench, which emphasizes multivariate and covariate-informed forecasting,\nChronos-2's universal ICL capabilities lead to substantial improvements over\nexisting models. On tasks involving covariates, it consistently outperforms\nbaselines by a wide margin. Case studies in the energy and retail domains\nfurther highlight its practical advantages. The in-context learning\ncapabilities of Chronos-2 establish it as a general-purpose forecasting model\nthat can be used \"as is\" in real-world forecasting pipelines.",
      "fetch_date": "2025-10-21",
      "num_comments": 3,
      "ai_summary": "Chronos-2, a pretrained model with a group attention mechanism, achieves state-of-the-art performance in zero-shot univariate, multivariate, and covariate-informed forecasting tasks.",
      "ai_keywords": [
        "pretrained model",
        "group attention mechanism",
        "in-context learning",
        "ICL",
        "synthetic datasets",
        "multivariate structures",
        "fev-bench",
        "GIFT-Eval",
        "Chronos Benchmark II",
        "energy domain",
        "retail domain"
      ]
    }
  },
  {
    "id": "56964b5c4b70a7c48e204a4541b8da35",
    "source": "huggingface",
    "type": "paper",
    "title": "Black-Box On-Policy Distillation of Large Language Models",
    "description": "Black-box distillation creates student large language models (LLMs) by learning from a proprietary teacher model's text outputs alone, without access to its internal logits or parameters. In this work...<br/>Upvotes: 39<br/>GitHub Stars: 4186<br/>Authors: Tianzhu Ye, Li Dong, Zewen Chi<br/>ðŸ”— <a href=\"https://github.com/microsoft/LMOps/tree/main/gad\">GitHub</a><br/>ðŸ”— <a href=\"https://aka.ms/GAD-project\">Project Page</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2511.10643\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2511.10643",
    "external_url": "https://github.com/microsoft/LMOps/tree/main/gad",
    "published_date": "2025-11-13T13:58:37.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2511.10643",
      "upvotes": 39,
      "github_stars": 4186,
      "github_url": "https://github.com/microsoft/LMOps/tree/main/gad",
      "project_url": "https://aka.ms/GAD-project",
      "authors": [
        "Tianzhu Ye",
        "Li Dong",
        "Zewen Chi",
        "Xun Wu",
        "Shaohan Huang",
        "Furu Wei"
      ],
      "summary": "Black-box distillation creates student large language models (LLMs) by learning from a proprietary teacher model's text outputs alone, without access to its internal logits or parameters. In this work, we introduce Generative Adversarial Distillation (GAD), which enables on-policy and black-box distillation. GAD frames the student LLM as a generator and trains a discriminator to distinguish its responses from the teacher LLM's, creating a minimax game. The discriminator acts as an on-policy reward model that co-evolves with the student, providing stable, adaptive feedback. Experimental results show that GAD consistently surpasses the commonly used sequence-level knowledge distillation. In particular, Qwen2.5-14B-Instruct (student) trained with GAD becomes comparable to its teacher, GPT-5-Chat, on the LMSYS-Chat automatic evaluation. The results establish GAD as a promising and effective paradigm for black-box LLM distillation.",
      "fetch_date": "2025-11-14",
      "num_comments": 3,
      "ai_summary": "Generative Adversarial Distillation (GAD) enhances black-box distillation by framing the student model as a generator and using a discriminator to provide adaptive feedback, surpassing traditional sequence-level knowledge distillation.",
      "ai_keywords": [
        "black-box distillation",
        "large language models (LLMs)",
        "Generative Adversarial Distillation (GAD)",
        "generator",
        "discriminator",
        "minimax game",
        "on-policy reward model",
        "sequence-level knowledge distillation",
        "LMSYS-Chat automatic evaluation"
      ]
    }
  },
  {
    "id": "1f8425376c830b061c351b993f70d01b",
    "source": "huggingface",
    "type": "paper",
    "title": "DeepAnalyze: Agentic Large Language Models for Autonomous Data Science",
    "description": "Autonomous data science, from raw data sources to analyst-grade deep research\nreports, has been a long-standing challenge, and is now becoming feasible with\nthe emergence of powerful large language mo...<br/>Upvotes: 98<br/>GitHub Stars: 2121<br/>Authors: Shaolei Zhang, Ju Fan, Meihao Fan<br/>ðŸ”— <a href=\"https://github.com/ruc-datalab/DeepAnalyze\">GitHub</a><br/>ðŸ”— <a href=\"https://ruc-deepanalyze.github.io/\">Project Page</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2510.16872\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2510.16872",
    "external_url": "https://github.com/ruc-datalab/DeepAnalyze",
    "published_date": "2025-10-19T11:13:42.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2510.16872",
      "upvotes": 98,
      "github_stars": 2121,
      "github_url": "https://github.com/ruc-datalab/DeepAnalyze",
      "project_url": "https://ruc-deepanalyze.github.io/",
      "authors": [
        "Shaolei Zhang",
        "Ju Fan",
        "Meihao Fan",
        "Guoliang Li",
        "Xiaoyong Du"
      ],
      "summary": "Autonomous data science, from raw data sources to analyst-grade deep research\nreports, has been a long-standing challenge, and is now becoming feasible with\nthe emergence of powerful large language models (LLMs). Recent workflow-based\ndata agents have shown promising results on specific data tasks but remain\nfundamentally limited in achieving fully autonomous data science due to their\nreliance on predefined workflows. In this paper, we introduce DeepAnalyze-8B,\nthe first agentic LLM designed for autonomous data science, capable of\nautomatically completing the end-toend pipeline from data sources to\nanalyst-grade deep research reports. To tackle high-complexity data science\ntasks, we propose a curriculum-based agentic training paradigm that emulates\nthe learning trajectory of human data scientists, enabling LLMs to\nprogressively acquire and integrate multiple capabilities in real-world\nenvironments. We also introduce a data-grounded trajectory synthesis framework\nthat constructs high-quality training data. Through agentic training,\nDeepAnalyze learns to perform a broad spectrum of data tasks, ranging from data\nquestion answering and specialized analytical tasks to open-ended data\nresearch. Experiments demonstrate that, with only 8B parameters, DeepAnalyze\noutperforms previous workflow-based agents built on most advanced proprietary\nLLMs. The model, code, and training data of DeepAnalyze are open-sourced,\npaving the way toward autonomous data science.",
      "fetch_date": "2025-10-21",
      "num_comments": 4,
      "ai_summary": "DeepAnalyze-8B, an agentic LLM, autonomously completes the data science pipeline from raw data to research reports using curriculum-based training and data-grounded trajectory synthesis.",
      "ai_keywords": [
        "large language models",
        "LLMs",
        "workflow-based data agents",
        "agentic LLM",
        "curriculum-based agentic training",
        "data-grounded trajectory synthesis",
        "data question answering",
        "specialized analytical tasks",
        "open-ended data research"
      ]
    }
  },
  {
    "id": "516eebe0ff75c447a2516832b9987a1b",
    "source": "huggingface",
    "type": "paper",
    "title": "Depth Anything 3: Recovering the Visual Space from Any Views",
    "description": "We present Depth Anything 3 (DA3), a model that predicts spatially consistent geometry from an arbitrary number of visual inputs, with or without known camera poses. In pursuit of minimal modeling, DA...<br/>Upvotes: 54<br/>GitHub Stars: 1837<br/>Authors: Haotong Lin, Sili Chen, Junhao Liew<br/>ðŸ”— <a href=\"https://github.com/ByteDance-Seed/depth-anything-3\">GitHub</a><br/>ðŸ”— <a href=\"https://depth-anything-3.github.io/\">Project Page</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2511.10647\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2511.10647",
    "external_url": "https://github.com/ByteDance-Seed/depth-anything-3",
    "published_date": "2025-11-13T13:59:53.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2511.10647",
      "upvotes": 54,
      "github_stars": 1837,
      "github_url": "https://github.com/ByteDance-Seed/depth-anything-3",
      "project_url": "https://depth-anything-3.github.io/",
      "authors": [
        "Haotong Lin",
        "Sili Chen",
        "Junhao Liew",
        "Donny Y. Chen",
        "Zhenyu Li",
        "Guang Shi",
        "Jiashi Feng",
        "Bingyi Kang"
      ],
      "summary": "We present Depth Anything 3 (DA3), a model that predicts spatially consistent geometry from an arbitrary number of visual inputs, with or without known camera poses. In pursuit of minimal modeling, DA3 yields two key insights: a single plain transformer (e.g., vanilla DINO encoder) is sufficient as a backbone without architectural specialization, and a singular depth-ray prediction target obviates the need for complex multi-task learning. Through our teacher-student training paradigm, the model achieves a level of detail and generalization on par with Depth Anything 2 (DA2). We establish a new visual geometry benchmark covering camera pose estimation, any-view geometry and visual rendering. On this benchmark, DA3 sets a new state-of-the-art across all tasks, surpassing prior SOTA VGGT by an average of 44.3% in camera pose accuracy and 25.1% in geometric accuracy. Moreover, it outperforms DA2 in monocular depth estimation. All models are trained exclusively on public academic datasets.",
      "fetch_date": "2025-11-14",
      "num_comments": 2,
      "ai_summary": "Depth Anything 3 (DA3) uses a plain transformer for geometry prediction from visual inputs, achieving state-of-the-art results in camera pose estimation, any-view geometry, visual rendering, and monocular depth estimation.",
      "ai_keywords": [
        "plain transformer",
        "vanilla DINO encoder",
        "depth-ray prediction",
        "teacher-student training paradigm",
        "visual geometry benchmark",
        "camera pose estimation",
        "any-view geometry",
        "visual rendering",
        "monocular depth estimation",
        "state-of-the-art (SOTA)",
        "VGGT"
      ]
    }
  },
  {
    "id": "c1f2367c73a40263de9e1d62da95aa34",
    "source": "huggingface",
    "type": "paper",
    "title": "Pico-Banana-400K: A Large-Scale Dataset for Text-Guided Image Editing",
    "description": "Recent advances in multimodal models have demonstrated remarkable text-guided\nimage editing capabilities, with systems like GPT-4o and Nano-Banana setting\nnew benchmarks. However, the research communi...<br/>Upvotes: 28<br/>GitHub Stars: 1662<br/>Authors: Yusu Qian, Eli Bocek-Rivele, Liangchen Song<br/>ðŸ”— <a href=\"https://github.com/apple/pico-banana-400k\">GitHub</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2510.19808\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2510.19808",
    "external_url": "https://github.com/apple/pico-banana-400k",
    "published_date": "2025-10-22T13:43:15.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2510.19808",
      "upvotes": 28,
      "github_stars": 1662,
      "github_url": "https://github.com/apple/pico-banana-400k",
      "project_url": "",
      "authors": [
        "Yusu Qian",
        "Eli Bocek-Rivele",
        "Liangchen Song",
        "Jialing Tong",
        "Yinfei Yang",
        "Jiasen Lu",
        "Wenze Hu",
        "Zhe Gan"
      ],
      "summary": "Recent advances in multimodal models have demonstrated remarkable text-guided\nimage editing capabilities, with systems like GPT-4o and Nano-Banana setting\nnew benchmarks. However, the research community's progress remains constrained\nby the absence of large-scale, high-quality, and openly accessible datasets\nbuilt from real images. We introduce Pico-Banana-400K, a comprehensive\n400K-image dataset for instruction-based image editing. Our dataset is\nconstructed by leveraging Nano-Banana to generate diverse edit pairs from real\nphotographs in the OpenImages collection. What distinguishes Pico-Banana-400K\nfrom previous synthetic datasets is our systematic approach to quality and\ndiversity. We employ a fine-grained image editing taxonomy to ensure\ncomprehensive coverage of edit types while maintaining precise content\npreservation and instruction faithfulness through MLLM-based quality scoring\nand careful curation. Beyond single turn editing, Pico-Banana-400K enables\nresearch into complex editing scenarios. The dataset includes three specialized\nsubsets: (1) a 72K-example multi-turn collection for studying sequential\nediting, reasoning, and planning across consecutive modifications; (2) a\n56K-example preference subset for alignment research and reward model training;\nand (3) paired long-short editing instructions for developing instruction\nrewriting and summarization capabilities. By providing this large-scale,\nhigh-quality, and task-rich resource, Pico-Banana-400K establishes a robust\nfoundation for training and benchmarking the next generation of text-guided\nimage editing models.",
      "fetch_date": "2025-10-23",
      "num_comments": 2,
      "ai_summary": "Pico-Banana-400K is a large-scale, high-quality dataset for instruction-based image editing, featuring diverse edit pairs, multi-turn editing, preference subsets, and long-short instruction pairs, enabling comprehensive research and benchmarking.",
      "ai_keywords": [
        "multimodal models",
        "text-guided image editing",
        "GPT-4o",
        "Nano-Banana",
        "OpenImages",
        "fine-grained image editing taxonomy",
        "MLLM-based quality scoring",
        "multi-turn editing",
        "preference subset",
        "instruction rewriting",
        "instruction summarization"
      ]
    }
  }
]