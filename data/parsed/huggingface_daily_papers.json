[
  {
    "id": "8c7bb673a7c23605ce494554bc937b12",
    "source": "huggingface",
    "type": "paper",
    "title": "Scaling Latent Reasoning via Looped Language Models",
    "description": "Modern LLMs are trained to \"think\" primarily via explicit text generation,\nsuch as chain-of-thought (CoT), which defers reasoning to post-training and\nunder-leverages pre-training data. We present and...<br/>Upvotes: 211<br/>Authors: Rui-Jie Zhu, Zixuan Wang, Kai Hua<br/>ðŸ”— <a href=\"https://ouro-llm.github.io/\">Project Page</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2510.25741\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2510.25741",
    "external_url": "",
    "published_date": "2025-10-29T13:45:42.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2510.25741",
      "upvotes": 211,
      "github_stars": 0,
      "github_url": "",
      "project_url": "https://ouro-llm.github.io/",
      "authors": [
        "Rui-Jie Zhu",
        "Zixuan Wang",
        "Kai Hua",
        "Tianyu Zhang",
        "Ziniu Li",
        "Haoran Que",
        "Boyi Wei",
        "Zixin Wen",
        "Fan Yin",
        "He Xing",
        "Lu Li",
        "Jiajun Shi",
        "Kaijing Ma",
        "Shanda Li",
        "Taylor Kergan",
        "Andrew Smith",
        "Xingwei Qu",
        "Mude Hui",
        "Bohong Wu",
        "Qiyang Min",
        "Hongzhi Huang",
        "Xun Zhou",
        "Wei Ye",
        "Jiaheng Liu",
        "Jian Yang",
        "Yunfeng Shi",
        "Chenghua Lin",
        "Enduo Zhao",
        "Tianle Cai",
        "Ge Zhang",
        "Wenhao Huang",
        "Yoshua Bengio",
        "Jason Eshraghian"
      ],
      "summary": "Modern LLMs are trained to \"think\" primarily via explicit text generation,\nsuch as chain-of-thought (CoT), which defers reasoning to post-training and\nunder-leverages pre-training data. We present and open-source Ouro, named after\nthe recursive Ouroboros, a family of pre-trained Looped Language Models\n(LoopLM) that instead build reasoning into the pre-training phase through (i)\niterative computation in latent space, (ii) an entropy-regularized objective\nfor learned depth allocation, and (iii) scaling to 7.7T tokens. Ouro 1.4B and\n2.6B models enjoy superior performance that match the results of up to 12B SOTA\nLLMs across a wide range of benchmarks. Through controlled experiments, we show\nthis advantage stems not from increased knowledge capacity, but from superior\nknowledge manipulation capabilities. We also show that LoopLM yields reasoning\ntraces more aligned with final outputs than explicit CoT. We hope our results\nshow the potential of LoopLM as a novel scaling direction in the reasoning era.\nOur model could be found in: http://ouro-llm.github.io.",
      "fetch_date": "2025-10-30",
      "num_comments": 4,
      "ai_summary": "LoopLM, a family of pre-trained Looped Language Models, enhances reasoning by integrating iterative computation and entropy regularization during pre-training, achieving superior performance with better knowledge manipulation.",
      "ai_keywords": [
        "Looped Language Models",
        "LoopLM",
        "iterative computation",
        "latent space",
        "entropy-regularized objective",
        "learned depth allocation",
        "chain-of-thought",
        "knowledge manipulation",
        "reasoning traces"
      ]
    }
  },
  {
    "id": "b81e62a9e2bd28a9fe78c760c27308b6",
    "source": "huggingface",
    "type": "paper",
    "title": "Thinking with Video: Video Generation as a Promising Multimodal\n  Reasoning Paradigm",
    "description": "\"Thinking with Text\" and \"Thinking with Images\" paradigm significantly\nimprove the reasoning ability of large language models (LLMs) and Vision\nLanguage Models (VLMs). However, these paradigms have in...<br/>Upvotes: 191<br/>GitHub Stars: 188<br/>Authors: Jingqi Tong, Yurong Mou, Hangcheng Li<br/>ðŸ”— <a href=\"https://github.com/tongjingqi/Thinking-with-Video\">GitHub</a><br/>ðŸ”— <a href=\"https://thinking-with-video.github.io/\">Project Page</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2511.04570\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2511.04570",
    "external_url": "https://github.com/tongjingqi/Thinking-with-Video",
    "published_date": "2025-11-06T12:25:23.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2511.04570",
      "upvotes": 191,
      "github_stars": 188,
      "github_url": "https://github.com/tongjingqi/Thinking-with-Video",
      "project_url": "https://thinking-with-video.github.io/",
      "authors": [
        "Jingqi Tong",
        "Yurong Mou",
        "Hangcheng Li",
        "Mingzhe Li",
        "Yongzhuo Yang",
        "Ming Zhang",
        "Qiguang Chen",
        "Tianyi Liang",
        "Xiaomeng Hu",
        "Yining Zheng",
        "Xinchi Chen",
        "Jun Zhao",
        "Xuanjing Huang",
        "Xipeng Qiu"
      ],
      "summary": "\"Thinking with Text\" and \"Thinking with Images\" paradigm significantly\nimprove the reasoning ability of large language models (LLMs) and Vision\nLanguage Models (VLMs). However, these paradigms have inherent limitations. (1)\nImages capture only single moments and fail to represent dynamic processes or\ncontinuous changes, and (2) The separation of text and vision as distinct\nmodalities, hindering unified multimodal understanding and generation. To\novercome these limitations, we introduce \"Thinking with Video\", a new paradigm\nthat leverages video generation models, such as Sora-2, to bridge visual and\ntextual reasoning in a unified temporal framework. To support this exploration,\nwe developed the Video Thinking Benchmark (VideoThinkBench). VideoThinkBench\nencompasses two task categories: (1) vision-centric tasks (e.g., Eyeballing\nPuzzles), and (2) text-centric tasks (e.g., subsets of GSM8K, MMMU). Our\nevaluation establishes Sora-2 as a capable reasoner. On vision-centric tasks,\nSora-2 is generally comparable to state-of-the-art (SOTA) VLMs, and even\nsurpasses VLMs on several tasks, such as Eyeballing Games. On text-centric\ntasks, Sora-2 achieves 92% accuracy on MATH, and 75.53% accuracy on MMMU.\nFurthermore, we systematically analyse the source of these abilities. We also\nfind that self-consistency and in-context learning can improve Sora-2's\nperformance. In summary, our findings demonstrate that the video generation\nmodel is the potential unified multimodal understanding and generation model,\npositions \"thinking with video\" as a unified multimodal reasoning paradigm.",
      "fetch_date": "2025-11-07",
      "num_comments": 4,
      "ai_summary": "The \"Thinking with Video\" paradigm enhances multimodal reasoning by integrating video generation models, demonstrated through the Video Thinking Benchmark and improved performance on both vision and text tasks.",
      "ai_keywords": [
        "Thinking with Text",
        "Thinking with Images",
        "large language models",
        "Vision Language Models",
        "Thinking with Video",
        "video generation models",
        "Video Thinking Benchmark",
        "vision-centric tasks",
        "text-centric tasks",
        "Eyeballing Puzzles",
        "GSM8K",
        "MMMU",
        "self-consistency",
        "in-context learning"
      ]
    }
  },
  {
    "id": "9f97533076b36bd588d78f78c4352369",
    "source": "huggingface",
    "type": "paper",
    "title": "Concerto: Joint 2D-3D Self-Supervised Learning Emerges Spatial\n  Representations",
    "description": "Humans learn abstract concepts through multisensory synergy, and once formed,\nsuch representations can often be recalled from a single modality. Inspired by\nthis principle, we introduce Concerto, a mi...<br/>Upvotes: 172<br/>GitHub Stars: 419<br/>Authors: Yujia Zhang, Xiaoyang Wu, Yixing Lao<br/>ðŸ”— <a href=\"https://github.com/Pointcept/Concerto\">GitHub</a><br/>ðŸ”— <a href=\"https://pointcept.github.io/Concerto/\">Project Page</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2510.23607\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2510.23607",
    "external_url": "https://github.com/Pointcept/Concerto",
    "published_date": "2025-10-27T13:59:59.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2510.23607",
      "upvotes": 172,
      "github_stars": 419,
      "github_url": "https://github.com/Pointcept/Concerto",
      "project_url": "https://pointcept.github.io/Concerto/",
      "authors": [
        "Yujia Zhang",
        "Xiaoyang Wu",
        "Yixing Lao",
        "Chengyao Wang",
        "Zhuotao Tian",
        "Naiyan Wang",
        "Hengshuang Zhao"
      ],
      "summary": "Humans learn abstract concepts through multisensory synergy, and once formed,\nsuch representations can often be recalled from a single modality. Inspired by\nthis principle, we introduce Concerto, a minimalist simulation of human concept\nlearning for spatial cognition, combining 3D intra-modal self-distillation with\n2D-3D cross-modal joint embedding. Despite its simplicity, Concerto learns more\ncoherent and informative spatial features, as demonstrated by zero-shot\nvisualizations. It outperforms both standalone SOTA 2D and 3D self-supervised\nmodels by 14.2% and 4.8%, respectively, as well as their feature concatenation,\nin linear probing for 3D scene perception. With full fine-tuning, Concerto sets\nnew SOTA results across multiple scene understanding benchmarks (e.g., 80.7%\nmIoU on ScanNet). We further present a variant of Concerto tailored for\nvideo-lifted point cloud spatial understanding, and a translator that linearly\nprojects Concerto representations into CLIP's language space, enabling\nopen-world perception. These results highlight that Concerto emerges spatial\nrepresentations with superior fine-grained geometric and semantic consistency.",
      "fetch_date": "2025-10-28",
      "num_comments": 4,
      "ai_summary": "Concerto, a minimalist model combining 3D self-distillation and 2D-3D joint embedding, achieves superior spatial feature learning and outperforms existing models in scene understanding and open-world perception.",
      "ai_keywords": [
        "3D intra-modal self-distillation",
        "2D-3D cross-modal joint embedding",
        "zero-shot visualizations",
        "linear probing",
        "3D scene perception",
        "ScanNet",
        "mIoU",
        "video-lifted point cloud",
        "CLIP's language space",
        "open-world perception",
        "fine-grained geometric and semantic consistency"
      ]
    }
  },
  {
    "id": "4622a47084403f1652a1baac4335b4fa",
    "source": "huggingface",
    "type": "paper",
    "title": "Lumine: An Open Recipe for Building Generalist Agents in 3D Open Worlds",
    "description": "We introduce Lumine, the first open recipe for developing generalist agents capable of completing hours-long complex missions in real time within challenging 3D open-world environments. Lumine adopts ...<br/>Upvotes: 163<br/>Authors: Weihao Tan, Xiangyang Li, Yunhao Fang<br/>ðŸ”— <a href=\"https://www.lumine-ai.org/\">Project Page</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2511.08892\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2511.08892",
    "external_url": "",
    "published_date": "2025-11-11T21:01:26.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2511.08892",
      "upvotes": 163,
      "github_stars": 0,
      "github_url": "",
      "project_url": "https://www.lumine-ai.org/",
      "authors": [
        "Weihao Tan",
        "Xiangyang Li",
        "Yunhao Fang",
        "Heyuan Yao",
        "Shi Yan",
        "Hao Luo",
        "Tenglong Ao",
        "Huihui Li",
        "Hongbin Ren",
        "Bairen Yi",
        "Yujia Qin",
        "Bo An",
        "Libin Liu",
        "Guang Shi"
      ],
      "summary": "We introduce Lumine, the first open recipe for developing generalist agents capable of completing hours-long complex missions in real time within challenging 3D open-world environments. Lumine adopts a human-like interaction paradigm that unifies perception, reasoning, and action in an end-to-end manner, powered by a vision-language model. It processes raw pixels at 5 Hz to produce precise 30 Hz keyboard-mouse actions and adaptively invokes reasoning only when necessary. Trained in Genshin Impact, Lumine successfully completes the entire five-hour Mondstadt main storyline on par with human-level efficiency and follows natural language instructions to perform a broad spectrum of tasks in both 3D open-world exploration and 2D GUI manipulation across collection, combat, puzzle-solving, and NPC interaction. In addition to its in-domain performance, Lumine demonstrates strong zero-shot cross-game generalization. Without any fine-tuning, it accomplishes 100-minute missions in Wuthering Waves and the full five-hour first chapter of Honkai: Star Rail. These promising results highlight Lumine's effectiveness across distinct worlds and interaction dynamics, marking a concrete step toward generalist agents in open-ended environments.",
      "fetch_date": "2025-11-13",
      "num_comments": 11,
      "ai_summary": "Lumine, a vision-language model-based agent, completes complex missions in real-time across different 3D open-world environments with human-like efficiency and zero-shot cross-game generalization.",
      "ai_keywords": [
        "vision-language model",
        "end-to-end",
        "3D open-world environments",
        "human-like interaction",
        "real-time",
        "zero-shot cross-game generalization"
      ]
    }
  },
  {
    "id": "fa71d4f57dc7d25049e28fe9f9644922",
    "source": "huggingface",
    "type": "paper",
    "title": "A Theoretical Study on Bridging Internal Probability and\n  Self-Consistency for LLM Reasoning",
    "description": "Test-time scaling seeks to improve the reasoning performance of large\nlanguage models (LLMs) by adding computational resources. A prevalent approach\nwithin the field is sampling-based test-time scalin...<br/>Upvotes: 145<br/>GitHub Stars: 13<br/>Authors: Zhi Zhou, Yuhao Tan, Zenan Li<br/>ðŸ”— <a href=\"https://github.com/WNJXYK/RPC\">GitHub</a><br/>ðŸ”— <a href=\"https://wnjxyk.github.io/RPC\">Project Page</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2510.15444\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2510.15444",
    "external_url": "https://github.com/WNJXYK/RPC",
    "published_date": "2025-10-17T04:59:30.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2510.15444",
      "upvotes": 145,
      "github_stars": 13,
      "github_url": "https://github.com/WNJXYK/RPC",
      "project_url": "https://wnjxyk.github.io/RPC",
      "authors": [
        "Zhi Zhou",
        "Yuhao Tan",
        "Zenan Li",
        "Yuan Yao",
        "Lan-Zhe Guo",
        "Yu-Feng Li",
        "Xiaoxing Ma"
      ],
      "summary": "Test-time scaling seeks to improve the reasoning performance of large\nlanguage models (LLMs) by adding computational resources. A prevalent approach\nwithin the field is sampling-based test-time scaling methods, which enhance\nreasoning by generating multiple reasoning paths for a given input during\ninference. However, despite its practical success, the theoretical foundations\nremain underexplored. In this paper, we provide the first theoretical framework\nfor analyzing sampling-based test-time scaling methods, grounded in the\nperspective of confidence estimation. Based on the framework, we analyze two\ndominant paradigms: self-consistency and perplexity, and reveal key\nlimitations: self-consistency suffers from high estimation error while\nperplexity exhibits substantial modeling error and possible degradation of the\nestimation error convergence. To address these limitations, we introduce RPC, a\nhybrid method that leverages our theoretical insights through two key\ncomponents: Perplexity Consistency and Reasoning Pruning. Perplexity\nConsistency combines the strengths of self-consistency and perplexity, boosting\nthe convergence rate of estimation error from linear to exponential while\npreserving model error. Reasoning Pruning prevents degradation by eliminating\nlow-probability reasoning paths. Both theoretical analysis and empirical\nresults across seven benchmark datasets demonstrate that RPC has a strong\npotential for reducing reasoning error. Notably, RPC achieves reasoning\nperformance comparable to self-consistency while not only enhancing confidence\nreliability but also reducing sampling costs by 50%. The code and resources are\navailable at https://wnjxyk.github.io/RPC.",
      "fetch_date": "2025-10-20",
      "num_comments": 6,
      "ai_summary": "A theoretical framework for sampling-based test-time scaling in large language models reveals limitations in self-consistency and perplexity, and introduces RPC to improve reasoning performance and reduce sampling costs.",
      "ai_keywords": [
        "sampling-based test-time scaling",
        "large language models",
        "self-consistency",
        "perplexity",
        "Perplexity Consistency",
        "Reasoning Pruning",
        "confidence estimation",
        "reasoning error",
        "benchmark datasets"
      ]
    }
  },
  {
    "id": "0a60cb0f535685cc7eb12b1b01de62bc",
    "source": "huggingface",
    "type": "paper",
    "title": "MiroThinker: Pushing the Performance Boundaries of Open-Source Research Agents via Model, Context, and Interactive Scaling",
    "description": "We present MiroThinker v1.0, an open-source research agent designed to advance tool-augmented reasoning and information-seeking capabilities. Unlike previous agents that only scale up model size or co...<br/>Upvotes: 127<br/>GitHub Stars: 789<br/>Authors: MiroMind Team, Song Bai, Lidong Bing<br/>ðŸ”— <a href=\"https://github.com/MiroMindAI/MiroThinker\">GitHub</a><br/>ðŸ”— <a href=\"https://dr.miromind.ai/\">Project Page</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2511.11793\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2511.11793",
    "external_url": "https://github.com/MiroMindAI/MiroThinker",
    "published_date": "2025-11-14T13:52:07.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2511.11793",
      "upvotes": 127,
      "github_stars": 789,
      "github_url": "https://github.com/MiroMindAI/MiroThinker",
      "project_url": "https://dr.miromind.ai/",
      "authors": [
        "MiroMind Team",
        "Song Bai",
        "Lidong Bing",
        "Carson Chen",
        "Guanzheng Chen",
        "Yuntao Chen",
        "Zhe Chen",
        "Ziyi Chen",
        "Jifeng Dai",
        "Xuan Dong",
        "Yue Deng",
        "Yunjie Fu",
        "Junqi Ge",
        "Chenxia Han",
        "Tammy Huang",
        "Zhenhang Huang",
        "Jerry Jiao",
        "Shilei Jiang",
        "Tianyu Jiao",
        "Xiaoqi Jian",
        "Lei Lei",
        "Ruilin Li",
        "Ryan Luo",
        "Tiantong Li",
        "Xiang Lin",
        "Ziyuan Liu",
        "Zhiqi Li",
        "Jie Ni",
        "Qiang Ren",
        "Pax Sun",
        "Shiqian Su",
        "Chenxin Tao",
        "Bin Wang",
        "Hellen Wang",
        "Haonan Wang",
        "James Wang",
        "Jin Wang",
        "Jojo Wang",
        "Letian Wang",
        "Shizun Wang",
        "Weizhi Wang",
        "Zixuan Wang",
        "Jinfan Xu",
        "Sen Xing",
        "Chenyu Yang",
        "Hai Ye",
        "Jiaheng Yu",
        "Yue Yu",
        "Muyan Zhong",
        "Tianchen Zhao",
        "Xizhou Zhu",
        "Yanpeng Zhou",
        "Yifan Zhang",
        "Zhi Zhu"
      ],
      "summary": "We present MiroThinker v1.0, an open-source research agent designed to advance tool-augmented reasoning and information-seeking capabilities. Unlike previous agents that only scale up model size or context length, MiroThinker explores interaction scaling at the model level, systematically training the model to handle deeper and more frequent agent-environment interactions as a third dimension of performance improvement. Unlike LLM test-time scaling, which operates in isolation and risks degradation with longer reasoning chains, interactive scaling leverages environment feedback and external information acquisition to correct errors and refine trajectories. Through reinforcement learning, the model achieves efficient interaction scaling: with a 256K context window, it can perform up to 600 tool calls per task, enabling sustained multi-turn reasoning and complex real-world research workflows. Across four representative benchmarks-GAIA, HLE, BrowseComp, and BrowseComp-ZH-the 72B variant achieves up to 81.9%, 37.7%, 47.1%, and 55.6% accuracy respectively, surpassing previous open-source agents and approaching commercial counterparts such as GPT-5-high. Our analysis reveals that MiroThinker benefits from interactive scaling consistently: research performance improves predictably as the model engages in deeper and more frequent agent-environment interactions, demonstrating that interaction depth exhibits scaling behaviors analogous to model size and context length. These findings establish interaction scaling as a third critical dimension for building next-generation open research agents, complementing model capacity and context windows.",
      "fetch_date": "2025-11-18",
      "num_comments": 3,
      "ai_summary": "",
      "ai_keywords": []
    }
  },
  {
    "id": "bf88f955951ceb1c5ba0121481fe4bf5",
    "source": "huggingface",
    "type": "paper",
    "title": "FAPO: Flawed-Aware Policy Optimization for Efficient and Reliable\n  Reasoning",
    "description": "Reinforcement learning with verifiable rewards (RLVR) has emerged as a\npromising paradigm for enhancing the reasoning capabilities of large language\nmodels (LLMs). In this context, models explore reas...<br/>Upvotes: 7<br/>GitHub Stars: 16066<br/>Authors: Yuyang Ding, Chi Zhang, Juntao Li<br/>ðŸ”— <a href=\"https://github.com/volcengine/verl/tree/main/recipe/fapo\">GitHub</a><br/>ðŸ”— <a href=\"https://fapo-rl.github.io/\">Project Page</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2510.22543\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2510.22543",
    "external_url": "https://github.com/volcengine/verl/tree/main/recipe/fapo",
    "published_date": "2025-10-26T01:49:38.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2510.22543",
      "upvotes": 7,
      "github_stars": 16066,
      "github_url": "https://github.com/volcengine/verl/tree/main/recipe/fapo",
      "project_url": "https://fapo-rl.github.io/",
      "authors": [
        "Yuyang Ding",
        "Chi Zhang",
        "Juntao Li",
        "Haibin Lin",
        "Xin Liu",
        "Min Zhang"
      ],
      "summary": "Reinforcement learning with verifiable rewards (RLVR) has emerged as a\npromising paradigm for enhancing the reasoning capabilities of large language\nmodels (LLMs). In this context, models explore reasoning trajectories and\nexploit rollouts with correct answers as positive signals for policy\noptimization. However, these rollouts might involve flawed patterns such as\nanswer-guessing and jump-in-reasoning. Such flawed-positive rollouts are\nrewarded identically to fully correct ones, causing policy models to\ninternalize these unreliable reasoning patterns. In this work, we first conduct\na systematic study of flawed-positive rollouts in RL and find that they enable\nrapid capability gains during the early optimization stage, while constraining\nreasoning capability later by reinforcing unreliable patterns. Building on\nthese insights, we propose Flawed-Aware Policy Optimization (FAPO), which\npresents a parameter-free reward penalty for flawed-positive rollouts, enabling\nthe policy to leverage them as useful shortcuts in the warm-up stage, securing\nstable early gains, while gradually shifting optimization toward reliable\nreasoning in the later refinement stage. To accurately and comprehensively\ndetect flawed-positive rollouts, we introduce a generative reward model (GenRM)\nwith a process-level reward that precisely localizes reasoning errors.\nExperiments show that FAPO is effective in broad domains, improving outcome\ncorrectness, process reliability, and training stability without increasing the\ntoken budget.",
      "fetch_date": "2025-10-30",
      "num_comments": 1,
      "ai_summary": "Flawed-Aware Policy Optimization (FAPO) enhances reinforcement learning with verifiable rewards by penalizing flawed-positive rollouts, improving reasoning capability and training stability in large language models.",
      "ai_keywords": [
        "reinforcement learning",
        "verifiable rewards",
        "large language models",
        "reasoning trajectories",
        "policy optimization",
        "flawed-positive rollouts",
        "parameter-free reward penalty",
        "generative reward model",
        "process-level reward",
        "reasoning errors"
      ]
    }
  },
  {
    "id": "f37a636c7cc5f515c6866d60bda27643",
    "source": "huggingface",
    "type": "paper",
    "title": "UFO^3: Weaving the Digital Agent Galaxy",
    "description": "Large language model (LLM)-powered agents are transforming digital devices from passive tools into proactive intelligent collaborators. However, most existing frameworks remain confined to a single OS...<br/>Upvotes: 17<br/>GitHub Stars: 7724<br/>Authors: Chaoyun Zhang, Liqun Li, He Huang<br/>ðŸ”— <a href=\"https://github.com/microsoft/UFO/\">GitHub</a><br/>ðŸ”— <a href=\"https://microsoft.github.io/UFO/\">Project Page</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2511.11332\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2511.11332",
    "external_url": "https://github.com/microsoft/UFO/",
    "published_date": "2025-11-14T09:05:31.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2511.11332",
      "upvotes": 17,
      "github_stars": 7724,
      "github_url": "https://github.com/microsoft/UFO/",
      "project_url": "https://microsoft.github.io/UFO/",
      "authors": [
        "Chaoyun Zhang",
        "Liqun Li",
        "He Huang",
        "Chiming Ni",
        "Bo Qiao",
        "Si Qin",
        "Yu Kang",
        "Minghua Ma",
        "Qingwei Lin",
        "Saravan Rajmohan",
        "Dongmei Zhang"
      ],
      "summary": "Large language model (LLM)-powered agents are transforming digital devices from passive tools into proactive intelligent collaborators. However, most existing frameworks remain confined to a single OS or device, making cross-device workflows brittle and largely manual. We present UFO^3, a system that unifies heterogeneous endpoints, desktops, servers, mobile devices, and edge, into a single orchestration fabric. UFO^3 models each user request as a mutable TaskConstellation: a distributed DAG of atomic subtasks (TaskStars) with explicit control and data dependencies (TaskStarLines). The TaskConstellation continuously evolves as results stream in from distributed devices, enabling asynchronous execution, adaptive recovery, and dynamic optimization. A Constellation Orchestrator} executes tasks safely and asynchronously while applying dynamic DAG updates, and the Agent Interaction Protocol (AIP) provides persistent, low-latency channels for reliable task dispatch and result streaming. These designs dissolve the traditional boundaries between devices and platforms, allowing agents to collaborate seamlessly and amplify their collective intelligence.\n  We evaluate UFO^3 on NebulaBench, a benchmark of 55 cross-device tasks across 5 machines and 10 categories. UFO^3 achieves 83.3% subtask completion, 70.9% task success, exposes parallelism with an average width of 1.72, and reduces end-to-end latency by 31% relative to a sequential baseline. Fault-injection experiments demonstrate graceful degradation and recovery under transient and permanent agent failures. These results show that UFO^3 achieves accurate, efficient, and resilient task orchestration across heterogeneous devices, uniting isolated agents into a coherent, adaptive computing fabric that extends across the landscape of ubiquitous computing.",
      "fetch_date": "2025-11-18",
      "num_comments": 3,
      "ai_summary": "UFO$^3$ unifies heterogeneous devices into a single orchestration fabric, enabling seamless task collaboration and dynamic optimization across distributed environments.",
      "ai_keywords": [
        "TaskConstellation",
        "TaskStars",
        "TaskStarLines",
        "DAG",
        "Constellation Orchestrator",
        "Agent Interaction Protocol",
        "NebulaBench",
        "parallelism",
        "end-to-end latency",
        "fault-injection",
        "adaptive computing fabric",
        "ubiquitous computing"
      ]
    }
  },
  {
    "id": "32811c5aee11a368e90161a3c41bd70b",
    "source": "huggingface",
    "type": "paper",
    "title": "Chronos-2: From Univariate to Universal Forecasting",
    "description": "Pretrained time series models have enabled inference-only forecasting systems\nthat produce accurate predictions without task-specific training. However,\nexisting approaches largely focus on univariate...<br/>Upvotes: 19<br/>GitHub Stars: 4335<br/>Authors: Abdul Fatir Ansari, Oleksandr Shchur, Jaris KÃ¼ken<br/>ðŸ”— <a href=\"https://github.com/amazon-science/chronos-forecasting\">GitHub</a><br/>ðŸ”— <a href=\"https://huggingface.co/amazon/chronos-2\">Project Page</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2510.15821\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2510.15821",
    "external_url": "https://github.com/amazon-science/chronos-forecasting",
    "published_date": "2025-10-17T13:00:53.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2510.15821",
      "upvotes": 19,
      "github_stars": 4335,
      "github_url": "https://github.com/amazon-science/chronos-forecasting",
      "project_url": "https://huggingface.co/amazon/chronos-2",
      "authors": [
        "Abdul Fatir Ansari",
        "Oleksandr Shchur",
        "Jaris KÃ¼ken",
        "Andreas Auer",
        "Boran Han",
        "Pedro Mercado",
        "Syama Sundar Rangapuram",
        "Huibin Shen",
        "Lorenzo Stella",
        "Xiyuan Zhang",
        "Mononito Goswami",
        "Shubham Kapoor",
        "Danielle C. Maddix",
        "Pablo Guerron",
        "Tony Hu",
        "Junming Yin",
        "Nick Erickson",
        "Prateek Mutalik Desai",
        "Hao Wang",
        "Huzefa Rangwala",
        "George Karypis",
        "Yuyang Wang",
        "Michael Bohlke-Schneider"
      ],
      "summary": "Pretrained time series models have enabled inference-only forecasting systems\nthat produce accurate predictions without task-specific training. However,\nexisting approaches largely focus on univariate forecasting, limiting their\napplicability in real-world scenarios where multivariate data and covariates\nplay a crucial role. We present Chronos-2, a pretrained model capable of\nhandling univariate, multivariate, and covariate-informed forecasting tasks in\na zero-shot manner. Chronos-2 employs a group attention mechanism that\nfacilitates in-context learning (ICL) through efficient information sharing\nacross multiple time series within a group, which may represent sets of related\nseries, variates of a multivariate series, or targets and covariates in a\nforecasting task. These general capabilities are achieved through training on\nsynthetic datasets that impose diverse multivariate structures on univariate\nseries. Chronos-2 delivers state-of-the-art performance across three\ncomprehensive benchmarks: fev-bench, GIFT-Eval, and Chronos Benchmark II. On\nfev-bench, which emphasizes multivariate and covariate-informed forecasting,\nChronos-2's universal ICL capabilities lead to substantial improvements over\nexisting models. On tasks involving covariates, it consistently outperforms\nbaselines by a wide margin. Case studies in the energy and retail domains\nfurther highlight its practical advantages. The in-context learning\ncapabilities of Chronos-2 establish it as a general-purpose forecasting model\nthat can be used \"as is\" in real-world forecasting pipelines.",
      "fetch_date": "2025-10-21",
      "num_comments": 3,
      "ai_summary": "Chronos-2, a pretrained model with a group attention mechanism, achieves state-of-the-art performance in zero-shot univariate, multivariate, and covariate-informed forecasting tasks.",
      "ai_keywords": [
        "pretrained model",
        "group attention mechanism",
        "in-context learning",
        "ICL",
        "synthetic datasets",
        "multivariate structures",
        "fev-bench",
        "GIFT-Eval",
        "Chronos Benchmark II",
        "energy domain",
        "retail domain"
      ]
    }
  },
  {
    "id": "56964b5c4b70a7c48e204a4541b8da35",
    "source": "huggingface",
    "type": "paper",
    "title": "Black-Box On-Policy Distillation of Large Language Models",
    "description": "Black-box distillation creates student large language models (LLMs) by learning from a proprietary teacher model's text outputs alone, without access to its internal logits or parameters. In this work...<br/>Upvotes: 39<br/>GitHub Stars: 4191<br/>Authors: Tianzhu Ye, Li Dong, Zewen Chi<br/>ðŸ”— <a href=\"https://github.com/microsoft/LMOps/tree/main/gad\">GitHub</a><br/>ðŸ”— <a href=\"https://aka.ms/GAD-project\">Project Page</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2511.10643\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2511.10643",
    "external_url": "https://github.com/microsoft/LMOps/tree/main/gad",
    "published_date": "2025-11-13T13:58:37.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2511.10643",
      "upvotes": 39,
      "github_stars": 4191,
      "github_url": "https://github.com/microsoft/LMOps/tree/main/gad",
      "project_url": "https://aka.ms/GAD-project",
      "authors": [
        "Tianzhu Ye",
        "Li Dong",
        "Zewen Chi",
        "Xun Wu",
        "Shaohan Huang",
        "Furu Wei"
      ],
      "summary": "Black-box distillation creates student large language models (LLMs) by learning from a proprietary teacher model's text outputs alone, without access to its internal logits or parameters. In this work, we introduce Generative Adversarial Distillation (GAD), which enables on-policy and black-box distillation. GAD frames the student LLM as a generator and trains a discriminator to distinguish its responses from the teacher LLM's, creating a minimax game. The discriminator acts as an on-policy reward model that co-evolves with the student, providing stable, adaptive feedback. Experimental results show that GAD consistently surpasses the commonly used sequence-level knowledge distillation. In particular, Qwen2.5-14B-Instruct (student) trained with GAD becomes comparable to its teacher, GPT-5-Chat, on the LMSYS-Chat automatic evaluation. The results establish GAD as a promising and effective paradigm for black-box LLM distillation.",
      "fetch_date": "2025-11-14",
      "num_comments": 3,
      "ai_summary": "Generative Adversarial Distillation (GAD) enhances black-box distillation by framing the student model as a generator and using a discriminator to provide adaptive feedback, surpassing traditional sequence-level knowledge distillation.",
      "ai_keywords": [
        "black-box distillation",
        "large language models (LLMs)",
        "Generative Adversarial Distillation (GAD)",
        "generator",
        "discriminator",
        "minimax game",
        "on-policy reward model",
        "sequence-level knowledge distillation",
        "LMSYS-Chat automatic evaluation"
      ]
    }
  },
  {
    "id": "516eebe0ff75c447a2516832b9987a1b",
    "source": "huggingface",
    "type": "paper",
    "title": "Depth Anything 3: Recovering the Visual Space from Any Views",
    "description": "We present Depth Anything 3 (DA3), a model that predicts spatially consistent geometry from an arbitrary number of visual inputs, with or without known camera poses. In pursuit of minimal modeling, DA...<br/>Upvotes: 64<br/>GitHub Stars: 2138<br/>Authors: Haotong Lin, Sili Chen, Junhao Liew<br/>ðŸ”— <a href=\"https://github.com/ByteDance-Seed/depth-anything-3\">GitHub</a><br/>ðŸ”— <a href=\"https://depth-anything-3.github.io/\">Project Page</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2511.10647\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2511.10647",
    "external_url": "https://github.com/ByteDance-Seed/depth-anything-3",
    "published_date": "2025-11-13T13:59:53.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2511.10647",
      "upvotes": 64,
      "github_stars": 2138,
      "github_url": "https://github.com/ByteDance-Seed/depth-anything-3",
      "project_url": "https://depth-anything-3.github.io/",
      "authors": [
        "Haotong Lin",
        "Sili Chen",
        "Junhao Liew",
        "Donny Y. Chen",
        "Zhenyu Li",
        "Guang Shi",
        "Jiashi Feng",
        "Bingyi Kang"
      ],
      "summary": "We present Depth Anything 3 (DA3), a model that predicts spatially consistent geometry from an arbitrary number of visual inputs, with or without known camera poses. In pursuit of minimal modeling, DA3 yields two key insights: a single plain transformer (e.g., vanilla DINO encoder) is sufficient as a backbone without architectural specialization, and a singular depth-ray prediction target obviates the need for complex multi-task learning. Through our teacher-student training paradigm, the model achieves a level of detail and generalization on par with Depth Anything 2 (DA2). We establish a new visual geometry benchmark covering camera pose estimation, any-view geometry and visual rendering. On this benchmark, DA3 sets a new state-of-the-art across all tasks, surpassing prior SOTA VGGT by an average of 44.3% in camera pose accuracy and 25.1% in geometric accuracy. Moreover, it outperforms DA2 in monocular depth estimation. All models are trained exclusively on public academic datasets.",
      "fetch_date": "2025-11-14",
      "num_comments": 2,
      "ai_summary": "Depth Anything 3 (DA3) uses a plain transformer for geometry prediction from visual inputs, achieving state-of-the-art results in camera pose estimation, any-view geometry, visual rendering, and monocular depth estimation.",
      "ai_keywords": [
        "plain transformer",
        "vanilla DINO encoder",
        "depth-ray prediction",
        "teacher-student training paradigm",
        "visual geometry benchmark",
        "camera pose estimation",
        "any-view geometry",
        "visual rendering",
        "monocular depth estimation",
        "state-of-the-art (SOTA)",
        "VGGT"
      ]
    }
  },
  {
    "id": "1f8425376c830b061c351b993f70d01b",
    "source": "huggingface",
    "type": "paper",
    "title": "DeepAnalyze: Agentic Large Language Models for Autonomous Data Science",
    "description": "Autonomous data science, from raw data sources to analyst-grade deep research\nreports, has been a long-standing challenge, and is now becoming feasible with\nthe emergence of powerful large language mo...<br/>Upvotes: 98<br/>GitHub Stars: 2132<br/>Authors: Shaolei Zhang, Ju Fan, Meihao Fan<br/>ðŸ”— <a href=\"https://github.com/ruc-datalab/DeepAnalyze\">GitHub</a><br/>ðŸ”— <a href=\"https://ruc-deepanalyze.github.io/\">Project Page</a><br/>ðŸ”— <a href=\"https://huggingface.co/papers/2510.16872\">Hugging Face</a>",
    "url": "https://arxiv.org/abs/2510.16872",
    "external_url": "https://github.com/ruc-datalab/DeepAnalyze",
    "published_date": "2025-10-19T11:13:42.000Z",
    "categories": [
      "research",
      "paper"
    ],
    "metadata": {
      "paper_id": "2510.16872",
      "upvotes": 98,
      "github_stars": 2132,
      "github_url": "https://github.com/ruc-datalab/DeepAnalyze",
      "project_url": "https://ruc-deepanalyze.github.io/",
      "authors": [
        "Shaolei Zhang",
        "Ju Fan",
        "Meihao Fan",
        "Guoliang Li",
        "Xiaoyong Du"
      ],
      "summary": "Autonomous data science, from raw data sources to analyst-grade deep research\nreports, has been a long-standing challenge, and is now becoming feasible with\nthe emergence of powerful large language models (LLMs). Recent workflow-based\ndata agents have shown promising results on specific data tasks but remain\nfundamentally limited in achieving fully autonomous data science due to their\nreliance on predefined workflows. In this paper, we introduce DeepAnalyze-8B,\nthe first agentic LLM designed for autonomous data science, capable of\nautomatically completing the end-toend pipeline from data sources to\nanalyst-grade deep research reports. To tackle high-complexity data science\ntasks, we propose a curriculum-based agentic training paradigm that emulates\nthe learning trajectory of human data scientists, enabling LLMs to\nprogressively acquire and integrate multiple capabilities in real-world\nenvironments. We also introduce a data-grounded trajectory synthesis framework\nthat constructs high-quality training data. Through agentic training,\nDeepAnalyze learns to perform a broad spectrum of data tasks, ranging from data\nquestion answering and specialized analytical tasks to open-ended data\nresearch. Experiments demonstrate that, with only 8B parameters, DeepAnalyze\noutperforms previous workflow-based agents built on most advanced proprietary\nLLMs. The model, code, and training data of DeepAnalyze are open-sourced,\npaving the way toward autonomous data science.",
      "fetch_date": "2025-10-21",
      "num_comments": 4,
      "ai_summary": "DeepAnalyze-8B, an agentic LLM, autonomously completes the data science pipeline from raw data to research reports using curriculum-based training and data-grounded trajectory synthesis.",
      "ai_keywords": [
        "large language models",
        "LLMs",
        "workflow-based data agents",
        "agentic LLM",
        "curriculum-based agentic training",
        "data-grounded trajectory synthesis",
        "data question answering",
        "specialized analytical tasks",
        "open-ended data research"
      ]
    }
  }
]